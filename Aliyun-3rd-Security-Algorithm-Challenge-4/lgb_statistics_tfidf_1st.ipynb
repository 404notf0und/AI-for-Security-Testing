{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 工具包导入&数据读取\n",
    "## 工具包导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import gc\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/admin/Aliyun/Alibaba-3rd-Security-Algorithm-Challenge-master'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读取\n",
    "- 为了方便分析，我们读取3000万条数据进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '../final_input/'\n",
    "# train = pd.read_csv(path + 'final_train.csv',nrows=1000000)\n",
    "# test = pd.read_csv(path + 'final_test.csv',nrows=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv('../train.csv')\n",
    "#test = pd.read_csv(path + 'final_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程 & 验证结果(1-Gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_id  label\n",
       "0           0      0\n",
       "424         1      5\n",
       "426         2      5\n",
       "460         3      5\n",
       "3260        4      5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train[['file_id','label']].drop_duplicates()\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    111545\n",
       "5      3397\n",
       "2       744\n",
       "3       598\n",
       "1       287\n",
       "4        53\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全局特征:\n",
    "- File_id (Api): count,nunique\n",
    "- File_id (Tid): count,nunique,max,min,quantile(20,40,50,60,80),std,range\n",
    "- File_id (Return Value): count,nunique,max,min,quantile(20,40,50,60,80),std,range\n",
    "- File_id (Index): count,nunique,max,min,quantile(20,40,50,60,80),std,range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File_id (Api): count,nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>label</th>\n",
       "      <th>api</th>\n",
       "      <th>tid</th>\n",
       "      <th>return_value</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GetSystemTimeAsFileTime</td>\n",
       "      <td>2644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NtAllocateVirtualMemory</td>\n",
       "      <td>2644</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NtFreeVirtualMemory</td>\n",
       "      <td>2644</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NtAllocateVirtualMemory</td>\n",
       "      <td>2644</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NtAllocateVirtualMemory</td>\n",
       "      <td>2644</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_id  label                      api   tid  return_value  index\n",
       "0        0      0  GetSystemTimeAsFileTime  2644             0      0\n",
       "1        0      0  NtAllocateVirtualMemory  2644             0      1\n",
       "2        0      0      NtFreeVirtualMemory  2644             0      2\n",
       "3        0      0  NtAllocateVirtualMemory  2644             0      3\n",
       "4        0      0  NtAllocateVirtualMemory  2644             0      4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunique\n"
     ]
    }
   ],
   "source": [
    "api_opt = ['count','nunique'] \n",
    "for opt in api_opt:\n",
    "    print(opt)\n",
    "    tmp = train.groupby(['file_id'])['api'].agg({'fileid_api_' + opt: opt}).reset_index() \n",
    "    train_data = pd.merge(train_data,tmp,how='left', on='file_id')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>label</th>\n",
       "      <th>fileid_api_count</th>\n",
       "      <th>fileid_api_nunique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>424</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2800</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6832</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_id  label  fileid_api_count  fileid_api_nunique\n",
       "0        0      0               424                  19\n",
       "1        1      5                 2                   2\n",
       "2        2      5                34                  15\n",
       "3        3      5              2800                  65\n",
       "4        4      5              6832                  78"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File_id (Tid): count,nunique,max,min,quantile(20,40,50,60,80),std,range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunique\n",
      "max\n",
      "min\n",
      "median\n",
      "std\n"
     ]
    }
   ],
   "source": [
    "tid_opt = ['count','nunique','max','min','median','std'] \n",
    "for opt in tid_opt:\n",
    "    print(opt)\n",
    "    tmp = train.groupby(['file_id'])['tid'].agg({'fileid_tid_' + opt: opt}).reset_index() \n",
    "    train_data = pd.merge(train_data,tmp,how='left', on='file_id') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "secs = [0.2,0.4,0.6,0.8]\n",
    "for sec in secs: \n",
    "    train_data['fileid_tid_quantile_' + str(sec * 100)] = train.groupby(['file_id'])['tid'].quantile(sec).values\n",
    " \n",
    "train_data['fileid_tid_range'] = train.groupby(['file_id'])['tid'].quantile(0.975).values - train.groupby(['file_id'])['tid'].quantile(0.0125).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File_id (Index): count,nunique,max,min,quantile(20,40,50,60,80),std,range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunique\n",
      "max\n",
      "min\n",
      "median\n",
      "std\n"
     ]
    }
   ],
   "source": [
    "index_opt = ['count','nunique','max','min','median','std'] \n",
    "for opt in index_opt:\n",
    "    print(opt)\n",
    "    tmp = train.groupby(['file_id'])['index'].agg({'fileid_index_' + opt: opt}).reset_index() \n",
    "    train_data = pd.merge(train_data,tmp,how='left', on='file_id') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "secs = [0.2,0.4,0.6,0.8]\n",
    "for sec in secs: \n",
    "    train_data['fileid_index_quantile_' + str(sec * 100)] = train.groupby(['file_id'])['index'].quantile(sec).values\n",
    " \n",
    "train_data['fileid_index_range'] = train.groupby(['file_id'])['index'].quantile(0.975).values - train.groupby(['file_id'])['index'].quantile(0.0125).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全局特征的线下验证 <font color=red>( 0.0969482)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 评估指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_logloss(preds,data):\n",
    "    labels_ = data.get_label()\n",
    "    classes_ = np.unique(labels_) \n",
    "    preds_prob = []\n",
    "    \n",
    "    for i in range(len(classes_)):\n",
    "        preds_prob.append(preds[i*len(labels_):(i+1) * len(labels_)])\n",
    "    #print(preds_prob)\n",
    "    preds_prob_ = np.vstack(preds_prob) \n",
    "    \n",
    "    loss = [] \n",
    "    for i in range(preds_prob_.shape[1]):  # 样本个数\n",
    "        sum_ = 0  \n",
    "        for j in range(preds_prob_.shape[0]): #类别个数\n",
    "            pred = preds_prob_[j,i] # 第i个样本预测为第j类的概率\n",
    "            if  j == labels_[i]:\n",
    "                sum_ += np.log(pred)\n",
    "            else:\n",
    "                sum_ += np.log(1 - pred) \n",
    "             \n",
    "        loss.append(sum_)  \n",
    "         \n",
    "    return 'loss is: ' ,-1 * (np.sum(loss) / preds_prob_.shape[1]),False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练特征 & 标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = [col for col in train_data.columns if col!='label' and col!='file_id']\n",
    "train_label = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split( train_data[train_features],train_data[train_label].values, test_size = 0.33) \n",
    "#del _\n",
    "gc.collect()\n",
    "\n",
    "train_ind = train_X.index\n",
    "test_ind = test_X.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78138, 24), numpy.ndarray)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_X.shape),type(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_logloss: 1.64895\ttraining's loss is: : 2.52991\tvalid_1's multi_logloss: 1.65089\tvalid_1's loss is: : 2.53227\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's multi_logloss: 1.5265\ttraining's loss is: : 2.37761\tvalid_1's multi_logloss: 1.53033\tvalid_1's loss is: : 2.38233\n",
      "[3]\ttraining's multi_logloss: 1.41946\ttraining's loss is: : 2.24143\tvalid_1's multi_logloss: 1.42494\tvalid_1's loss is: : 2.24828\n",
      "[4]\ttraining's multi_logloss: 1.3244\ttraining's loss is: : 2.11789\tvalid_1's multi_logloss: 1.33141\tvalid_1's loss is: : 2.12675\n",
      "[5]\ttraining's multi_logloss: 1.23913\ttraining's loss is: : 2.00479\tvalid_1's multi_logloss: 1.24747\tvalid_1's loss is: : 2.01546\n",
      "[6]\ttraining's multi_logloss: 1.16219\ttraining's loss is: : 1.90076\tvalid_1's multi_logloss: 1.17178\tvalid_1's loss is: : 1.91317\n",
      "[7]\ttraining's multi_logloss: 1.09203\ttraining's loss is: : 1.80414\tvalid_1's multi_logloss: 1.10279\tvalid_1's loss is: : 1.81819\n",
      "[8]\ttraining's multi_logloss: 1.02778\ttraining's loss is: : 1.71408\tvalid_1's multi_logloss: 1.03962\tvalid_1's loss is: : 1.72969\n",
      "[9]\ttraining's multi_logloss: 0.968856\ttraining's loss is: : 1.6301\tvalid_1's multi_logloss: 0.981742\tvalid_1's loss is: : 1.64725\n",
      "[10]\ttraining's multi_logloss: 0.914471\ttraining's loss is: : 1.55136\tvalid_1's multi_logloss: 0.928355\tvalid_1's loss is: : 1.57001\n",
      "[11]\ttraining's multi_logloss: 0.86398\ttraining's loss is: : 1.47717\tvalid_1's multi_logloss: 0.878741\tvalid_1's loss is: : 1.49716\n",
      "[12]\ttraining's multi_logloss: 0.817184\ttraining's loss is: : 1.4074\tvalid_1's multi_logloss: 0.832763\tvalid_1's loss is: : 1.42867\n",
      "[13]\ttraining's multi_logloss: 0.773602\ttraining's loss is: : 1.34154\tvalid_1's multi_logloss: 0.789988\tvalid_1's loss is: : 1.36407\n",
      "[14]\ttraining's multi_logloss: 0.732819\ttraining's loss is: : 1.2791\tvalid_1's multi_logloss: 0.749982\tvalid_1's loss is: : 1.30288\n",
      "[15]\ttraining's multi_logloss: 0.6947\ttraining's loss is: : 1.22001\tvalid_1's multi_logloss: 0.712616\tvalid_1's loss is: : 1.24501\n",
      "[16]\ttraining's multi_logloss: 0.658892\ttraining's loss is: : 1.16386\tvalid_1's multi_logloss: 0.677528\tvalid_1's loss is: : 1.19004\n",
      "[17]\ttraining's multi_logloss: 0.625271\ttraining's loss is: : 1.11056\tvalid_1's multi_logloss: 0.644593\tvalid_1's loss is: : 1.13787\n",
      "[18]\ttraining's multi_logloss: 0.593816\ttraining's loss is: : 1.06013\tvalid_1's multi_logloss: 0.613824\tvalid_1's loss is: : 1.08859\n",
      "[19]\ttraining's multi_logloss: 0.564208\ttraining's loss is: : 1.01219\tvalid_1's multi_logloss: 0.58485\tvalid_1's loss is: : 1.04171\n",
      "[20]\ttraining's multi_logloss: 0.536333\ttraining's loss is: : 0.966594\tvalid_1's multi_logloss: 0.557559\tvalid_1's loss is: : 0.997127\n",
      "[21]\ttraining's multi_logloss: 0.510201\ttraining's loss is: : 0.923489\tvalid_1's multi_logloss: 0.532085\tvalid_1's loss is: : 0.955131\n",
      "[22]\ttraining's multi_logloss: 0.485531\ttraining's loss is: : 0.882442\tvalid_1's multi_logloss: 0.508091\tvalid_1's loss is: : 0.915201\n",
      "[23]\ttraining's multi_logloss: 0.462089\ttraining's loss is: : 0.843127\tvalid_1's multi_logloss: 0.485252\tvalid_1's loss is: : 0.87693\n",
      "[24]\ttraining's multi_logloss: 0.440028\ttraining's loss is: : 0.80583\tvalid_1's multi_logloss: 0.463804\tvalid_1's loss is: : 0.840692\n",
      "[25]\ttraining's multi_logloss: 0.419179\ttraining's loss is: : 0.770313\tvalid_1's multi_logloss: 0.443532\tvalid_1's loss is: : 0.8062\n",
      "[26]\ttraining's multi_logloss: 0.399391\ttraining's loss is: : 0.736402\tvalid_1's multi_logloss: 0.424413\tvalid_1's loss is: : 0.773424\n",
      "[27]\ttraining's multi_logloss: 0.380762\ttraining's loss is: : 0.704219\tvalid_1's multi_logloss: 0.406398\tvalid_1's loss is: : 0.742319\n",
      "[28]\ttraining's multi_logloss: 0.363066\ttraining's loss is: : 0.673466\tvalid_1's multi_logloss: 0.3893\tvalid_1's loss is: : 0.71262\n",
      "[29]\ttraining's multi_logloss: 0.346336\ttraining's loss is: : 0.644202\tvalid_1's multi_logloss: 0.373128\tvalid_1's loss is: : 0.684348\n",
      "[30]\ttraining's multi_logloss: 0.330447\ttraining's loss is: : 0.616273\tvalid_1's multi_logloss: 0.35772\tvalid_1's loss is: : 0.657299\n",
      "[31]\ttraining's multi_logloss: 0.315398\ttraining's loss is: : 0.589684\tvalid_1's multi_logloss: 0.343205\tvalid_1's loss is: : 0.631667\n",
      "[32]\ttraining's multi_logloss: 0.301152\ttraining's loss is: : 0.564388\tvalid_1's multi_logloss: 0.32953\tvalid_1's loss is: : 0.607392\n",
      "[33]\ttraining's multi_logloss: 0.287657\ttraining's loss is: : 0.540261\tvalid_1's multi_logloss: 0.316503\tvalid_1's loss is: : 0.584135\n",
      "[34]\ttraining's multi_logloss: 0.274926\ttraining's loss is: : 0.517388\tvalid_1's multi_logloss: 0.304216\tvalid_1's loss is: : 0.562106\n",
      "[35]\ttraining's multi_logloss: 0.262811\ttraining's loss is: : 0.495532\tvalid_1's multi_logloss: 0.292545\tvalid_1's loss is: : 0.541084\n",
      "[36]\ttraining's multi_logloss: 0.251144\ttraining's loss is: : 0.474509\tvalid_1's multi_logloss: 0.281528\tvalid_1's loss is: : 0.521165\n",
      "[37]\ttraining's multi_logloss: 0.240064\ttraining's loss is: : 0.454424\tvalid_1's multi_logloss: 0.271021\tvalid_1's loss is: : 0.502105\n",
      "[38]\ttraining's multi_logloss: 0.229587\ttraining's loss is: : 0.435336\tvalid_1's multi_logloss: 0.261101\tvalid_1's loss is: : 0.48403\n",
      "[39]\ttraining's multi_logloss: 0.219584\ttraining's loss is: : 0.417042\tvalid_1's multi_logloss: 0.251579\tvalid_1's loss is: : 0.46663\n",
      "[40]\ttraining's multi_logloss: 0.210153\ttraining's loss is: : 0.399724\tvalid_1's multi_logloss: 0.24266\tvalid_1's loss is: : 0.450261\n",
      "[41]\ttraining's multi_logloss: 0.201117\ttraining's loss is: : 0.383133\tvalid_1's multi_logloss: 0.234161\tvalid_1's loss is: : 0.434651\n",
      "[42]\ttraining's multi_logloss: 0.192622\ttraining's loss is: : 0.36747\tvalid_1's multi_logloss: 0.226239\tvalid_1's loss is: : 0.420013\n",
      "[43]\ttraining's multi_logloss: 0.184411\ttraining's loss is: : 0.352318\tvalid_1's multi_logloss: 0.218552\tvalid_1's loss is: : 0.405826\n",
      "[44]\ttraining's multi_logloss: 0.176594\ttraining's loss is: : 0.33783\tvalid_1's multi_logloss: 0.211242\tvalid_1's loss is: : 0.392296\n",
      "[45]\ttraining's multi_logloss: 0.169145\ttraining's loss is: : 0.324005\tvalid_1's multi_logloss: 0.20429\tvalid_1's loss is: : 0.379391\n",
      "[46]\ttraining's multi_logloss: 0.162083\ttraining's loss is: : 0.310844\tvalid_1's multi_logloss: 0.197757\tvalid_1's loss is: : 0.367209\n",
      "[47]\ttraining's multi_logloss: 0.155308\ttraining's loss is: : 0.298217\tvalid_1's multi_logloss: 0.191498\tvalid_1's loss is: : 0.355542\n",
      "[48]\ttraining's multi_logloss: 0.1489\ttraining's loss is: : 0.286232\tvalid_1's multi_logloss: 0.185638\tvalid_1's loss is: : 0.344577\n",
      "[49]\ttraining's multi_logloss: 0.142733\ttraining's loss is: : 0.274689\tvalid_1's multi_logloss: 0.179983\tvalid_1's loss is: : 0.333991\n",
      "[50]\ttraining's multi_logloss: 0.136811\ttraining's loss is: : 0.263614\tvalid_1's multi_logloss: 0.174632\tvalid_1's loss is: : 0.323943\n",
      "[51]\ttraining's multi_logloss: 0.131181\ttraining's loss is: : 0.253031\tvalid_1's multi_logloss: 0.16954\tvalid_1's loss is: : 0.314364\n",
      "[52]\ttraining's multi_logloss: 0.125825\ttraining's loss is: : 0.242936\tvalid_1's multi_logloss: 0.164684\tvalid_1's loss is: : 0.305215\n",
      "[53]\ttraining's multi_logloss: 0.120791\ttraining's loss is: : 0.233412\tvalid_1's multi_logloss: 0.16016\tvalid_1's loss is: : 0.296656\n",
      "[54]\ttraining's multi_logloss: 0.115949\ttraining's loss is: : 0.224245\tvalid_1's multi_logloss: 0.15581\tvalid_1's loss is: : 0.28844\n",
      "[55]\ttraining's multi_logloss: 0.111371\ttraining's loss is: : 0.215548\tvalid_1's multi_logloss: 0.151675\tvalid_1's loss is: : 0.280617\n",
      "[56]\ttraining's multi_logloss: 0.106985\ttraining's loss is: : 0.207242\tvalid_1's multi_logloss: 0.147839\tvalid_1's loss is: : 0.273342\n",
      "[57]\ttraining's multi_logloss: 0.102781\ttraining's loss is: : 0.199273\tvalid_1's multi_logloss: 0.14414\tvalid_1's loss is: : 0.266346\n",
      "[58]\ttraining's multi_logloss: 0.0987751\ttraining's loss is: : 0.191676\tvalid_1's multi_logloss: 0.140698\tvalid_1's loss is: : 0.259817\n",
      "[59]\ttraining's multi_logloss: 0.0949953\ttraining's loss is: : 0.184461\tvalid_1's multi_logloss: 0.137401\tvalid_1's loss is: : 0.25355\n",
      "[60]\ttraining's multi_logloss: 0.0912997\ttraining's loss is: : 0.177467\tvalid_1's multi_logloss: 0.1343\tvalid_1's loss is: : 0.247671\n",
      "[61]\ttraining's multi_logloss: 0.0877159\ttraining's loss is: : 0.170642\tvalid_1's multi_logloss: 0.131183\tvalid_1's loss is: : 0.241775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62]\ttraining's multi_logloss: 0.0843635\ttraining's loss is: : 0.164218\tvalid_1's multi_logloss: 0.128267\tvalid_1's loss is: : 0.23623\n",
      "[63]\ttraining's multi_logloss: 0.081106\ttraining's loss is: : 0.158023\tvalid_1's multi_logloss: 0.125563\tvalid_1's loss is: : 0.231088\n",
      "[64]\ttraining's multi_logloss: 0.0780027\ttraining's loss is: : 0.152087\tvalid_1's multi_logloss: 0.122951\tvalid_1's loss is: : 0.226128\n",
      "[65]\ttraining's multi_logloss: 0.0750579\ttraining's loss is: : 0.146446\tvalid_1's multi_logloss: 0.120481\tvalid_1's loss is: : 0.22142\n",
      "[66]\ttraining's multi_logloss: 0.072228\ttraining's loss is: : 0.141026\tvalid_1's multi_logloss: 0.11811\tvalid_1's loss is: : 0.216908\n",
      "[67]\ttraining's multi_logloss: 0.0695694\ttraining's loss is: : 0.13592\tvalid_1's multi_logloss: 0.115906\tvalid_1's loss is: : 0.212705\n",
      "[68]\ttraining's multi_logloss: 0.0670089\ttraining's loss is: : 0.130994\tvalid_1's multi_logloss: 0.113789\tvalid_1's loss is: : 0.208669\n",
      "[69]\ttraining's multi_logloss: 0.0646012\ttraining's loss is: : 0.126339\tvalid_1's multi_logloss: 0.111779\tvalid_1's loss is: : 0.204841\n",
      "[70]\ttraining's multi_logloss: 0.0622382\ttraining's loss is: : 0.121798\tvalid_1's multi_logloss: 0.109891\tvalid_1's loss is: : 0.201241\n",
      "[71]\ttraining's multi_logloss: 0.059936\ttraining's loss is: : 0.117376\tvalid_1's multi_logloss: 0.108088\tvalid_1's loss is: : 0.197807\n",
      "[72]\ttraining's multi_logloss: 0.0577918\ttraining's loss is: : 0.113246\tvalid_1's multi_logloss: 0.106436\tvalid_1's loss is: : 0.194665\n",
      "[73]\ttraining's multi_logloss: 0.0556926\ttraining's loss is: : 0.1092\tvalid_1's multi_logloss: 0.104844\tvalid_1's loss is: : 0.191636\n",
      "[74]\ttraining's multi_logloss: 0.0537782\ttraining's loss is: : 0.105517\tvalid_1's multi_logloss: 0.103469\tvalid_1's loss is: : 0.189012\n",
      "[75]\ttraining's multi_logloss: 0.0519018\ttraining's loss is: : 0.10191\tvalid_1's multi_logloss: 0.102126\tvalid_1's loss is: : 0.186447\n",
      "[76]\ttraining's multi_logloss: 0.0500684\ttraining's loss is: : 0.0983819\tvalid_1's multi_logloss: 0.100833\tvalid_1's loss is: : 0.183984\n",
      "[77]\ttraining's multi_logloss: 0.0483075\ttraining's loss is: : 0.0949635\tvalid_1's multi_logloss: 0.0994881\tvalid_1's loss is: : 0.181438\n",
      "[78]\ttraining's multi_logloss: 0.0465223\ttraining's loss is: : 0.0915489\tvalid_1's multi_logloss: 0.0982411\tvalid_1's loss is: : 0.179077\n",
      "[79]\ttraining's multi_logloss: 0.0449673\ttraining's loss is: : 0.0885302\tvalid_1's multi_logloss: 0.097079\tvalid_1's loss is: : 0.176863\n",
      "[80]\ttraining's multi_logloss: 0.0434327\ttraining's loss is: : 0.0855406\tvalid_1's multi_logloss: 0.0959018\tvalid_1's loss is: : 0.174642\n",
      "[81]\ttraining's multi_logloss: 0.0419949\ttraining's loss is: : 0.0827374\tvalid_1's multi_logloss: 0.0948366\tvalid_1's loss is: : 0.172626\n",
      "[82]\ttraining's multi_logloss: 0.0406125\ttraining's loss is: : 0.0800417\tvalid_1's multi_logloss: 0.0938422\tvalid_1's loss is: : 0.170735\n",
      "[83]\ttraining's multi_logloss: 0.0392954\ttraining's loss is: : 0.0774678\tvalid_1's multi_logloss: 0.0928708\tvalid_1's loss is: : 0.168902\n",
      "[84]\ttraining's multi_logloss: 0.0380293\ttraining's loss is: : 0.0749937\tvalid_1's multi_logloss: 0.0919652\tvalid_1's loss is: : 0.1672\n",
      "[85]\ttraining's multi_logloss: 0.0368177\ttraining's loss is: : 0.0726245\tvalid_1's multi_logloss: 0.0911458\tvalid_1's loss is: : 0.165654\n",
      "[86]\ttraining's multi_logloss: 0.0355701\ttraining's loss is: : 0.0702205\tvalid_1's multi_logloss: 0.0904101\tvalid_1's loss is: : 0.164273\n",
      "[87]\ttraining's multi_logloss: 0.0343704\ttraining's loss is: : 0.0678949\tvalid_1's multi_logloss: 0.089661\tvalid_1's loss is: : 0.162885\n",
      "[88]\ttraining's multi_logloss: 0.0332935\ttraining's loss is: : 0.0657869\tvalid_1's multi_logloss: 0.0889355\tvalid_1's loss is: : 0.161539\n",
      "[89]\ttraining's multi_logloss: 0.0323067\ttraining's loss is: : 0.0638549\tvalid_1's multi_logloss: 0.0882885\tvalid_1's loss is: : 0.160336\n",
      "[90]\ttraining's multi_logloss: 0.0313273\ttraining's loss is: : 0.0619343\tvalid_1's multi_logloss: 0.0876626\tvalid_1's loss is: : 0.159172\n",
      "[91]\ttraining's multi_logloss: 0.0303651\ttraining's loss is: : 0.0600486\tvalid_1's multi_logloss: 0.0870718\tvalid_1's loss is: : 0.158071\n",
      "[92]\ttraining's multi_logloss: 0.0294168\ttraining's loss is: : 0.0581927\tvalid_1's multi_logloss: 0.0864974\tvalid_1's loss is: : 0.157006\n",
      "[93]\ttraining's multi_logloss: 0.0285431\ttraining's loss is: : 0.0564787\tvalid_1's multi_logloss: 0.0860076\tvalid_1's loss is: : 0.156095\n",
      "[94]\ttraining's multi_logloss: 0.0277172\ttraining's loss is: : 0.0548583\tvalid_1's multi_logloss: 0.0855485\tvalid_1's loss is: : 0.155243\n",
      "[95]\ttraining's multi_logloss: 0.0269048\ttraining's loss is: : 0.0532644\tvalid_1's multi_logloss: 0.0850996\tvalid_1's loss is: : 0.154419\n",
      "[96]\ttraining's multi_logloss: 0.0261282\ttraining's loss is: : 0.0517396\tvalid_1's multi_logloss: 0.0847025\tvalid_1's loss is: : 0.153686\n",
      "[97]\ttraining's multi_logloss: 0.0253819\ttraining's loss is: : 0.0502742\tvalid_1's multi_logloss: 0.0843211\tvalid_1's loss is: : 0.152977\n",
      "[98]\ttraining's multi_logloss: 0.0246623\ttraining's loss is: : 0.0488597\tvalid_1's multi_logloss: 0.0839474\tvalid_1's loss is: : 0.152288\n",
      "[99]\ttraining's multi_logloss: 0.0239865\ttraining's loss is: : 0.0475311\tvalid_1's multi_logloss: 0.0836335\tvalid_1's loss is: : 0.15171\n",
      "[100]\ttraining's multi_logloss: 0.023336\ttraining's loss is: : 0.0462512\tvalid_1's multi_logloss: 0.083324\tvalid_1's loss is: : 0.151142\n",
      "[101]\ttraining's multi_logloss: 0.0227045\ttraining's loss is: : 0.0450085\tvalid_1's multi_logloss: 0.0830647\tvalid_1's loss is: : 0.150679\n",
      "[102]\ttraining's multi_logloss: 0.0220922\ttraining's loss is: : 0.0438032\tvalid_1's multi_logloss: 0.0828255\tvalid_1's loss is: : 0.150256\n",
      "[103]\ttraining's multi_logloss: 0.021515\ttraining's loss is: : 0.0426667\tvalid_1's multi_logloss: 0.0825754\tvalid_1's loss is: : 0.149816\n",
      "[104]\ttraining's multi_logloss: 0.02094\ttraining's loss is: : 0.0415339\tvalid_1's multi_logloss: 0.0823558\tvalid_1's loss is: : 0.149419\n",
      "[105]\ttraining's multi_logloss: 0.0203952\ttraining's loss is: : 0.0404607\tvalid_1's multi_logloss: 0.0821551\tvalid_1's loss is: : 0.149068\n",
      "[106]\ttraining's multi_logloss: 0.0198548\ttraining's loss is: : 0.039396\tvalid_1's multi_logloss: 0.0819209\tvalid_1's loss is: : 0.148655\n",
      "[107]\ttraining's multi_logloss: 0.0193558\ttraining's loss is: : 0.0384129\tvalid_1's multi_logloss: 0.081762\tvalid_1's loss is: : 0.148386\n",
      "[108]\ttraining's multi_logloss: 0.018851\ttraining's loss is: : 0.0374175\tvalid_1's multi_logloss: 0.0815511\tvalid_1's loss is: : 0.148015\n",
      "[109]\ttraining's multi_logloss: 0.0183891\ttraining's loss is: : 0.036507\tvalid_1's multi_logloss: 0.0813984\tvalid_1's loss is: : 0.147766\n",
      "[110]\ttraining's multi_logloss: 0.0179465\ttraining's loss is: : 0.035634\tvalid_1's multi_logloss: 0.0812688\tvalid_1's loss is: : 0.147553\n",
      "[111]\ttraining's multi_logloss: 0.0175118\ttraining's loss is: : 0.0347762\tvalid_1's multi_logloss: 0.0811581\tvalid_1's loss is: : 0.147387\n",
      "[112]\ttraining's multi_logloss: 0.0170688\ttraining's loss is: : 0.0339024\tvalid_1's multi_logloss: 0.0810382\tvalid_1's loss is: : 0.147195\n",
      "[113]\ttraining's multi_logloss: 0.0166323\ttraining's loss is: : 0.0330404\tvalid_1's multi_logloss: 0.0808673\tvalid_1's loss is: : 0.1469\n",
      "[114]\ttraining's multi_logloss: 0.0162207\ttraining's loss is: : 0.0322274\tvalid_1's multi_logloss: 0.0807344\tvalid_1's loss is: : 0.146694\n",
      "[115]\ttraining's multi_logloss: 0.0158435\ttraining's loss is: : 0.0314824\tvalid_1's multi_logloss: 0.080662\tvalid_1's loss is: : 0.14659\n",
      "[116]\ttraining's multi_logloss: 0.0154715\ttraining's loss is: : 0.0307481\tvalid_1's multi_logloss: 0.0806062\tvalid_1's loss is: : 0.146515\n",
      "[117]\ttraining's multi_logloss: 0.0151126\ttraining's loss is: : 0.0300394\tvalid_1's multi_logloss: 0.0805883\tvalid_1's loss is: : 0.146502\n",
      "[118]\ttraining's multi_logloss: 0.0147629\ttraining's loss is: : 0.0293486\tvalid_1's multi_logloss: 0.0805576\tvalid_1's loss is: : 0.146468\n",
      "[119]\ttraining's multi_logloss: 0.0144335\ttraining's loss is: : 0.0286976\tvalid_1's multi_logloss: 0.0805437\tvalid_1's loss is: : 0.146468\n",
      "[120]\ttraining's multi_logloss: 0.0141216\ttraining's loss is: : 0.0280811\tvalid_1's multi_logloss: 0.080539\tvalid_1's loss is: : 0.146489\n",
      "[121]\ttraining's multi_logloss: 0.0137956\ttraining's loss is: : 0.0274363\tvalid_1's multi_logloss: 0.0805199\tvalid_1's loss is: : 0.146475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[122]\ttraining's multi_logloss: 0.0135009\ttraining's loss is: : 0.026854\tvalid_1's multi_logloss: 0.0805337\tvalid_1's loss is: : 0.146537\n",
      "[123]\ttraining's multi_logloss: 0.0132081\ttraining's loss is: : 0.0262747\tvalid_1's multi_logloss: 0.0805441\tvalid_1's loss is: : 0.146587\n",
      "[124]\ttraining's multi_logloss: 0.0129072\ttraining's loss is: : 0.025679\tvalid_1's multi_logloss: 0.0805013\tvalid_1's loss is: : 0.146531\n",
      "[125]\ttraining's multi_logloss: 0.0126465\ttraining's loss is: : 0.0251632\tvalid_1's multi_logloss: 0.0805682\tvalid_1's loss is: : 0.146685\n",
      "[126]\ttraining's multi_logloss: 0.0123659\ttraining's loss is: : 0.0246081\tvalid_1's multi_logloss: 0.0805522\tvalid_1's loss is: : 0.14669\n",
      "[127]\ttraining's multi_logloss: 0.0120873\ttraining's loss is: : 0.0240564\tvalid_1's multi_logloss: 0.0805353\tvalid_1's loss is: : 0.146703\n",
      "[128]\ttraining's multi_logloss: 0.01183\ttraining's loss is: : 0.0235468\tvalid_1's multi_logloss: 0.0805219\tvalid_1's loss is: : 0.146723\n",
      "[129]\ttraining's multi_logloss: 0.0115815\ttraining's loss is: : 0.0230546\tvalid_1's multi_logloss: 0.080541\tvalid_1's loss is: : 0.146795\n",
      "[130]\ttraining's multi_logloss: 0.0113301\ttraining's loss is: : 0.0225563\tvalid_1's multi_logloss: 0.080535\tvalid_1's loss is: : 0.146815\n",
      "[131]\ttraining's multi_logloss: 0.011107\ttraining's loss is: : 0.0221147\tvalid_1's multi_logloss: 0.0806162\tvalid_1's loss is: : 0.147001\n",
      "[132]\ttraining's multi_logloss: 0.0108859\ttraining's loss is: : 0.0216766\tvalid_1's multi_logloss: 0.0806658\tvalid_1's loss is: : 0.147133\n",
      "[133]\ttraining's multi_logloss: 0.0106683\ttraining's loss is: : 0.0212455\tvalid_1's multi_logloss: 0.080716\tvalid_1's loss is: : 0.147268\n",
      "[134]\ttraining's multi_logloss: 0.0104632\ttraining's loss is: : 0.020839\tvalid_1's multi_logloss: 0.0807922\tvalid_1's loss is: : 0.147443\n",
      "[135]\ttraining's multi_logloss: 0.0102762\ttraining's loss is: : 0.0204685\tvalid_1's multi_logloss: 0.0808794\tvalid_1's loss is: : 0.14763\n",
      "[136]\ttraining's multi_logloss: 0.0100653\ttraining's loss is: : 0.0200516\tvalid_1's multi_logloss: 0.0809242\tvalid_1's loss is: : 0.147749\n",
      "[137]\ttraining's multi_logloss: 0.0098777\ttraining's loss is: : 0.0196807\tvalid_1's multi_logloss: 0.0810276\tvalid_1's loss is: : 0.147962\n",
      "[138]\ttraining's multi_logloss: 0.0096878\ttraining's loss is: : 0.0193047\tvalid_1's multi_logloss: 0.0811177\tvalid_1's loss is: : 0.148156\n",
      "[139]\ttraining's multi_logloss: 0.00950055\ttraining's loss is: : 0.0189336\tvalid_1's multi_logloss: 0.0812241\tvalid_1's loss is: : 0.148383\n",
      "[140]\ttraining's multi_logloss: 0.00933076\ttraining's loss is: : 0.0185972\tvalid_1's multi_logloss: 0.0813215\tvalid_1's loss is: : 0.148594\n",
      "[141]\ttraining's multi_logloss: 0.00915353\ttraining's loss is: : 0.0182455\tvalid_1's multi_logloss: 0.0813811\tvalid_1's loss is: : 0.148721\n",
      "[142]\ttraining's multi_logloss: 0.00897812\ttraining's loss is: : 0.0178975\tvalid_1's multi_logloss: 0.0814403\tvalid_1's loss is: : 0.148851\n",
      "[143]\ttraining's multi_logloss: 0.0088056\ttraining's loss is: : 0.0175551\tvalid_1's multi_logloss: 0.0814899\tvalid_1's loss is: : 0.148961\n",
      "[144]\ttraining's multi_logloss: 0.00863633\ttraining's loss is: : 0.0172191\tvalid_1's multi_logloss: 0.0815434\tvalid_1's loss is: : 0.149092\n",
      "[145]\ttraining's multi_logloss: 0.00847266\ttraining's loss is: : 0.0168941\tvalid_1's multi_logloss: 0.0815905\tvalid_1's loss is: : 0.14921\n",
      "[146]\ttraining's multi_logloss: 0.00832068\ttraining's loss is: : 0.0165923\tvalid_1's multi_logloss: 0.0816858\tvalid_1's loss is: : 0.149405\n",
      "[147]\ttraining's multi_logloss: 0.00816887\ttraining's loss is: : 0.0162908\tvalid_1's multi_logloss: 0.081773\tvalid_1's loss is: : 0.149594\n",
      "[148]\ttraining's multi_logloss: 0.00802234\ttraining's loss is: : 0.0159998\tvalid_1's multi_logloss: 0.0818798\tvalid_1's loss is: : 0.149809\n",
      "[149]\ttraining's multi_logloss: 0.0078831\ttraining's loss is: : 0.0157232\tvalid_1's multi_logloss: 0.0819895\tvalid_1's loss is: : 0.150036\n",
      "[150]\ttraining's multi_logloss: 0.00774349\ttraining's loss is: : 0.0154458\tvalid_1's multi_logloss: 0.0820795\tvalid_1's loss is: : 0.150224\n",
      "[151]\ttraining's multi_logloss: 0.00760905\ttraining's loss is: : 0.0151787\tvalid_1's multi_logloss: 0.0821886\tvalid_1's loss is: : 0.150455\n",
      "[152]\ttraining's multi_logloss: 0.00748312\ttraining's loss is: : 0.0149286\tvalid_1's multi_logloss: 0.0822805\tvalid_1's loss is: : 0.150649\n",
      "[153]\ttraining's multi_logloss: 0.00735885\ttraining's loss is: : 0.0146817\tvalid_1's multi_logloss: 0.0824021\tvalid_1's loss is: : 0.150893\n",
      "[154]\ttraining's multi_logloss: 0.00723977\ttraining's loss is: : 0.014445\tvalid_1's multi_logloss: 0.082504\tvalid_1's loss is: : 0.151105\n",
      "[155]\ttraining's multi_logloss: 0.00712536\ttraining's loss is: : 0.0142176\tvalid_1's multi_logloss: 0.0826306\tvalid_1's loss is: : 0.151361\n",
      "[156]\ttraining's multi_logloss: 0.00700361\ttraining's loss is: : 0.0139755\tvalid_1's multi_logloss: 0.0827772\tvalid_1's loss is: : 0.151659\n",
      "[157]\ttraining's multi_logloss: 0.00688649\ttraining's loss is: : 0.0137426\tvalid_1's multi_logloss: 0.0829064\tvalid_1's loss is: : 0.151917\n",
      "[158]\ttraining's multi_logloss: 0.00675833\ttraining's loss is: : 0.0134876\tvalid_1's multi_logloss: 0.0829741\tvalid_1's loss is: : 0.152063\n",
      "[159]\ttraining's multi_logloss: 0.00663798\ttraining's loss is: : 0.013248\tvalid_1's multi_logloss: 0.0830847\tvalid_1's loss is: : 0.152284\n",
      "[160]\ttraining's multi_logloss: 0.00652547\ttraining's loss is: : 0.0130241\tvalid_1's multi_logloss: 0.0832028\tvalid_1's loss is: : 0.152516\n",
      "[161]\ttraining's multi_logloss: 0.00640994\ttraining's loss is: : 0.0127942\tvalid_1's multi_logloss: 0.0833411\tvalid_1's loss is: : 0.152781\n",
      "[162]\ttraining's multi_logloss: 0.00630063\ttraining's loss is: : 0.0125766\tvalid_1's multi_logloss: 0.0834696\tvalid_1's loss is: : 0.153031\n",
      "[163]\ttraining's multi_logloss: 0.00619537\ttraining's loss is: : 0.0123671\tvalid_1's multi_logloss: 0.0835761\tvalid_1's loss is: : 0.15324\n",
      "[164]\ttraining's multi_logloss: 0.00609338\ttraining's loss is: : 0.0121641\tvalid_1's multi_logloss: 0.0836875\tvalid_1's loss is: : 0.153466\n",
      "[165]\ttraining's multi_logloss: 0.00600091\ttraining's loss is: : 0.01198\tvalid_1's multi_logloss: 0.0838398\tvalid_1's loss is: : 0.153762\n",
      "[166]\ttraining's multi_logloss: 0.00590668\ttraining's loss is: : 0.0117924\tvalid_1's multi_logloss: 0.0839688\tvalid_1's loss is: : 0.154027\n",
      "[167]\ttraining's multi_logloss: 0.00581562\ttraining's loss is: : 0.0116112\tvalid_1's multi_logloss: 0.0841156\tvalid_1's loss is: : 0.154309\n",
      "[168]\ttraining's multi_logloss: 0.00572404\ttraining's loss is: : 0.0114288\tvalid_1's multi_logloss: 0.0842517\tvalid_1's loss is: : 0.15457\n",
      "[169]\ttraining's multi_logloss: 0.00563387\ttraining's loss is: : 0.0112492\tvalid_1's multi_logloss: 0.084375\tvalid_1's loss is: : 0.154801\n",
      "Early stopping, best iteration is:\n",
      "[119]\ttraining's multi_logloss: 0.0144335\ttraining's loss is: : 0.0286976\tvalid_1's multi_logloss: 0.0805437\tvalid_1's loss is: : 0.146468\n"
     ]
    }
   ],
   "source": [
    "dtrain = lgb.Dataset(train_X,train_Y) \n",
    "dval   = lgb.Dataset(test_X,test_Y, reference = dtrain) \n",
    "\n",
    "params = {\n",
    "         'task':'train', \n",
    "         'num_leaves': 255,\n",
    "         'objective': 'multiclass',\n",
    "         'num_class':6,\n",
    "        #'min_data_in_leaf': 40,\n",
    "         'min_data_in_leaf': 1,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.85,\n",
    "        'bagging_fraction': 0.9,\n",
    "         'bagging_freq': 5, \n",
    "         'max_bin':128,\n",
    "        'num_threads': 10,\n",
    "        'random_state':100\n",
    "     }  \n",
    "lgb_model_0_order = lgb.train(params, dtrain, num_boost_round=500,valid_sets=[dtrain,dval], early_stopping_rounds=50,feval=lgb_logloss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全局特征扩充\n",
    "- File_id + return_value分段：计数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 局部组合特征(展开形式)\n",
    "### File_id + Api  \n",
    "- File_id + Api (tid): count,nunique\n",
    "- File_id + Api (return value): nunique, max, min, median, std\n",
    "- File_id + Api (index):  nunique, max, min, median, std\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File_id + Api (tid): count,nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_pivot_features(data_merge, data_orig , groupby_features,col1 = None, col2 = None, opts = None):\n",
    "    for opt in opts:\n",
    "        print(opt)\n",
    "        train_split = data_orig.groupby(['file_id',col1])[col2].agg({'fileid_' + col1 + '_'+col2+'_'+ str(opt):opt}).reset_index() \n",
    "        \n",
    "        train_split_ =  pd.pivot_table(train_split, values = 'fileid_' + col1 + '_'+col2+'_'+ str(opt), index=['file_id'],columns=[col1])\n",
    "        new_cols = [ 'fileid_' + col1 + '_'+col2+  '_' + opt + '_' + str(col) for col in train_split_.columns]\n",
    "        \n",
    "        groupby_features.append(new_cols)\n",
    "        train_split_.columns = new_cols \n",
    "\n",
    "        train_split_.reset_index(inplace = True)\n",
    "        \n",
    "        data_merge = pd.merge(data_merge,train_split_,how='left', on='file_id') \n",
    "    return data_merge,groupby_features \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunique\n"
     ]
    }
   ],
   "source": [
    "groupby_features = []\n",
    "api_opts = ['count', 'nunique']\n",
    "train_data_,groupby_features = groupby_pivot_features(train_data, train, groupby_features, col1 = 'api', col2 = 'tid', opts = api_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File_id + Api (return value): nunique, max, min, median, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# api_opts = ['nunique','max','min','median','std']\n",
    "# train_data_,groupby_features = groupby_pivot_features(train_data_, train, groupby_features, col1 = 'api', col2 = 'return_value', opts = api_opts) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  File_id + Api(index): nunique, max, min, median, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunique\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max\n",
      "min\n",
      "median\n",
      "std\n"
     ]
    }
   ],
   "source": [
    "api_opts = ['nunique','max','min','median','std']\n",
    "train_data_,groupby_features = groupby_pivot_features(train_data_, train, groupby_features, col1 = 'api', col2 = 'index', opts = api_opts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>label</th>\n",
       "      <th>fileid_api_count</th>\n",
       "      <th>fileid_api_nunique</th>\n",
       "      <th>fileid_tid_count</th>\n",
       "      <th>fileid_tid_nunique</th>\n",
       "      <th>fileid_tid_max</th>\n",
       "      <th>fileid_tid_min</th>\n",
       "      <th>fileid_tid_median</th>\n",
       "      <th>fileid_tid_std</th>\n",
       "      <th>...</th>\n",
       "      <th>fileid_api_index_std_recv</th>\n",
       "      <th>fileid_api_index_std_recvfrom</th>\n",
       "      <th>fileid_api_index_std_select</th>\n",
       "      <th>fileid_api_index_std_send</th>\n",
       "      <th>fileid_api_index_std_sendto</th>\n",
       "      <th>fileid_api_index_std_setsockopt</th>\n",
       "      <th>fileid_api_index_std_shutdown</th>\n",
       "      <th>fileid_api_index_std_socket</th>\n",
       "      <th>fileid_api_index_std_system</th>\n",
       "      <th>fileid_api_index_std_timeGetTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>424</td>\n",
       "      <td>19</td>\n",
       "      <td>424</td>\n",
       "      <td>1</td>\n",
       "      <td>2644</td>\n",
       "      <td>2644</td>\n",
       "      <td>2644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2524</td>\n",
       "      <td>2524</td>\n",
       "      <td>2524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2516</td>\n",
       "      <td>2516</td>\n",
       "      <td>2516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2800</td>\n",
       "      <td>65</td>\n",
       "      <td>2800</td>\n",
       "      <td>5</td>\n",
       "      <td>2884</td>\n",
       "      <td>2508</td>\n",
       "      <td>2884</td>\n",
       "      <td>170.764080</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.193663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6832</td>\n",
       "      <td>78</td>\n",
       "      <td>6832</td>\n",
       "      <td>6</td>\n",
       "      <td>2968</td>\n",
       "      <td>2060</td>\n",
       "      <td>2820</td>\n",
       "      <td>48.861741</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1013.848858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_id  label  fileid_api_count  fileid_api_nunique  fileid_tid_count  \\\n",
       "0        0      0               424                  19               424   \n",
       "1        1      5                 2                   2                 2   \n",
       "2        2      5                34                  15                34   \n",
       "3        3      5              2800                  65              2800   \n",
       "4        4      5              6832                  78              6832   \n",
       "\n",
       "   fileid_tid_nunique  fileid_tid_max  fileid_tid_min  fileid_tid_median  \\\n",
       "0                   1            2644            2644               2644   \n",
       "1                   1            2524            2524               2524   \n",
       "2                   1            2516            2516               2516   \n",
       "3                   5            2884            2508               2884   \n",
       "4                   6            2968            2060               2820   \n",
       "\n",
       "   fileid_tid_std                ...                 \\\n",
       "0        0.000000                ...                  \n",
       "1        0.000000                ...                  \n",
       "2        0.000000                ...                  \n",
       "3      170.764080                ...                  \n",
       "4       48.861741                ...                  \n",
       "\n",
       "   fileid_api_index_std_recv  fileid_api_index_std_recvfrom  \\\n",
       "0                        NaN                            NaN   \n",
       "1                        NaN                            NaN   \n",
       "2                        NaN                            NaN   \n",
       "3                        NaN                            NaN   \n",
       "4                        NaN                            NaN   \n",
       "\n",
       "   fileid_api_index_std_select  fileid_api_index_std_send  \\\n",
       "0                          NaN                        NaN   \n",
       "1                          NaN                        NaN   \n",
       "2                          NaN                        NaN   \n",
       "3                          NaN                        NaN   \n",
       "4                          NaN                        NaN   \n",
       "\n",
       "   fileid_api_index_std_sendto  fileid_api_index_std_setsockopt  \\\n",
       "0                          NaN                              NaN   \n",
       "1                          NaN                              NaN   \n",
       "2                          NaN                              NaN   \n",
       "3                          NaN                              NaN   \n",
       "4                          NaN                              NaN   \n",
       "\n",
       "   fileid_api_index_std_shutdown  fileid_api_index_std_socket  \\\n",
       "0                            NaN                          NaN   \n",
       "1                            NaN                          NaN   \n",
       "2                            NaN                          NaN   \n",
       "3                            NaN                    24.193663   \n",
       "4                            NaN                  1013.848858   \n",
       "\n",
       "   fileid_api_index_std_system  fileid_api_index_std_timeGetTime  \n",
       "0                          NaN                               NaN  \n",
       "1                          NaN                               NaN  \n",
       "2                          NaN                               NaN  \n",
       "3                          NaN                               NaN  \n",
       "4                          NaN                               NaN  \n",
       "\n",
       "[5 rows x 2180 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1阶特征的线下验证(File_id + Api)（<font color=red>0.0347293</font>）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File_id + Index  \n",
    "- File_id + Index (api): count,nunique\n",
    "- File_id + Index (return value): nunique, max, min, median, std(暂时先搁置)\n",
    "- File_id + Index (tid):  nunique, max, min, median, std(暂时先搁置)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File_id +Tid (api): count,nunique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File_id + Index特征过拟合，删除\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# delcol = []\n",
    "# for i in range(2):\n",
    "#     for item in groupby_features2[i]:\n",
    "#         delcol.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_.drop(delcol,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征补充（加入index的差值特征）\n",
    "- File_id + Api (index_diff): 'nunique','max','min','median','std'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_diff = train.groupby(['file_id','tid'])['index'].diff().fillna(-999).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['index_diff'] = train_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_diff = train.loc[train.index_diff!=-999] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunique\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max\n",
      "min\n",
      "median\n",
      "std\n"
     ]
    }
   ],
   "source": [
    "api_opts = ['nunique','max','min','median','std']\n",
    "train_data_,groupby_features = groupby_pivot_features(train_data_, train_diff, groupby_features, col1 = 'api', col2 = 'index_diff', opts = api_opts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116624, 3718)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_logloss(preds,data):\n",
    "    labels_ = data.get_label()\n",
    "    classes_ = np.unique(labels_) \n",
    "    preds_prob = []\n",
    "    for i in range(len(classes_)):\n",
    "        preds_prob.append(preds[i*len(labels_):(i+1) * len(labels_)])\n",
    "    preds_prob_ = np.vstack(preds_prob) \n",
    "    \n",
    "    loss = [] \n",
    "    for i in range(preds_prob_.shape[1]):  # 样本个数\n",
    "        sum_ = 0  \n",
    "        for j in range(preds_prob_.shape[0]): #类别个数\n",
    "            pred = preds_prob_[j,i] # 第i个样本预测为第j类的概率\n",
    "            if  j == labels_[i]:\n",
    "                sum_ += np.log(pred)\n",
    "            else:\n",
    "                sum_ += np.log(1 - pred) \n",
    "             \n",
    "        loss.append(sum_)  \n",
    "         \n",
    "    return 'loss is: ' ,-1 * (np.sum(loss) / preds_prob_.shape[1]),False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线下验证(<font color=red>0.0346954</font>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_logloss: 1.64633\ttraining's loss is: : 2.52671\tvalid_1's multi_logloss: 1.64655\tvalid_1's loss is: : 2.52698\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's multi_logloss: 1.52161\ttraining's loss is: : 2.37151\tvalid_1's multi_logloss: 1.52201\tvalid_1's loss is: : 2.372\n",
      "[3]\ttraining's multi_logloss: 1.41271\ttraining's loss is: : 2.23286\tvalid_1's multi_logloss: 1.41328\tvalid_1's loss is: : 2.23357\n",
      "[4]\ttraining's multi_logloss: 1.31623\ttraining's loss is: : 2.10733\tvalid_1's multi_logloss: 1.31698\tvalid_1's loss is: : 2.10827\n",
      "[5]\ttraining's multi_logloss: 1.2298\ttraining's loss is: : 1.99255\tvalid_1's multi_logloss: 1.23069\tvalid_1's loss is: : 1.99366\n",
      "[6]\ttraining's multi_logloss: 1.15164\ttraining's loss is: : 1.88668\tvalid_1's multi_logloss: 1.15263\tvalid_1's loss is: : 1.88795\n",
      "[7]\ttraining's multi_logloss: 1.08064\ttraining's loss is: : 1.78872\tvalid_1's multi_logloss: 1.08177\tvalid_1's loss is: : 1.79017\n",
      "[8]\ttraining's multi_logloss: 1.01556\ttraining's loss is: : 1.69732\tvalid_1's multi_logloss: 1.01684\tvalid_1's loss is: : 1.69898\n",
      "[9]\ttraining's multi_logloss: 0.955712\ttraining's loss is: : 1.61183\tvalid_1's multi_logloss: 0.957103\tvalid_1's loss is: : 1.61365\n",
      "[10]\ttraining's multi_logloss: 0.900525\ttraining's loss is: : 1.53173\tvalid_1's multi_logloss: 0.902028\tvalid_1's loss is: : 1.53371\n",
      "[11]\ttraining's multi_logloss: 0.849409\ttraining's loss is: : 1.45639\tvalid_1's multi_logloss: 0.851048\tvalid_1's loss is: : 1.45857\n",
      "[12]\ttraining's multi_logloss: 0.801944\ttraining's loss is: : 1.38541\tvalid_1's multi_logloss: 0.803709\tvalid_1's loss is: : 1.38776\n",
      "[13]\ttraining's multi_logloss: 0.75772\ttraining's loss is: : 1.31835\tvalid_1's multi_logloss: 0.759604\tvalid_1's loss is: : 1.32089\n",
      "[14]\ttraining's multi_logloss: 0.716449\ttraining's loss is: : 1.25494\tvalid_1's multi_logloss: 0.718444\tvalid_1's loss is: : 1.25765\n",
      "[15]\ttraining's multi_logloss: 0.677847\ttraining's loss is: : 1.19489\tvalid_1's multi_logloss: 0.679965\tvalid_1's loss is: : 1.19778\n",
      "[16]\ttraining's multi_logloss: 0.64171\ttraining's loss is: : 1.138\tvalid_1's multi_logloss: 0.643957\tvalid_1's loss is: : 1.14108\n",
      "[17]\ttraining's multi_logloss: 0.607853\ttraining's loss is: : 1.08408\tvalid_1's multi_logloss: 0.610219\tvalid_1's loss is: : 1.08734\n",
      "[18]\ttraining's multi_logloss: 0.576078\ttraining's loss is: : 1.03293\tvalid_1's multi_logloss: 0.578569\tvalid_1's loss is: : 1.03638\n",
      "[19]\ttraining's multi_logloss: 0.546199\ttraining's loss is: : 0.984329\tvalid_1's multi_logloss: 0.548831\tvalid_1's loss is: : 0.988002\n",
      "[20]\ttraining's multi_logloss: 0.518101\ttraining's loss is: : 0.938174\tvalid_1's multi_logloss: 0.520864\tvalid_1's loss is: : 0.94205\n",
      "[21]\ttraining's multi_logloss: 0.491603\ttraining's loss is: : 0.89425\tvalid_1's multi_logloss: 0.494477\tvalid_1's loss is: : 0.898304\n",
      "[22]\ttraining's multi_logloss: 0.466649\ttraining's loss is: : 0.852509\tvalid_1's multi_logloss: 0.469648\tvalid_1's loss is: : 0.85676\n",
      "[23]\ttraining's multi_logloss: 0.443096\ttraining's loss is: : 0.812785\tvalid_1's multi_logloss: 0.446203\tvalid_1's loss is: : 0.817213\n",
      "[24]\ttraining's multi_logloss: 0.420879\ttraining's loss is: : 0.775011\tvalid_1's multi_logloss: 0.424096\tvalid_1's loss is: : 0.779619\n",
      "[25]\ttraining's multi_logloss: 0.399878\ttraining's loss is: : 0.739031\tvalid_1's multi_logloss: 0.403214\tvalid_1's loss is: : 0.743839\n",
      "[26]\ttraining's multi_logloss: 0.380044\ttraining's loss is: : 0.704806\tvalid_1's multi_logloss: 0.383488\tvalid_1's loss is: : 0.709797\n",
      "[27]\ttraining's multi_logloss: 0.361285\ttraining's loss is: : 0.672213\tvalid_1's multi_logloss: 0.364837\tvalid_1's loss is: : 0.677389\n",
      "[28]\ttraining's multi_logloss: 0.343528\ttraining's loss is: : 0.641159\tvalid_1's multi_logloss: 0.347181\tvalid_1's loss is: : 0.646513\n",
      "[29]\ttraining's multi_logloss: 0.326724\ttraining's loss is: : 0.611587\tvalid_1's multi_logloss: 0.33047\tvalid_1's loss is: : 0.617101\n",
      "[30]\ttraining's multi_logloss: 0.310806\ttraining's loss is: : 0.583411\tvalid_1's multi_logloss: 0.314644\tvalid_1's loss is: : 0.589085\n",
      "[31]\ttraining's multi_logloss: 0.295743\ttraining's loss is: : 0.556596\tvalid_1's multi_logloss: 0.299673\tvalid_1's loss is: : 0.562431\n",
      "[32]\ttraining's multi_logloss: 0.281463\ttraining's loss is: : 0.53104\tvalid_1's multi_logloss: 0.285518\tvalid_1's loss is: : 0.537085\n",
      "[33]\ttraining's multi_logloss: 0.267919\ttraining's loss is: : 0.506678\tvalid_1's multi_logloss: 0.272074\tvalid_1's loss is: : 0.512902\n",
      "[34]\ttraining's multi_logloss: 0.255074\ttraining's loss is: : 0.483465\tvalid_1's multi_logloss: 0.259357\tvalid_1's loss is: : 0.489909\n",
      "[35]\ttraining's multi_logloss: 0.242904\ttraining's loss is: : 0.461365\tvalid_1's multi_logloss: 0.247286\tvalid_1's loss is: : 0.467981\n",
      "[36]\ttraining's multi_logloss: 0.231341\ttraining's loss is: : 0.440282\tvalid_1's multi_logloss: 0.235842\tvalid_1's loss is: : 0.447101\n",
      "[37]\ttraining's multi_logloss: 0.220368\ttraining's loss is: : 0.420191\tvalid_1's multi_logloss: 0.224985\tvalid_1's loss is: : 0.427215\n",
      "[38]\ttraining's multi_logloss: 0.209958\ttraining's loss is: : 0.401058\tvalid_1's multi_logloss: 0.21468\tvalid_1's loss is: : 0.408262\n",
      "[39]\ttraining's multi_logloss: 0.20007\ttraining's loss is: : 0.382817\tvalid_1's multi_logloss: 0.204904\tvalid_1's loss is: : 0.390214\n",
      "[40]\ttraining's multi_logloss: 0.190689\ttraining's loss is: : 0.365451\tvalid_1's multi_logloss: 0.195634\tvalid_1's loss is: : 0.373046\n",
      "[41]\ttraining's multi_logloss: 0.181767\ttraining's loss is: : 0.34888\tvalid_1's multi_logloss: 0.186791\tvalid_1's loss is: : 0.356619\n",
      "[42]\ttraining's multi_logloss: 0.173291\ttraining's loss is: : 0.333088\tvalid_1's multi_logloss: 0.178439\tvalid_1's loss is: : 0.341041\n",
      "[43]\ttraining's multi_logloss: 0.165235\ttraining's loss is: : 0.318034\tvalid_1's multi_logloss: 0.170502\tvalid_1's loss is: : 0.326192\n",
      "[44]\ttraining's multi_logloss: 0.157585\ttraining's loss is: : 0.303698\tvalid_1's multi_logloss: 0.162977\tvalid_1's loss is: : 0.312073\n",
      "[45]\ttraining's multi_logloss: 0.150314\ttraining's loss is: : 0.290032\tvalid_1's multi_logloss: 0.1558\tvalid_1's loss is: : 0.298578\n",
      "[46]\ttraining's multi_logloss: 0.143392\ttraining's loss is: : 0.276995\tvalid_1's multi_logloss: 0.14899\tvalid_1's loss is: : 0.285736\n",
      "[47]\ttraining's multi_logloss: 0.136807\ttraining's loss is: : 0.264561\tvalid_1's multi_logloss: 0.142537\tvalid_1's loss is: : 0.27353\n",
      "[48]\ttraining's multi_logloss: 0.130539\ttraining's loss is: : 0.252697\tvalid_1's multi_logloss: 0.136387\tvalid_1's loss is: : 0.261878\n",
      "[49]\ttraining's multi_logloss: 0.124574\ttraining's loss is: : 0.241388\tvalid_1's multi_logloss: 0.130541\tvalid_1's loss is: : 0.250774\n",
      "[50]\ttraining's multi_logloss: 0.118897\ttraining's loss is: : 0.230599\tvalid_1's multi_logloss: 0.124991\tvalid_1's loss is: : 0.240212\n",
      "[51]\ttraining's multi_logloss: 0.113498\ttraining's loss is: : 0.220322\tvalid_1's multi_logloss: 0.119705\tvalid_1's loss is: : 0.230133\n",
      "[52]\ttraining's multi_logloss: 0.108362\ttraining's loss is: : 0.210525\tvalid_1's multi_logloss: 0.114686\tvalid_1's loss is: : 0.220545\n",
      "[53]\ttraining's multi_logloss: 0.103472\ttraining's loss is: : 0.201183\tvalid_1's multi_logloss: 0.109912\tvalid_1's loss is: : 0.211409\n",
      "[54]\ttraining's multi_logloss: 0.0988135\ttraining's loss is: : 0.192268\tvalid_1's multi_logloss: 0.105365\tvalid_1's loss is: : 0.202699\n",
      "[55]\ttraining's multi_logloss: 0.0943984\ttraining's loss is: : 0.183803\tvalid_1's multi_logloss: 0.101053\tvalid_1's loss is: : 0.19442\n",
      "[56]\ttraining's multi_logloss: 0.0901761\ttraining's loss is: : 0.175701\tvalid_1's multi_logloss: 0.0969599\tvalid_1's loss is: : 0.186552\n",
      "[57]\ttraining's multi_logloss: 0.0861564\ttraining's loss is: : 0.167977\tvalid_1's multi_logloss: 0.0930648\tvalid_1's loss is: : 0.179056\n",
      "[58]\ttraining's multi_logloss: 0.0823221\ttraining's loss is: : 0.160599\tvalid_1's multi_logloss: 0.0893505\tvalid_1's loss is: : 0.171897\n",
      "[59]\ttraining's multi_logloss: 0.0786782\ttraining's loss is: : 0.153577\tvalid_1's multi_logloss: 0.0858427\tvalid_1's loss is: : 0.165119\n",
      "[60]\ttraining's multi_logloss: 0.0752069\ttraining's loss is: : 0.146883\tvalid_1's multi_logloss: 0.0824921\tvalid_1's loss is: : 0.158642\n",
      "[61]\ttraining's multi_logloss: 0.071895\ttraining's loss is: : 0.140487\tvalid_1's multi_logloss: 0.0792971\tvalid_1's loss is: : 0.152459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62]\ttraining's multi_logloss: 0.0687329\ttraining's loss is: : 0.134376\tvalid_1's multi_logloss: 0.0762731\tvalid_1's loss is: : 0.146598\n",
      "[63]\ttraining's multi_logloss: 0.0657284\ttraining's loss is: : 0.128563\tvalid_1's multi_logloss: 0.0733965\tvalid_1's loss is: : 0.141017\n",
      "[64]\ttraining's multi_logloss: 0.0628502\ttraining's loss is: : 0.12299\tvalid_1's multi_logloss: 0.0706546\tvalid_1's loss is: : 0.135695\n",
      "[65]\ttraining's multi_logloss: 0.0601072\ttraining's loss is: : 0.117673\tvalid_1's multi_logloss: 0.0680478\tvalid_1's loss is: : 0.130625\n",
      "[66]\ttraining's multi_logloss: 0.0575026\ttraining's loss is: : 0.112621\tvalid_1's multi_logloss: 0.0655753\tvalid_1's loss is: : 0.125822\n",
      "[67]\ttraining's multi_logloss: 0.0550053\ttraining's loss is: : 0.107776\tvalid_1's multi_logloss: 0.0632257\tvalid_1's loss is: : 0.121253\n",
      "[68]\ttraining's multi_logloss: 0.0526268\ttraining's loss is: : 0.103156\tvalid_1's multi_logloss: 0.0609908\tvalid_1's loss is: : 0.116903\n",
      "[69]\ttraining's multi_logloss: 0.0503628\ttraining's loss is: : 0.0987579\tvalid_1's multi_logloss: 0.0588691\tvalid_1's loss is: : 0.112766\n",
      "[70]\ttraining's multi_logloss: 0.0481989\ttraining's loss is: : 0.0945495\tvalid_1's multi_logloss: 0.0568538\tvalid_1's loss is: : 0.108833\n",
      "[71]\ttraining's multi_logloss: 0.0461268\ttraining's loss is: : 0.0905187\tvalid_1's multi_logloss: 0.0549178\tvalid_1's loss is: : 0.105058\n",
      "[72]\ttraining's multi_logloss: 0.0441548\ttraining's loss is: : 0.0866783\tvalid_1's multi_logloss: 0.0530859\tvalid_1's loss is: : 0.101483\n",
      "[73]\ttraining's multi_logloss: 0.0422683\ttraining's loss is: : 0.083003\tvalid_1's multi_logloss: 0.0513426\tvalid_1's loss is: : 0.0980779\n",
      "[74]\ttraining's multi_logloss: 0.0404738\ttraining's loss is: : 0.079504\tvalid_1's multi_logloss: 0.0496952\tvalid_1's loss is: : 0.0948512\n",
      "[75]\ttraining's multi_logloss: 0.0387621\ttraining's loss is: : 0.0761652\tvalid_1's multi_logloss: 0.0481166\tvalid_1's loss is: : 0.0917652\n",
      "[76]\ttraining's multi_logloss: 0.0371271\ttraining's loss is: : 0.0729758\tvalid_1's multi_logloss: 0.0466239\tvalid_1's loss is: : 0.0888414\n",
      "[77]\ttraining's multi_logloss: 0.0355761\ttraining's loss is: : 0.0699469\tvalid_1's multi_logloss: 0.045192\tvalid_1's loss is: : 0.0860383\n",
      "[78]\ttraining's multi_logloss: 0.0340882\ttraining's loss is: : 0.0670403\tvalid_1's multi_logloss: 0.0438157\tvalid_1's loss is: : 0.0833556\n",
      "[79]\ttraining's multi_logloss: 0.0326656\ttraining's loss is: : 0.0642614\tvalid_1's multi_logloss: 0.0425043\tvalid_1's loss is: : 0.0807954\n",
      "[80]\ttraining's multi_logloss: 0.031313\ttraining's loss is: : 0.0616173\tvalid_1's multi_logloss: 0.0412557\tvalid_1's loss is: : 0.0783598\n",
      "[81]\ttraining's multi_logloss: 0.0300058\ttraining's loss is: : 0.0590637\tvalid_1's multi_logloss: 0.040072\tvalid_1's loss is: : 0.0760438\n",
      "[82]\ttraining's multi_logloss: 0.0287568\ttraining's loss is: : 0.0566239\tvalid_1's multi_logloss: 0.0389494\tvalid_1's loss is: : 0.0738483\n",
      "[83]\ttraining's multi_logloss: 0.0275593\ttraining's loss is: : 0.0542842\tvalid_1's multi_logloss: 0.0378834\tvalid_1's loss is: : 0.0717564\n",
      "[84]\ttraining's multi_logloss: 0.0264099\ttraining's loss is: : 0.0520368\tvalid_1's multi_logloss: 0.0368611\tvalid_1's loss is: : 0.0697561\n",
      "[85]\ttraining's multi_logloss: 0.0253221\ttraining's loss is: : 0.0499081\tvalid_1's multi_logloss: 0.0358893\tvalid_1's loss is: : 0.067856\n",
      "[86]\ttraining's multi_logloss: 0.0242739\ttraining's loss is: : 0.0478564\tvalid_1's multi_logloss: 0.0349673\tvalid_1's loss is: : 0.0660542\n",
      "[87]\ttraining's multi_logloss: 0.023272\ttraining's loss is: : 0.0458955\tvalid_1's multi_logloss: 0.0340842\tvalid_1's loss is: : 0.0643366\n",
      "[88]\ttraining's multi_logloss: 0.0223094\ttraining's loss is: : 0.0440102\tvalid_1's multi_logloss: 0.0332447\tvalid_1's loss is: : 0.0627009\n",
      "[89]\ttraining's multi_logloss: 0.0213818\ttraining's loss is: : 0.0421939\tvalid_1's multi_logloss: 0.032461\tvalid_1's loss is: : 0.061164\n",
      "[90]\ttraining's multi_logloss: 0.0205027\ttraining's loss is: : 0.0404716\tvalid_1's multi_logloss: 0.031684\tvalid_1's loss is: : 0.0596523\n",
      "[91]\ttraining's multi_logloss: 0.0196515\ttraining's loss is: : 0.0388028\tvalid_1's multi_logloss: 0.0309749\tvalid_1's loss is: : 0.0582623\n",
      "[92]\ttraining's multi_logloss: 0.0188384\ttraining's loss is: : 0.0372086\tvalid_1's multi_logloss: 0.0302862\tvalid_1's loss is: : 0.0569167\n",
      "[93]\ttraining's multi_logloss: 0.0180592\ttraining's loss is: : 0.0356806\tvalid_1's multi_logloss: 0.0296375\tvalid_1's loss is: : 0.0556484\n",
      "[94]\ttraining's multi_logloss: 0.0173175\ttraining's loss is: : 0.0342245\tvalid_1's multi_logloss: 0.029018\tvalid_1's loss is: : 0.0544342\n",
      "[95]\ttraining's multi_logloss: 0.0166035\ttraining's loss is: : 0.0328229\tvalid_1's multi_logloss: 0.028433\tvalid_1's loss is: : 0.0532888\n",
      "[96]\ttraining's multi_logloss: 0.0159276\ttraining's loss is: : 0.0314949\tvalid_1's multi_logloss: 0.0278808\tvalid_1's loss is: : 0.0522\n",
      "[97]\ttraining's multi_logloss: 0.0152759\ttraining's loss is: : 0.0302137\tvalid_1's multi_logloss: 0.0273549\tvalid_1's loss is: : 0.0511684\n",
      "[98]\ttraining's multi_logloss: 0.0146612\ttraining's loss is: : 0.0290043\tvalid_1's multi_logloss: 0.0268579\tvalid_1's loss is: : 0.0501923\n",
      "[99]\ttraining's multi_logloss: 0.0140698\ttraining's loss is: : 0.0278406\tvalid_1's multi_logloss: 0.0263986\tvalid_1's loss is: : 0.0492886\n",
      "[100]\ttraining's multi_logloss: 0.0135\ttraining's loss is: : 0.0267198\tvalid_1's multi_logloss: 0.0259641\tvalid_1's loss is: : 0.0484358\n",
      "[101]\ttraining's multi_logloss: 0.0129561\ttraining's loss is: : 0.025649\tvalid_1's multi_logloss: 0.0255601\tvalid_1's loss is: : 0.0476413\n",
      "[102]\ttraining's multi_logloss: 0.0124387\ttraining's loss is: : 0.0246299\tvalid_1's multi_logloss: 0.0251671\tvalid_1's loss is: : 0.0468715\n",
      "[103]\ttraining's multi_logloss: 0.0119403\ttraining's loss is: : 0.023648\tvalid_1's multi_logloss: 0.0247907\tvalid_1's loss is: : 0.0461299\n",
      "[104]\ttraining's multi_logloss: 0.0114649\ttraining's loss is: : 0.0227109\tvalid_1's multi_logloss: 0.0244385\tvalid_1's loss is: : 0.0454326\n",
      "[105]\ttraining's multi_logloss: 0.011007\ttraining's loss is: : 0.021808\tvalid_1's multi_logloss: 0.0241016\tvalid_1's loss is: : 0.0447731\n",
      "[106]\ttraining's multi_logloss: 0.0105616\ttraining's loss is: : 0.0209305\tvalid_1's multi_logloss: 0.0237754\tvalid_1's loss is: : 0.0441378\n",
      "[107]\ttraining's multi_logloss: 0.0101364\ttraining's loss is: : 0.0200928\tvalid_1's multi_logloss: 0.023482\tvalid_1's loss is: : 0.0435618\n",
      "[108]\ttraining's multi_logloss: 0.00972881\ttraining's loss is: : 0.0192893\tvalid_1's multi_logloss: 0.0231891\tvalid_1's loss is: : 0.0429897\n",
      "[109]\ttraining's multi_logloss: 0.00933933\ttraining's loss is: : 0.0185212\tvalid_1's multi_logloss: 0.0229221\tvalid_1's loss is: : 0.0424688\n",
      "[110]\ttraining's multi_logloss: 0.00896654\ttraining's loss is: : 0.0177854\tvalid_1's multi_logloss: 0.0226638\tvalid_1's loss is: : 0.0419645\n",
      "[111]\ttraining's multi_logloss: 0.00861566\ttraining's loss is: : 0.0170928\tvalid_1's multi_logloss: 0.0224238\tvalid_1's loss is: : 0.0414913\n",
      "[112]\ttraining's multi_logloss: 0.00827793\ttraining's loss is: : 0.0164259\tvalid_1's multi_logloss: 0.0222027\tvalid_1's loss is: : 0.0410536\n",
      "[113]\ttraining's multi_logloss: 0.00795379\ttraining's loss is: : 0.0157857\tvalid_1's multi_logloss: 0.0219921\tvalid_1's loss is: : 0.0406398\n",
      "[114]\ttraining's multi_logloss: 0.00764293\ttraining's loss is: : 0.0151713\tvalid_1's multi_logloss: 0.0217989\tvalid_1's loss is: : 0.0402627\n",
      "[115]\ttraining's multi_logloss: 0.00735041\ttraining's loss is: : 0.0145931\tvalid_1's multi_logloss: 0.0216148\tvalid_1's loss is: : 0.0398999\n",
      "[116]\ttraining's multi_logloss: 0.00705842\ttraining's loss is: : 0.0140161\tvalid_1's multi_logloss: 0.0214524\tvalid_1's loss is: : 0.0395772\n",
      "[117]\ttraining's multi_logloss: 0.00677849\ttraining's loss is: : 0.0134628\tvalid_1's multi_logloss: 0.0212838\tvalid_1's loss is: : 0.0392494\n",
      "[118]\ttraining's multi_logloss: 0.00651271\ttraining's loss is: : 0.0129371\tvalid_1's multi_logloss: 0.0211286\tvalid_1's loss is: : 0.038946\n",
      "[119]\ttraining's multi_logloss: 0.00625575\ttraining's loss is: : 0.0124289\tvalid_1's multi_logloss: 0.0209864\tvalid_1's loss is: : 0.0386731\n",
      "[120]\ttraining's multi_logloss: 0.00601566\ttraining's loss is: : 0.0119537\tvalid_1's multi_logloss: 0.0208462\tvalid_1's loss is: : 0.0384006\n",
      "[121]\ttraining's multi_logloss: 0.0057775\ttraining's loss is: : 0.0114824\tvalid_1's multi_logloss: 0.0207075\tvalid_1's loss is: : 0.0381312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[122]\ttraining's multi_logloss: 0.00554634\ttraining's loss is: : 0.011025\tvalid_1's multi_logloss: 0.0206035\tvalid_1's loss is: : 0.0379255\n",
      "[123]\ttraining's multi_logloss: 0.00532893\ttraining's loss is: : 0.0105945\tvalid_1's multi_logloss: 0.0204957\tvalid_1's loss is: : 0.0377147\n",
      "[124]\ttraining's multi_logloss: 0.00512331\ttraining's loss is: : 0.0101872\tvalid_1's multi_logloss: 0.0204113\tvalid_1's loss is: : 0.0375447\n",
      "[125]\ttraining's multi_logloss: 0.00493127\ttraining's loss is: : 0.00980648\tvalid_1's multi_logloss: 0.0203189\tvalid_1's loss is: : 0.0373628\n",
      "[126]\ttraining's multi_logloss: 0.00474015\ttraining's loss is: : 0.00942797\tvalid_1's multi_logloss: 0.0202194\tvalid_1's loss is: : 0.0371783\n",
      "[127]\ttraining's multi_logloss: 0.0045591\ttraining's loss is: : 0.00906936\tvalid_1's multi_logloss: 0.0201327\tvalid_1's loss is: : 0.0370164\n",
      "[128]\ttraining's multi_logloss: 0.00438636\ttraining's loss is: : 0.00872696\tvalid_1's multi_logloss: 0.0200431\tvalid_1's loss is: : 0.0368479\n",
      "[129]\ttraining's multi_logloss: 0.00422363\ttraining's loss is: : 0.00840428\tvalid_1's multi_logloss: 0.019978\tvalid_1's loss is: : 0.0367277\n",
      "[130]\ttraining's multi_logloss: 0.00406337\ttraining's loss is: : 0.00808642\tvalid_1's multi_logloss: 0.0199292\tvalid_1's loss is: : 0.036634\n",
      "[131]\ttraining's multi_logloss: 0.00390299\ttraining's loss is: : 0.00776854\tvalid_1's multi_logloss: 0.0198642\tvalid_1's loss is: : 0.03651\n",
      "[132]\ttraining's multi_logloss: 0.00374799\ttraining's loss is: : 0.00746121\tvalid_1's multi_logloss: 0.0198057\tvalid_1's loss is: : 0.036398\n",
      "[133]\ttraining's multi_logloss: 0.00360208\ttraining's loss is: : 0.00717178\tvalid_1's multi_logloss: 0.019743\tvalid_1's loss is: : 0.0362784\n",
      "[134]\ttraining's multi_logloss: 0.00346488\ttraining's loss is: : 0.00689952\tvalid_1's multi_logloss: 0.0196994\tvalid_1's loss is: : 0.036198\n",
      "[135]\ttraining's multi_logloss: 0.00333421\ttraining's loss is: : 0.00664015\tvalid_1's multi_logloss: 0.0196551\tvalid_1's loss is: : 0.0361097\n",
      "[136]\ttraining's multi_logloss: 0.00320902\ttraining's loss is: : 0.00639158\tvalid_1's multi_logloss: 0.0195995\tvalid_1's loss is: : 0.0360115\n",
      "[137]\ttraining's multi_logloss: 0.00308659\ttraining's loss is: : 0.0061485\tvalid_1's multi_logloss: 0.0195629\tvalid_1's loss is: : 0.0359444\n",
      "[138]\ttraining's multi_logloss: 0.00297163\ttraining's loss is: : 0.00592014\tvalid_1's multi_logloss: 0.0195414\tvalid_1's loss is: : 0.0359081\n",
      "[139]\ttraining's multi_logloss: 0.00285996\ttraining's loss is: : 0.00569832\tvalid_1's multi_logloss: 0.0195318\tvalid_1's loss is: : 0.0358953\n",
      "[140]\ttraining's multi_logloss: 0.00275591\ttraining's loss is: : 0.00549151\tvalid_1's multi_logloss: 0.0194943\tvalid_1's loss is: : 0.0358295\n",
      "[141]\ttraining's multi_logloss: 0.00265646\ttraining's loss is: : 0.00529382\tvalid_1's multi_logloss: 0.019472\tvalid_1's loss is: : 0.0357882\n",
      "[142]\ttraining's multi_logloss: 0.00256074\ttraining's loss is: : 0.00510353\tvalid_1's multi_logloss: 0.0194653\tvalid_1's loss is: : 0.0357737\n",
      "[143]\ttraining's multi_logloss: 0.00246681\ttraining's loss is: : 0.00491677\tvalid_1's multi_logloss: 0.0194641\tvalid_1's loss is: : 0.0357728\n",
      "[144]\ttraining's multi_logloss: 0.00237912\ttraining's loss is: : 0.00474234\tvalid_1's multi_logloss: 0.0194609\tvalid_1's loss is: : 0.0357663\n",
      "[145]\ttraining's multi_logloss: 0.0022936\ttraining's loss is: : 0.00457225\tvalid_1's multi_logloss: 0.0194618\tvalid_1's loss is: : 0.0357727\n",
      "[146]\ttraining's multi_logloss: 0.00220973\ttraining's loss is: : 0.00440538\tvalid_1's multi_logloss: 0.019476\tvalid_1's loss is: : 0.0358013\n",
      "[147]\ttraining's multi_logloss: 0.00213018\ttraining's loss is: : 0.00424711\tvalid_1's multi_logloss: 0.019481\tvalid_1's loss is: : 0.0358144\n",
      "[148]\ttraining's multi_logloss: 0.00205226\ttraining's loss is: : 0.00409207\tvalid_1's multi_logloss: 0.0194935\tvalid_1's loss is: : 0.0358435\n",
      "[149]\ttraining's multi_logloss: 0.00197799\ttraining's loss is: : 0.00394424\tvalid_1's multi_logloss: 0.019497\tvalid_1's loss is: : 0.0358521\n",
      "[150]\ttraining's multi_logloss: 0.00190657\ttraining's loss is: : 0.00380209\tvalid_1's multi_logloss: 0.0195202\tvalid_1's loss is: : 0.0358982\n",
      "[151]\ttraining's multi_logloss: 0.00183819\ttraining's loss is: : 0.00366597\tvalid_1's multi_logloss: 0.0195537\tvalid_1's loss is: : 0.0359639\n",
      "[152]\ttraining's multi_logloss: 0.00177184\ttraining's loss is: : 0.00353386\tvalid_1's multi_logloss: 0.0195846\tvalid_1's loss is: : 0.0360264\n",
      "[153]\ttraining's multi_logloss: 0.0017106\ttraining's loss is: : 0.00341189\tvalid_1's multi_logloss: 0.0196358\tvalid_1's loss is: : 0.0361274\n",
      "[154]\ttraining's multi_logloss: 0.00165175\ttraining's loss is: : 0.00329465\tvalid_1's multi_logloss: 0.0196746\tvalid_1's loss is: : 0.0362032\n",
      "[155]\ttraining's multi_logloss: 0.00159522\ttraining's loss is: : 0.00318205\tvalid_1's multi_logloss: 0.0197236\tvalid_1's loss is: : 0.0362982\n",
      "[156]\ttraining's multi_logloss: 0.00154028\ttraining's loss is: : 0.00307264\tvalid_1's multi_logloss: 0.0197677\tvalid_1's loss is: : 0.0363827\n",
      "[157]\ttraining's multi_logloss: 0.00148667\ttraining's loss is: : 0.00296589\tvalid_1's multi_logloss: 0.0198037\tvalid_1's loss is: : 0.0364549\n",
      "[158]\ttraining's multi_logloss: 0.00143684\ttraining's loss is: : 0.00286661\tvalid_1's multi_logloss: 0.0198484\tvalid_1's loss is: : 0.0365413\n",
      "[159]\ttraining's multi_logloss: 0.00138975\ttraining's loss is: : 0.00277281\tvalid_1's multi_logloss: 0.0198862\tvalid_1's loss is: : 0.0366185\n",
      "[160]\ttraining's multi_logloss: 0.00134581\ttraining's loss is: : 0.00268526\tvalid_1's multi_logloss: 0.0199304\tvalid_1's loss is: : 0.0367089\n",
      "[161]\ttraining's multi_logloss: 0.0013018\ttraining's loss is: : 0.00259757\tvalid_1's multi_logloss: 0.0199763\tvalid_1's loss is: : 0.036802\n",
      "[162]\ttraining's multi_logloss: 0.00125891\ttraining's loss is: : 0.00251212\tvalid_1's multi_logloss: 0.0200193\tvalid_1's loss is: : 0.0368898\n",
      "[163]\ttraining's multi_logloss: 0.00121824\ttraining's loss is: : 0.00243109\tvalid_1's multi_logloss: 0.0200632\tvalid_1's loss is: : 0.0369782\n",
      "[164]\ttraining's multi_logloss: 0.00117871\ttraining's loss is: : 0.00235231\tvalid_1's multi_logloss: 0.0201178\tvalid_1's loss is: : 0.0370864\n",
      "[165]\ttraining's multi_logloss: 0.00114113\ttraining's loss is: : 0.00227741\tvalid_1's multi_logloss: 0.0201695\tvalid_1's loss is: : 0.037189\n",
      "[166]\ttraining's multi_logloss: 0.00110318\ttraining's loss is: : 0.00220176\tvalid_1's multi_logloss: 0.020219\tvalid_1's loss is: : 0.0372904\n",
      "[167]\ttraining's multi_logloss: 0.00106672\ttraining's loss is: : 0.00212909\tvalid_1's multi_logloss: 0.0202702\tvalid_1's loss is: : 0.0373968\n",
      "[168]\ttraining's multi_logloss: 0.00103098\ttraining's loss is: : 0.00205785\tvalid_1's multi_logloss: 0.0203292\tvalid_1's loss is: : 0.037516\n",
      "[169]\ttraining's multi_logloss: 0.00099795\ttraining's loss is: : 0.001992\tvalid_1's multi_logloss: 0.020388\tvalid_1's loss is: : 0.0376318\n",
      "[170]\ttraining's multi_logloss: 0.000965997\ttraining's loss is: : 0.00192828\tvalid_1's multi_logloss: 0.0204416\tvalid_1's loss is: : 0.0377411\n",
      "[171]\ttraining's multi_logloss: 0.000932944\ttraining's loss is: : 0.0018624\tvalid_1's multi_logloss: 0.0204949\tvalid_1's loss is: : 0.0378465\n",
      "[172]\ttraining's multi_logloss: 0.000901667\ttraining's loss is: : 0.00180005\tvalid_1's multi_logloss: 0.0205606\tvalid_1's loss is: : 0.0379724\n",
      "[173]\ttraining's multi_logloss: 0.000873326\ttraining's loss is: : 0.00174354\tvalid_1's multi_logloss: 0.0206119\tvalid_1's loss is: : 0.0380718\n",
      "[174]\ttraining's multi_logloss: 0.000846103\ttraining's loss is: : 0.00168925\tvalid_1's multi_logloss: 0.0206784\tvalid_1's loss is: : 0.0382001\n",
      "[175]\ttraining's multi_logloss: 0.000820333\ttraining's loss is: : 0.00163786\tvalid_1's multi_logloss: 0.0207375\tvalid_1's loss is: : 0.0383214\n",
      "[176]\ttraining's multi_logloss: 0.00079422\ttraining's loss is: : 0.00158577\tvalid_1's multi_logloss: 0.0207992\tvalid_1's loss is: : 0.0384486\n",
      "[177]\ttraining's multi_logloss: 0.000768722\ttraining's loss is: : 0.00153491\tvalid_1's multi_logloss: 0.0208676\tvalid_1's loss is: : 0.0385899\n",
      "[178]\ttraining's multi_logloss: 0.000744712\ttraining's loss is: : 0.00148702\tvalid_1's multi_logloss: 0.0209377\tvalid_1's loss is: : 0.038731\n",
      "[179]\ttraining's multi_logloss: 0.00072256\ttraining's loss is: : 0.00144282\tvalid_1's multi_logloss: 0.0209974\tvalid_1's loss is: : 0.0388535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[180]\ttraining's multi_logloss: 0.000701126\ttraining's loss is: : 0.00140006\tvalid_1's multi_logloss: 0.0210788\tvalid_1's loss is: : 0.0390168\n",
      "[181]\ttraining's multi_logloss: 0.000680197\ttraining's loss is: : 0.00135831\tvalid_1's multi_logloss: 0.0211467\tvalid_1's loss is: : 0.0391498\n",
      "[182]\ttraining's multi_logloss: 0.000660359\ttraining's loss is: : 0.00131873\tvalid_1's multi_logloss: 0.0212092\tvalid_1's loss is: : 0.0392737\n",
      "[183]\ttraining's multi_logloss: 0.000639805\ttraining's loss is: : 0.00127772\tvalid_1's multi_logloss: 0.0212881\tvalid_1's loss is: : 0.0394297\n",
      "[184]\ttraining's multi_logloss: 0.000623048\ttraining's loss is: : 0.00124428\tvalid_1's multi_logloss: 0.0213609\tvalid_1's loss is: : 0.0395699\n",
      "[185]\ttraining's multi_logloss: 0.000605285\ttraining's loss is: : 0.00120884\tvalid_1's multi_logloss: 0.0214198\tvalid_1's loss is: : 0.0396854\n",
      "[186]\ttraining's multi_logloss: 0.000588288\ttraining's loss is: : 0.00117492\tvalid_1's multi_logloss: 0.0214855\tvalid_1's loss is: : 0.0398139\n",
      "[187]\ttraining's multi_logloss: 0.000569791\ttraining's loss is: : 0.00113802\tvalid_1's multi_logloss: 0.0215605\tvalid_1's loss is: : 0.0399618\n",
      "[188]\ttraining's multi_logloss: 0.000553991\ttraining's loss is: : 0.00110649\tvalid_1's multi_logloss: 0.0216318\tvalid_1's loss is: : 0.0401034\n",
      "[189]\ttraining's multi_logloss: 0.000539173\ttraining's loss is: : 0.00107691\tvalid_1's multi_logloss: 0.0217041\tvalid_1's loss is: : 0.0402474\n",
      "[190]\ttraining's multi_logloss: 0.000524687\ttraining's loss is: : 0.001048\tvalid_1's multi_logloss: 0.0217822\tvalid_1's loss is: : 0.0404034\n",
      "[191]\ttraining's multi_logloss: 0.000510484\ttraining's loss is: : 0.00101966\tvalid_1's multi_logloss: 0.0218381\tvalid_1's loss is: : 0.0405178\n",
      "[192]\ttraining's multi_logloss: 0.000495866\ttraining's loss is: : 0.00099049\tvalid_1's multi_logloss: 0.0218964\tvalid_1's loss is: : 0.0406364\n",
      "[193]\ttraining's multi_logloss: 0.000481692\ttraining's loss is: : 0.0009622\tvalid_1's multi_logloss: 0.0219671\tvalid_1's loss is: : 0.0407784\n",
      "[194]\ttraining's multi_logloss: 0.000469608\ttraining's loss is: : 0.000938082\tvalid_1's multi_logloss: 0.0220439\tvalid_1's loss is: : 0.0409341\n",
      "Early stopping, best iteration is:\n",
      "[144]\ttraining's multi_logloss: 0.00237912\ttraining's loss is: : 0.00474234\tvalid_1's multi_logloss: 0.0194609\tvalid_1's loss is: : 0.0357663\n"
     ]
    }
   ],
   "source": [
    "train_features = [col for col in train_data_.columns if col!='label' and col!='file_id']\n",
    "train_label = 'label'\n",
    "\n",
    "#print(len(train_features))\n",
    "#runXGB(train_data_.loc[train_ind,train_features],train_data_.loc[train_ind,train_label].values,train_data_.loc[test_ind,train_features],train_data_.loc[test_ind,train_label].values)\n",
    "dtrain = lgb.Dataset(train_data_.loc[train_ind,train_features],train_data_.loc[train_ind,train_label].values) \n",
    "dval   = lgb.Dataset(train_data_.loc[test_ind,train_features],train_data_.loc[test_ind,train_label].values, reference = dtrain) \n",
    "\n",
    "params = {\n",
    "         'task':'train', \n",
    "         'num_leaves': 255,\n",
    "         'objective': 'multiclass',\n",
    "         'num_class':6,\n",
    "         'min_data_in_leaf': 40,\n",
    "         'learning_rate': 0.05,\n",
    "         'feature_fraction': 0.85,\n",
    "         'bagging_fraction': 0.9,\n",
    "         'bagging_freq': 5, \n",
    "         'max_bin':128,\n",
    "         'num_threads': 64,\n",
    "         'random_state':100\n",
    "     }  \n",
    "lgb_model_3_order = lgb.train(params, dtrain, num_boost_round=500,valid_sets=[dtrain,dval], early_stopping_rounds=50, feval=lgb_logloss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删除quantile,std统计变量之后的验证(<font color=red>0.0350054</font>)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_features = [col for col in train_data_.columns if col!='label' and col!='file_id' and 'std' not in col and 'quantile' not in col]\n",
    "# train_label = 'label'\n",
    "# print(len(train_features))\n",
    "# dtrain = lgb.Dataset(train_data_.loc[train_ind,train_features],train_data_.loc[train_ind,train_label].values) \n",
    "# dval   = lgb.Dataset(train_data_.loc[test_ind,train_features],train_data_.loc[test_ind,train_label].values, reference = dtrain) \n",
    "\n",
    "# params = {\n",
    "#         'task':'train', \n",
    "#         'num_leaves': 255,\n",
    "#         'objective': 'multiclass',\n",
    "#         'num_class':6,\n",
    "#         'min_data_in_leaf': 40,\n",
    "#         'learning_rate': 0.05,\n",
    "#         'feature_fraction': 0.85,\n",
    "#         'bagging_fraction': 0.9,\n",
    "#         'bagging_freq': 5, \n",
    "#         'max_bin':128,\n",
    "#         'num_threads': 64,\n",
    "#         'random_state':100\n",
    "#     }  \n",
    "# lgb_model_3_order = lgb.train(params, dtrain, num_boost_round=500,valid_sets=[dtrain,dval], early_stopping_rounds=50, feval=lgb_logloss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_.to_csv('/data/Data_JieZhang/TC_SAFE/train_val/train_data.csv',index = None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程& 验证结果 2-Gram\n",
    "## 全局特征\n",
    "### File_id（Api_2）:count,nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['api_shift'] = train['api'].shift(-1)\n",
    "train['api_2'] = train['api'] +'_' + train['api_shift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['api_shift'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "api_count = train['api_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunique\n"
     ]
    }
   ],
   "source": [
    "api_opt = ['count','nunique'] \n",
    "for opt in api_opt:\n",
    "    print(opt)\n",
    "    tmp = train.groupby(['file_id'])['api_2'].agg({'fileid_api_2_' + opt: opt}).reset_index() \n",
    "    train_data_ = pd.merge(train_data_,tmp,how='left', on='file_id')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 局部特征\n",
    "### File_id + tid (Api_2): count特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "api_value_counts = pd.DataFrame(api_count).reset_index()\n",
    "api_value_counts.columns = ['api_2','api_2_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, api_value_counts, on ='api_2' , how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_opts = ['count']\n",
    "groupby_features =  []\n",
    "train_data_,groupby_features = groupby_pivot_features(train_data_, train.loc[train.api_2_count>=20], groupby_features, col1 = 'api_2', col2 = 'tid', opts = api_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线下验证(<font color=red> 0.0330886</font>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = [col for col in train_data_.columns if col!='label' and col!='file_id']\n",
    "train_label = 'label'\n",
    "print(len(train_features))\n",
    "dtrain = lgb.Dataset(train_data_.loc[train_ind,train_features],train_data_.loc[train_ind,train_label].values) \n",
    "dval   = lgb.Dataset(train_data_.loc[test_ind,train_features],train_data_.loc[test_ind,train_label].values, reference = dtrain) \n",
    "\n",
    "params = {\n",
    "         'task':'train', \n",
    "         'num_leaves': 255,\n",
    "         'objective': 'multiclass',\n",
    "         'num_class':6,\n",
    "         'min_data_in_leaf': 40,\n",
    "         'learning_rate': 0.05,\n",
    "         'feature_fraction': 0.85,\n",
    "         'bagging_fraction': 0.9,\n",
    "         'bagging_freq': 5, \n",
    "         'max_bin':128,\n",
    "         'num_threads': 64,\n",
    "         'random_state':100\n",
    "     }  \n",
    "lgb_model_3_order = lgb.train(params, dtrain, num_boost_round=500,valid_sets=[dtrain,dval], early_stopping_rounds=50, feval=lgb_logloss)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File_id + index (Api_2): max,min特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_features = [col for col in train_data_.columns if col!='label' and col!='file_id']\n",
    "train_label = 'label'\n",
    "print(len(train_features))\n",
    "train_X, test_X, train_Y, test_Y = train_test_split( train_data_[train_features],train_data_[train_label].values, test_size = 0.33) \n",
    "\n",
    "dtrain = lgb.Dataset(train_X,train_Y) \n",
    "dval   = lgb.Dataset(test_X,test_Y, reference = dtrain) \n",
    "\n",
    "params = {\n",
    "        'task':'train', \n",
    "        'num_leaves': 255,\n",
    "        'objective': 'multiclass',\n",
    "        'num_class':8,\n",
    "        #'min_data_in_leaf': 40,\n",
    "        'min_data_in_leaf': 10,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.85,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 5, \n",
    "        'max_bin':128,\n",
    "        'num_threads': 64,\n",
    "        'random_state':100\n",
    "    }  \n",
    "lgb_model_3_order = lgb.train(params, dtrain, num_boost_round=500,valid_sets=[dtrain,dval], early_stopping_rounds=50, feval=lgb_logloss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_imp = pd.DataFrame({'feature':train_features, 'imp':lgb_model_3_order.feature_importance()}).sort_values('imp')\n",
    "important_features = fea_imp.loc[fea_imp.imp >=1, 'feature'].values\n",
    "important_features = list(important_features)\n",
    "\n",
    "important_features.append('file_id')\n",
    "important_features.append('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_[important_features].to_csv('../feature_final/train_data_2gram.csv',index = None)\n",
    "\n",
    "train_ind = train_X.index\n",
    "test_ind = test_X.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_opts = ['max','min']\n",
    "train_data_,groupby_features = groupby_pivot_features(train_data_[important_features], train.loc[train.api_2_count>=20], groupby_features, col1 = 'api_2', col2 = 'index', opts = api_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_features = [col for col in train_data_.columns if col!='label' and col!='file_id' and 'std' not in col and 'quantile' not in col]\n",
    "train_label = 'label'\n",
    "\n",
    "train_ind = train_X.index\n",
    "test_ind = test_X.index\n",
    "\n",
    "dtrain = lgb.Dataset(train_data_.loc[train_ind,train_features],train_data_.loc[train_ind,train_label].values) \n",
    "dval   = lgb.Dataset(train_data_.loc[test_ind,train_features],train_data_.loc[test_ind,train_label].values, reference = dtrain) \n",
    "\n",
    "params = {\n",
    "        'task':'train', \n",
    "        'num_leaves': 255,\n",
    "        'objective': 'multiclass',\n",
    "        'num_class':8,\n",
    "        'min_data_in_leaf': 10,\n",
    "        #'min_data_in_leaf': 1,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.85,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 5, \n",
    "        'max_bin':128,\n",
    "        'num_threads': 64,\n",
    "        'random_state':100\n",
    "    }  \n",
    "lgb_model_3_order = lgb.train(params, dtrain, num_boost_round=500,valid_sets=[dtrain,dval], early_stopping_rounds=50, feval=lgb_logloss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_imp = pd.DataFrame({'feature':train_features, 'imp':lgb_model_3_order.feature_importance()}).sort_values('imp')\n",
    "important_features = fea_imp.loc[fea_imp.imp >=1, 'feature'].values\n",
    "important_features = list(important_features)\n",
    "\n",
    "important_features.append('file_id')\n",
    "important_features.append('label')\n",
    "\n",
    "train_data_[important_features].to_csv('./train_data_2gram.csv',index = None)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 附录\n",
    "tf-idf的1Gram特征可以替换api的次数特征等，加入tf-idf有提升，提升较小"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
