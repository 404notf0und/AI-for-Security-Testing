{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 工具包导入&数据读取\n",
    "## 工具包导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import gc\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/admin/Aliyun/Alibaba-3rd-Security-Algorithm-Challenge-master'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读取\n",
    "- 为了方便分析，我们读取3000万条数据进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '../final_input/'\n",
    "# train = pd.read_csv(path + 'final_train.csv',nrows=1000000)\n",
    "# test = pd.read_csv(path + 'final_test.csv',nrows=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv('../train.csv')\n",
    "#test = pd.read_csv(path + 'final_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程 & 验证结果(1-Gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_id  label\n",
       "0           0      0\n",
       "424         1      5\n",
       "426         2      5\n",
       "460         3      5\n",
       "3260        4      5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train[['file_id','label']].drop_duplicates()\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    111545\n",
       "5      3397\n",
       "2       744\n",
       "3       598\n",
       "1       287\n",
       "4        53\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全局特征:\n",
    "- File_id (Api): count,nunique\n",
    "- File_id (Tid): count,nunique,max,min,quantile(20,40,50,60,80),std,range\n",
    "- File_id (Return Value): count,nunique,max,min,quantile(20,40,50,60,80),std,range\n",
    "- File_id (Index): count,nunique,max,min,quantile(20,40,50,60,80),std,range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File_id (Api): count,nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>label</th>\n",
       "      <th>api</th>\n",
       "      <th>tid</th>\n",
       "      <th>return_value</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GetSystemTimeAsFileTime</td>\n",
       "      <td>2644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NtAllocateVirtualMemory</td>\n",
       "      <td>2644</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NtFreeVirtualMemory</td>\n",
       "      <td>2644</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NtAllocateVirtualMemory</td>\n",
       "      <td>2644</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NtAllocateVirtualMemory</td>\n",
       "      <td>2644</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_id  label                      api   tid  return_value  index\n",
       "0        0      0  GetSystemTimeAsFileTime  2644             0      0\n",
       "1        0      0  NtAllocateVirtualMemory  2644             0      1\n",
       "2        0      0      NtFreeVirtualMemory  2644             0      2\n",
       "3        0      0  NtAllocateVirtualMemory  2644             0      3\n",
       "4        0      0  NtAllocateVirtualMemory  2644             0      4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunique\n"
     ]
    }
   ],
   "source": [
    "api_opt = ['count','nunique'] \n",
    "for opt in api_opt:\n",
    "    print(opt)\n",
    "    tmp = train.groupby(['file_id'])['api'].agg({'fileid_api_' + opt: opt}).reset_index() \n",
    "    train_data = pd.merge(train_data,tmp,how='left', on='file_id')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>label</th>\n",
       "      <th>fileid_api_count</th>\n",
       "      <th>fileid_api_nunique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>424</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2800</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6832</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_id  label  fileid_api_count  fileid_api_nunique\n",
       "0        0      0               424                  19\n",
       "1        1      5                 2                   2\n",
       "2        2      5                34                  15\n",
       "3        3      5              2800                  65\n",
       "4        4      5              6832                  78"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File_id (Tid): count,nunique,max,min,quantile(20,40,50,60,80),std,range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunique\n",
      "max\n",
      "min\n",
      "median\n",
      "std\n"
     ]
    }
   ],
   "source": [
    "tid_opt = ['count','nunique','max','min','median','std'] \n",
    "for opt in tid_opt:\n",
    "    print(opt)\n",
    "    tmp = train.groupby(['file_id'])['tid'].agg({'fileid_tid_' + opt: opt}).reset_index() \n",
    "    train_data = pd.merge(train_data,tmp,how='left', on='file_id') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "secs = [0.2,0.4,0.6,0.8]\n",
    "for sec in secs: \n",
    "    train_data['fileid_tid_quantile_' + str(sec * 100)] = train.groupby(['file_id'])['tid'].quantile(sec).values\n",
    " \n",
    "train_data['fileid_tid_range'] = train.groupby(['file_id'])['tid'].quantile(0.975).values - train.groupby(['file_id'])['tid'].quantile(0.0125).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File_id (Index): count,nunique,max,min,quantile(20,40,50,60,80),std,range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunique\n",
      "max\n",
      "min\n",
      "median\n",
      "std\n"
     ]
    }
   ],
   "source": [
    "index_opt = ['count','nunique','max','min','median','std'] \n",
    "for opt in index_opt:\n",
    "    print(opt)\n",
    "    tmp = train.groupby(['file_id'])['index'].agg({'fileid_index_' + opt: opt}).reset_index() \n",
    "    train_data = pd.merge(train_data,tmp,how='left', on='file_id') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "secs = [0.2,0.4,0.6,0.8]\n",
    "for sec in secs: \n",
    "    train_data['fileid_index_quantile_' + str(sec * 100)] = train.groupby(['file_id'])['index'].quantile(sec).values\n",
    " \n",
    "train_data['fileid_index_range'] = train.groupby(['file_id'])['index'].quantile(0.975).values - train.groupby(['file_id'])['index'].quantile(0.0125).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全局特征的线下验证 <font color=red>( 0.0969482)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 评估指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_logloss(preds,data):\n",
    "    labels_ = data.get_label()\n",
    "    classes_ = np.unique(labels_) \n",
    "    preds_prob = []\n",
    "    for i in range(len(classes_)):\n",
    "        preds_prob.append(preds[i*len(labels_):(i+1) * len(labels_)])\n",
    "    preds_prob_ = np.vstack(preds_prob) \n",
    "    \n",
    "    loss = [] \n",
    "    for i in range(preds_prob_.shape[1]):  # 样本个数\n",
    "        sum_ = 0  \n",
    "        for j in range(preds_prob_.shape[0]): #类别个数\n",
    "            pred = preds_prob_[j,i] # 第i个样本预测为第j类的概率\n",
    "            if  j == labels_[i]:\n",
    "                sum_ += np.log(pred)\n",
    "            else:\n",
    "                sum_ += np.log(1 - pred) \n",
    "             \n",
    "        loss.append(sum_)  \n",
    "         \n",
    "    return 'loss is: ' ,-1 * (np.sum(loss) / preds_prob_.shape[1]),False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练特征 & 标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = [col for col in train_data.columns if col!='label' and col!='file_id']\n",
    "train_label = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split( train_data[train_features],train_data[train_label].values, test_size = 0.33) \n",
    "#del _\n",
    "gc.collect()\n",
    "\n",
    "train_ind = train_X.index\n",
    "test_ind = test_X.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_logloss: 1.64923\ttraining's loss is: : 2.53026\tvalid_1's multi_logloss: 1.65107\tvalid_1's loss is: : 2.53251\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's multi_logloss: 1.52682\ttraining's loss is: : 2.37802\tvalid_1's multi_logloss: 1.53022\tvalid_1's loss is: : 2.3822\n",
      "[3]\ttraining's multi_logloss: 1.4199\ttraining's loss is: : 2.24201\tvalid_1's multi_logloss: 1.42483\tvalid_1's loss is: : 2.24816\n",
      "[4]\ttraining's multi_logloss: 1.32484\ttraining's loss is: : 2.11848\tvalid_1's multi_logloss: 1.33108\tvalid_1's loss is: : 2.12637\n",
      "[5]\ttraining's multi_logloss: 1.23958\ttraining's loss is: : 2.00539\tvalid_1's multi_logloss: 1.24696\tvalid_1's loss is: : 2.01485\n",
      "[6]\ttraining's multi_logloss: 1.16259\ttraining's loss is: : 1.90132\tvalid_1's multi_logloss: 1.17106\tvalid_1's loss is: : 1.91228\n",
      "[7]\ttraining's multi_logloss: 1.09247\ttraining's loss is: : 1.80475\tvalid_1's multi_logloss: 1.10203\tvalid_1's loss is: : 1.81724\n",
      "[8]\ttraining's multi_logloss: 1.02823\ttraining's loss is: : 1.71473\tvalid_1's multi_logloss: 1.03872\tvalid_1's loss is: : 1.72856\n",
      "[9]\ttraining's multi_logloss: 0.969373\ttraining's loss is: : 1.63086\tvalid_1's multi_logloss: 0.980647\tvalid_1's loss is: : 1.64587\n",
      "[10]\ttraining's multi_logloss: 0.914944\ttraining's loss is: : 1.55206\tvalid_1's multi_logloss: 0.926953\tvalid_1's loss is: : 1.5682\n",
      "[11]\ttraining's multi_logloss: 0.864589\ttraining's loss is: : 1.47807\tvalid_1's multi_logloss: 0.877372\tvalid_1's loss is: : 1.49539\n",
      "[12]\ttraining's multi_logloss: 0.817736\ttraining's loss is: : 1.40825\tvalid_1's multi_logloss: 0.831322\tvalid_1's loss is: : 1.4268\n",
      "[13]\ttraining's multi_logloss: 0.774048\ttraining's loss is: : 1.34225\tvalid_1's multi_logloss: 0.788397\tvalid_1's loss is: : 1.36198\n",
      "[14]\ttraining's multi_logloss: 0.733304\ttraining's loss is: : 1.27989\tvalid_1's multi_logloss: 0.748414\tvalid_1's loss is: : 1.30082\n",
      "[15]\ttraining's multi_logloss: 0.695238\ttraining's loss is: : 1.2209\tvalid_1's multi_logloss: 0.710998\tvalid_1's loss is: : 1.24289\n",
      "[16]\ttraining's multi_logloss: 0.659502\ttraining's loss is: : 1.16485\tvalid_1's multi_logloss: 0.675925\tvalid_1's loss is: : 1.18791\n",
      "[17]\ttraining's multi_logloss: 0.625828\ttraining's loss is: : 1.11148\tvalid_1's multi_logloss: 0.642948\tvalid_1's loss is: : 1.13566\n",
      "[18]\ttraining's multi_logloss: 0.594406\ttraining's loss is: : 1.06113\tvalid_1's multi_logloss: 0.612151\tvalid_1's loss is: : 1.08634\n",
      "[19]\ttraining's multi_logloss: 0.564799\ttraining's loss is: : 1.01321\tvalid_1's multi_logloss: 0.583154\tvalid_1's loss is: : 1.03944\n",
      "[20]\ttraining's multi_logloss: 0.536933\ttraining's loss is: : 0.96768\tvalid_1's multi_logloss: 0.555921\tvalid_1's loss is: : 0.994959\n",
      "[21]\ttraining's multi_logloss: 0.510852\ttraining's loss is: : 0.92466\tvalid_1's multi_logloss: 0.530428\tvalid_1's loss is: : 0.952925\n",
      "[22]\ttraining's multi_logloss: 0.486125\ttraining's loss is: : 0.883523\tvalid_1's multi_logloss: 0.506303\tvalid_1's loss is: : 0.912794\n",
      "[23]\ttraining's multi_logloss: 0.462671\ttraining's loss is: : 0.844171\tvalid_1's multi_logloss: 0.483407\tvalid_1's loss is: : 0.874412\n",
      "[24]\ttraining's multi_logloss: 0.440539\ttraining's loss is: : 0.806769\tvalid_1's multi_logloss: 0.461832\tvalid_1's loss is: : 0.83796\n",
      "[25]\ttraining's multi_logloss: 0.41971\ttraining's loss is: : 0.771268\tvalid_1's multi_logloss: 0.441532\tvalid_1's loss is: : 0.803385\n",
      "[26]\ttraining's multi_logloss: 0.399969\ttraining's loss is: : 0.737443\tvalid_1's multi_logloss: 0.422356\tvalid_1's loss is: : 0.770525\n",
      "[27]\ttraining's multi_logloss: 0.381321\ttraining's loss is: : 0.705265\tvalid_1's multi_logloss: 0.40425\tvalid_1's loss is: : 0.739277\n",
      "[28]\ttraining's multi_logloss: 0.363676\ttraining's loss is: : 0.6746\tvalid_1's multi_logloss: 0.38708\tvalid_1's loss is: : 0.709469\n",
      "[29]\ttraining's multi_logloss: 0.346999\ttraining's loss is: : 0.645446\tvalid_1's multi_logloss: 0.370902\tvalid_1's loss is: : 0.681187\n",
      "[30]\ttraining's multi_logloss: 0.331124\ttraining's loss is: : 0.617545\tvalid_1's multi_logloss: 0.35548\tvalid_1's loss is: : 0.654117\n",
      "[31]\ttraining's multi_logloss: 0.316013\ttraining's loss is: : 0.59085\tvalid_1's multi_logloss: 0.340876\tvalid_1's loss is: : 0.628313\n",
      "[32]\ttraining's multi_logloss: 0.301791\ttraining's loss is: : 0.565567\tvalid_1's multi_logloss: 0.327125\tvalid_1's loss is: : 0.603889\n",
      "[33]\ttraining's multi_logloss: 0.288227\ttraining's loss is: : 0.541355\tvalid_1's multi_logloss: 0.314043\tvalid_1's loss is: : 0.580551\n",
      "[34]\ttraining's multi_logloss: 0.275408\ttraining's loss is: : 0.518357\tvalid_1's multi_logloss: 0.301719\tvalid_1's loss is: : 0.55845\n",
      "[35]\ttraining's multi_logloss: 0.263134\ttraining's loss is: : 0.496258\tvalid_1's multi_logloss: 0.289925\tvalid_1's loss is: : 0.537232\n",
      "[36]\ttraining's multi_logloss: 0.251589\ttraining's loss is: : 0.475363\tvalid_1's multi_logloss: 0.278798\tvalid_1's loss is: : 0.517126\n",
      "[37]\ttraining's multi_logloss: 0.240556\ttraining's loss is: : 0.455346\tvalid_1's multi_logloss: 0.26824\tvalid_1's loss is: : 0.497972\n",
      "[38]\ttraining's multi_logloss: 0.230096\ttraining's loss is: : 0.436276\tvalid_1's multi_logloss: 0.258224\tvalid_1's loss is: : 0.479732\n",
      "[39]\ttraining's multi_logloss: 0.220133\ttraining's loss is: : 0.418043\tvalid_1's multi_logloss: 0.248738\tvalid_1's loss is: : 0.462379\n",
      "[40]\ttraining's multi_logloss: 0.210712\ttraining's loss is: : 0.400747\tvalid_1's multi_logloss: 0.239796\tvalid_1's loss is: : 0.44596\n",
      "[41]\ttraining's multi_logloss: 0.201737\ttraining's loss is: : 0.384254\tvalid_1's multi_logloss: 0.231318\tvalid_1's loss is: : 0.430363\n",
      "[42]\ttraining's multi_logloss: 0.19325\ttraining's loss is: : 0.368603\tvalid_1's multi_logloss: 0.223369\tvalid_1's loss is: : 0.415665\n",
      "[43]\ttraining's multi_logloss: 0.185097\ttraining's loss is: : 0.353496\tvalid_1's multi_logloss: 0.215648\tvalid_1's loss is: : 0.401373\n",
      "[44]\ttraining's multi_logloss: 0.177276\ttraining's loss is: : 0.338988\tvalid_1's multi_logloss: 0.208315\tvalid_1's loss is: : 0.387761\n",
      "[45]\ttraining's multi_logloss: 0.169778\ttraining's loss is: : 0.32507\tvalid_1's multi_logloss: 0.201301\tvalid_1's loss is: : 0.374734\n",
      "[46]\ttraining's multi_logloss: 0.162665\ttraining's loss is: : 0.311853\tvalid_1's multi_logloss: 0.194682\tvalid_1's loss is: : 0.36241\n",
      "[47]\ttraining's multi_logloss: 0.155889\ttraining's loss is: : 0.299248\tvalid_1's multi_logloss: 0.188442\tvalid_1's loss is: : 0.350761\n",
      "[48]\ttraining's multi_logloss: 0.149482\ttraining's loss is: : 0.287271\tvalid_1's multi_logloss: 0.182515\tvalid_1's loss is: : 0.339687\n",
      "[49]\ttraining's multi_logloss: 0.143359\ttraining's loss is: : 0.27579\tvalid_1's multi_logloss: 0.176877\tvalid_1's loss is: : 0.329118\n",
      "[50]\ttraining's multi_logloss: 0.137585\ttraining's loss is: : 0.26493\tvalid_1's multi_logloss: 0.171549\tvalid_1's loss is: : 0.319117\n",
      "[51]\ttraining's multi_logloss: 0.131923\ttraining's loss is: : 0.254327\tvalid_1's multi_logloss: 0.166406\tvalid_1's loss is: : 0.309449\n",
      "[52]\ttraining's multi_logloss: 0.126548\ttraining's loss is: : 0.244237\tvalid_1's multi_logloss: 0.161522\tvalid_1's loss is: : 0.300247\n",
      "[53]\ttraining's multi_logloss: 0.121557\ttraining's loss is: : 0.234792\tvalid_1's multi_logloss: 0.15694\tvalid_1's loss is: : 0.291586\n",
      "[54]\ttraining's multi_logloss: 0.116768\ttraining's loss is: : 0.225724\tvalid_1's multi_logloss: 0.152652\tvalid_1's loss is: : 0.283469\n",
      "[55]\ttraining's multi_logloss: 0.112165\ttraining's loss is: : 0.21701\tvalid_1's multi_logloss: 0.148522\tvalid_1's loss is: : 0.275643\n",
      "[56]\ttraining's multi_logloss: 0.107772\ttraining's loss is: : 0.208673\tvalid_1's multi_logloss: 0.144549\tvalid_1's loss is: : 0.268127\n",
      "[57]\ttraining's multi_logloss: 0.103622\ttraining's loss is: : 0.200778\tvalid_1's multi_logloss: 0.14081\tvalid_1's loss is: : 0.261043\n",
      "[58]\ttraining's multi_logloss: 0.0996675\ttraining's loss is: : 0.193233\tvalid_1's multi_logloss: 0.137259\tvalid_1's loss is: : 0.254286\n",
      "[59]\ttraining's multi_logloss: 0.09585\ttraining's loss is: : 0.185947\tvalid_1's multi_logloss: 0.133869\tvalid_1's loss is: : 0.247836\n",
      "[60]\ttraining's multi_logloss: 0.0921634\ttraining's loss is: : 0.178958\tvalid_1's multi_logloss: 0.130667\tvalid_1's loss is: : 0.241768\n",
      "[61]\ttraining's multi_logloss: 0.0885781\ttraining's loss is: : 0.172143\tvalid_1's multi_logloss: 0.127537\tvalid_1's loss is: : 0.235837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62]\ttraining's multi_logloss: 0.0852451\ttraining's loss is: : 0.165758\tvalid_1's multi_logloss: 0.124617\tvalid_1's loss is: : 0.230288\n",
      "[63]\ttraining's multi_logloss: 0.0819673\ttraining's loss is: : 0.159547\tvalid_1's multi_logloss: 0.121804\tvalid_1's loss is: : 0.224988\n",
      "[64]\ttraining's multi_logloss: 0.0789316\ttraining's loss is: : 0.153722\tvalid_1's multi_logloss: 0.119187\tvalid_1's loss is: : 0.220008\n",
      "[65]\ttraining's multi_logloss: 0.0760245\ttraining's loss is: : 0.148135\tvalid_1's multi_logloss: 0.116649\tvalid_1's loss is: : 0.215183\n",
      "[66]\ttraining's multi_logloss: 0.0732493\ttraining's loss is: : 0.14279\tvalid_1's multi_logloss: 0.114253\tvalid_1's loss is: : 0.210623\n",
      "[67]\ttraining's multi_logloss: 0.07047\ttraining's loss is: : 0.137531\tvalid_1's multi_logloss: 0.112049\tvalid_1's loss is: : 0.206411\n",
      "[68]\ttraining's multi_logloss: 0.0679192\ttraining's loss is: : 0.132615\tvalid_1's multi_logloss: 0.109908\tvalid_1's loss is: : 0.202334\n",
      "[69]\ttraining's multi_logloss: 0.0654035\ttraining's loss is: : 0.127812\tvalid_1's multi_logloss: 0.107902\tvalid_1's loss is: : 0.198502\n",
      "[70]\ttraining's multi_logloss: 0.0630609\ttraining's loss is: : 0.1233\tvalid_1's multi_logloss: 0.106036\tvalid_1's loss is: : 0.194937\n",
      "[71]\ttraining's multi_logloss: 0.0606439\ttraining's loss is: : 0.118722\tvalid_1's multi_logloss: 0.10423\tvalid_1's loss is: : 0.191496\n",
      "[72]\ttraining's multi_logloss: 0.0584757\ttraining's loss is: : 0.114543\tvalid_1's multi_logloss: 0.1025\tvalid_1's loss is: : 0.188196\n",
      "[73]\ttraining's multi_logloss: 0.0563786\ttraining's loss is: : 0.110509\tvalid_1's multi_logloss: 0.100843\tvalid_1's loss is: : 0.185058\n",
      "[74]\ttraining's multi_logloss: 0.0544326\ttraining's loss is: : 0.106783\tvalid_1's multi_logloss: 0.0993976\tvalid_1's loss is: : 0.182298\n",
      "[75]\ttraining's multi_logloss: 0.0526169\ttraining's loss is: : 0.103267\tvalid_1's multi_logloss: 0.0980146\tvalid_1's loss is: : 0.179663\n",
      "[76]\ttraining's multi_logloss: 0.0508056\ttraining's loss is: : 0.099773\tvalid_1's multi_logloss: 0.0966684\tvalid_1's loss is: : 0.177109\n",
      "[77]\ttraining's multi_logloss: 0.0488209\ttraining's loss is: : 0.0960256\tvalid_1's multi_logloss: 0.0953739\tvalid_1's loss is: : 0.174659\n",
      "[78]\ttraining's multi_logloss: 0.0471543\ttraining's loss is: : 0.0927851\tvalid_1's multi_logloss: 0.0940906\tvalid_1's loss is: : 0.172223\n",
      "[79]\ttraining's multi_logloss: 0.0455372\ttraining's loss is: : 0.0896728\tvalid_1's multi_logloss: 0.0929459\tvalid_1's loss is: : 0.170044\n",
      "[80]\ttraining's multi_logloss: 0.0440067\ttraining's loss is: : 0.086695\tvalid_1's multi_logloss: 0.091814\tvalid_1's loss is: : 0.167897\n",
      "[81]\ttraining's multi_logloss: 0.0425518\ttraining's loss is: : 0.0838589\tvalid_1's multi_logloss: 0.0907202\tvalid_1's loss is: : 0.165821\n",
      "[82]\ttraining's multi_logloss: 0.041154\ttraining's loss is: : 0.0811456\tvalid_1's multi_logloss: 0.089687\tvalid_1's loss is: : 0.163876\n",
      "[83]\ttraining's multi_logloss: 0.0398435\ttraining's loss is: : 0.0785878\tvalid_1's multi_logloss: 0.088727\tvalid_1's loss is: : 0.162069\n",
      "[84]\ttraining's multi_logloss: 0.0385842\ttraining's loss is: : 0.0761302\tvalid_1's multi_logloss: 0.0878165\tvalid_1's loss is: : 0.160352\n",
      "[85]\ttraining's multi_logloss: 0.0373564\ttraining's loss is: : 0.0737293\tvalid_1's multi_logloss: 0.0869183\tvalid_1's loss is: : 0.158655\n",
      "[86]\ttraining's multi_logloss: 0.0361355\ttraining's loss is: : 0.0713647\tvalid_1's multi_logloss: 0.0861193\tvalid_1's loss is: : 0.157137\n",
      "[87]\ttraining's multi_logloss: 0.0349939\ttraining's loss is: : 0.0691327\tvalid_1's multi_logloss: 0.0852624\tvalid_1's loss is: : 0.155536\n",
      "[88]\ttraining's multi_logloss: 0.0339057\ttraining's loss is: : 0.0670048\tvalid_1's multi_logloss: 0.0844638\tvalid_1's loss is: : 0.154042\n",
      "[89]\ttraining's multi_logloss: 0.032892\ttraining's loss is: : 0.0650211\tvalid_1's multi_logloss: 0.0837895\tvalid_1's loss is: : 0.152773\n",
      "[90]\ttraining's multi_logloss: 0.0318962\ttraining's loss is: : 0.06307\tvalid_1's multi_logloss: 0.0831258\tvalid_1's loss is: : 0.151521\n",
      "[91]\ttraining's multi_logloss: 0.0309479\ttraining's loss is: : 0.061212\tvalid_1's multi_logloss: 0.082499\tvalid_1's loss is: : 0.15036\n",
      "[92]\ttraining's multi_logloss: 0.0299974\ttraining's loss is: : 0.059352\tvalid_1's multi_logloss: 0.0818635\tvalid_1's loss is: : 0.149187\n",
      "[93]\ttraining's multi_logloss: 0.0291067\ttraining's loss is: : 0.0576037\tvalid_1's multi_logloss: 0.081301\tvalid_1's loss is: : 0.148143\n",
      "[94]\ttraining's multi_logloss: 0.0282605\ttraining's loss is: : 0.0559425\tvalid_1's multi_logloss: 0.0807752\tvalid_1's loss is: : 0.147162\n",
      "[95]\ttraining's multi_logloss: 0.0274359\ttraining's loss is: : 0.0543224\tvalid_1's multi_logloss: 0.0803045\tvalid_1's loss is: : 0.146272\n",
      "[96]\ttraining's multi_logloss: 0.0266381\ttraining's loss is: : 0.0527559\tvalid_1's multi_logloss: 0.0798754\tvalid_1's loss is: : 0.145473\n",
      "[97]\ttraining's multi_logloss: 0.025891\ttraining's loss is: : 0.0512881\tvalid_1's multi_logloss: 0.0794646\tvalid_1's loss is: : 0.144714\n",
      "[98]\ttraining's multi_logloss: 0.0251739\ttraining's loss is: : 0.0498783\tvalid_1's multi_logloss: 0.0790581\tvalid_1's loss is: : 0.143961\n",
      "[99]\ttraining's multi_logloss: 0.024496\ttraining's loss is: : 0.0485457\tvalid_1's multi_logloss: 0.0787149\tvalid_1's loss is: : 0.143336\n",
      "[100]\ttraining's multi_logloss: 0.0238101\ttraining's loss is: : 0.0471961\tvalid_1's multi_logloss: 0.0783358\tvalid_1's loss is: : 0.142639\n",
      "[101]\ttraining's multi_logloss: 0.0231612\ttraining's loss is: : 0.0459196\tvalid_1's multi_logloss: 0.0779646\tvalid_1's loss is: : 0.141961\n",
      "[102]\ttraining's multi_logloss: 0.0225063\ttraining's loss is: : 0.0446308\tvalid_1's multi_logloss: 0.0775982\tvalid_1's loss is: : 0.1413\n",
      "[103]\ttraining's multi_logloss: 0.0219094\ttraining's loss is: : 0.0434557\tvalid_1's multi_logloss: 0.0772859\tvalid_1's loss is: : 0.140736\n",
      "[104]\ttraining's multi_logloss: 0.0213235\ttraining's loss is: : 0.0423013\tvalid_1's multi_logloss: 0.0770021\tvalid_1's loss is: : 0.140224\n",
      "[105]\ttraining's multi_logloss: 0.0207549\ttraining's loss is: : 0.0411811\tvalid_1's multi_logloss: 0.0767308\tvalid_1's loss is: : 0.139739\n",
      "[106]\ttraining's multi_logloss: 0.0202101\ttraining's loss is: : 0.0401075\tvalid_1's multi_logloss: 0.0764699\tvalid_1's loss is: : 0.139278\n",
      "[107]\ttraining's multi_logloss: 0.0196937\ttraining's loss is: : 0.0390899\tvalid_1's multi_logloss: 0.0762658\tvalid_1's loss is: : 0.138915\n",
      "[108]\ttraining's multi_logloss: 0.0191876\ttraining's loss is: : 0.0380918\tvalid_1's multi_logloss: 0.0760309\tvalid_1's loss is: : 0.138508\n",
      "[109]\ttraining's multi_logloss: 0.0187125\ttraining's loss is: : 0.037155\tvalid_1's multi_logloss: 0.0758339\tvalid_1's loss is: : 0.138167\n",
      "[110]\ttraining's multi_logloss: 0.0182612\ttraining's loss is: : 0.036265\tvalid_1's multi_logloss: 0.0756988\tvalid_1's loss is: : 0.137941\n",
      "[111]\ttraining's multi_logloss: 0.0178295\ttraining's loss is: : 0.0354137\tvalid_1's multi_logloss: 0.0755667\tvalid_1's loss is: : 0.137724\n",
      "[112]\ttraining's multi_logloss: 0.0173981\ttraining's loss is: : 0.0345624\tvalid_1's multi_logloss: 0.0754202\tvalid_1's loss is: : 0.137481\n",
      "[113]\ttraining's multi_logloss: 0.0169764\ttraining's loss is: : 0.0337298\tvalid_1's multi_logloss: 0.075258\tvalid_1's loss is: : 0.137211\n",
      "[114]\ttraining's multi_logloss: 0.0165846\ttraining's loss is: : 0.0329567\tvalid_1's multi_logloss: 0.0751732\tvalid_1's loss is: : 0.137081\n",
      "[115]\ttraining's multi_logloss: 0.0162158\ttraining's loss is: : 0.0322287\tvalid_1's multi_logloss: 0.0750871\tvalid_1's loss is: : 0.136955\n",
      "[116]\ttraining's multi_logloss: 0.0158341\ttraining's loss is: : 0.0314754\tvalid_1's multi_logloss: 0.0750024\tvalid_1's loss is: : 0.136826\n",
      "[117]\ttraining's multi_logloss: 0.0154748\ttraining's loss is: : 0.0307658\tvalid_1's multi_logloss: 0.074957\tvalid_1's loss is: : 0.136766\n",
      "[118]\ttraining's multi_logloss: 0.0151173\ttraining's loss is: : 0.0300591\tvalid_1's multi_logloss: 0.0748601\tvalid_1's loss is: : 0.136611\n",
      "[119]\ttraining's multi_logloss: 0.0147773\ttraining's loss is: : 0.0293871\tvalid_1's multi_logloss: 0.0747963\tvalid_1's loss is: : 0.136523\n",
      "[120]\ttraining's multi_logloss: 0.0144533\ttraining's loss is: : 0.0287468\tvalid_1's multi_logloss: 0.074747\tvalid_1's loss is: : 0.136459\n",
      "[121]\ttraining's multi_logloss: 0.0141265\ttraining's loss is: : 0.0281007\tvalid_1's multi_logloss: 0.0747267\tvalid_1's loss is: : 0.136437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[122]\ttraining's multi_logloss: 0.0138144\ttraining's loss is: : 0.0274836\tvalid_1's multi_logloss: 0.0746849\tvalid_1's loss is: : 0.136385\n",
      "[123]\ttraining's multi_logloss: 0.0135065\ttraining's loss is: : 0.0268745\tvalid_1's multi_logloss: 0.0746788\tvalid_1's loss is: : 0.1364\n",
      "[124]\ttraining's multi_logloss: 0.0132088\ttraining's loss is: : 0.0262854\tvalid_1's multi_logloss: 0.0746122\tvalid_1's loss is: : 0.136295\n",
      "[125]\ttraining's multi_logloss: 0.0129286\ttraining's loss is: : 0.0257307\tvalid_1's multi_logloss: 0.0746309\tvalid_1's loss is: : 0.136343\n",
      "[126]\ttraining's multi_logloss: 0.0126519\ttraining's loss is: : 0.0251832\tvalid_1's multi_logloss: 0.074629\tvalid_1's loss is: : 0.136374\n",
      "[127]\ttraining's multi_logloss: 0.0123726\ttraining's loss is: : 0.0246301\tvalid_1's multi_logloss: 0.0745697\tvalid_1's loss is: : 0.136293\n",
      "[128]\ttraining's multi_logloss: 0.0121043\ttraining's loss is: : 0.0240989\tvalid_1's multi_logloss: 0.0745343\tvalid_1's loss is: : 0.136258\n",
      "[129]\ttraining's multi_logloss: 0.0118433\ttraining's loss is: : 0.0235818\tvalid_1's multi_logloss: 0.0745139\tvalid_1's loss is: : 0.136244\n",
      "[130]\ttraining's multi_logloss: 0.0115882\ttraining's loss is: : 0.0230763\tvalid_1's multi_logloss: 0.0744822\tvalid_1's loss is: : 0.136215\n",
      "[131]\ttraining's multi_logloss: 0.0113648\ttraining's loss is: : 0.022634\tvalid_1's multi_logloss: 0.0745574\tvalid_1's loss is: : 0.136376\n",
      "[132]\ttraining's multi_logloss: 0.0111327\ttraining's loss is: : 0.0221742\tvalid_1's multi_logloss: 0.074576\tvalid_1's loss is: : 0.136428\n",
      "[133]\ttraining's multi_logloss: 0.0109115\ttraining's loss is: : 0.0217355\tvalid_1's multi_logloss: 0.0746446\tvalid_1's loss is: : 0.136575\n",
      "[134]\ttraining's multi_logloss: 0.0107066\ttraining's loss is: : 0.0213294\tvalid_1's multi_logloss: 0.0747149\tvalid_1's loss is: : 0.136735\n",
      "[135]\ttraining's multi_logloss: 0.0105107\ttraining's loss is: : 0.0209412\tvalid_1's multi_logloss: 0.0747789\tvalid_1's loss is: : 0.136882\n",
      "[136]\ttraining's multi_logloss: 0.0102998\ttraining's loss is: : 0.0205228\tvalid_1's multi_logloss: 0.0748408\tvalid_1's loss is: : 0.137021\n",
      "[137]\ttraining's multi_logloss: 0.0100954\ttraining's loss is: : 0.0201173\tvalid_1's multi_logloss: 0.0748691\tvalid_1's loss is: : 0.137091\n",
      "[138]\ttraining's multi_logloss: 0.00989295\ttraining's loss is: : 0.0197156\tvalid_1's multi_logloss: 0.074918\tvalid_1's loss is: : 0.137201\n",
      "[139]\ttraining's multi_logloss: 0.00969373\ttraining's loss is: : 0.0193201\tvalid_1's multi_logloss: 0.0749414\tvalid_1's loss is: : 0.137266\n",
      "[140]\ttraining's multi_logloss: 0.00950637\ttraining's loss is: : 0.0189481\tvalid_1's multi_logloss: 0.0749931\tvalid_1's loss is: : 0.137378\n",
      "[141]\ttraining's multi_logloss: 0.0093274\ttraining's loss is: : 0.0185929\tvalid_1's multi_logloss: 0.0750506\tvalid_1's loss is: : 0.137505\n",
      "[142]\ttraining's multi_logloss: 0.00914795\ttraining's loss is: : 0.0182366\tvalid_1's multi_logloss: 0.0751089\tvalid_1's loss is: : 0.13763\n",
      "[143]\ttraining's multi_logloss: 0.00896965\ttraining's loss is: : 0.0178825\tvalid_1's multi_logloss: 0.0751439\tvalid_1's loss is: : 0.137713\n",
      "[144]\ttraining's multi_logloss: 0.0087982\ttraining's loss is: : 0.0175419\tvalid_1's multi_logloss: 0.0751734\tvalid_1's loss is: : 0.137784\n",
      "[145]\ttraining's multi_logloss: 0.00863191\ttraining's loss is: : 0.0172114\tvalid_1's multi_logloss: 0.0752203\tvalid_1's loss is: : 0.137878\n",
      "[146]\ttraining's multi_logloss: 0.00848075\ttraining's loss is: : 0.0169112\tvalid_1's multi_logloss: 0.0752892\tvalid_1's loss is: : 0.13803\n",
      "[147]\ttraining's multi_logloss: 0.00832003\ttraining's loss is: : 0.016592\tvalid_1's multi_logloss: 0.0753782\tvalid_1's loss is: : 0.138216\n",
      "[148]\ttraining's multi_logloss: 0.0081749\ttraining's loss is: : 0.0163036\tvalid_1's multi_logloss: 0.0754463\tvalid_1's loss is: : 0.138365\n",
      "[149]\ttraining's multi_logloss: 0.00802869\ttraining's loss is: : 0.016013\tvalid_1's multi_logloss: 0.0755318\tvalid_1's loss is: : 0.138542\n",
      "[150]\ttraining's multi_logloss: 0.00789054\ttraining's loss is: : 0.0157384\tvalid_1's multi_logloss: 0.0756048\tvalid_1's loss is: : 0.138708\n",
      "[151]\ttraining's multi_logloss: 0.00775464\ttraining's loss is: : 0.0154683\tvalid_1's multi_logloss: 0.0757173\tvalid_1's loss is: : 0.138934\n",
      "[152]\ttraining's multi_logloss: 0.00762286\ttraining's loss is: : 0.0152064\tvalid_1's multi_logloss: 0.0758328\tvalid_1's loss is: : 0.139163\n",
      "[153]\ttraining's multi_logloss: 0.0075003\ttraining's loss is: : 0.0149629\tvalid_1's multi_logloss: 0.0759497\tvalid_1's loss is: : 0.139398\n",
      "[154]\ttraining's multi_logloss: 0.00737777\ttraining's loss is: : 0.0147194\tvalid_1's multi_logloss: 0.0760665\tvalid_1's loss is: : 0.139627\n",
      "[155]\ttraining's multi_logloss: 0.00725752\ttraining's loss is: : 0.0144802\tvalid_1's multi_logloss: 0.0762078\tvalid_1's loss is: : 0.139905\n",
      "[156]\ttraining's multi_logloss: 0.00713922\ttraining's loss is: : 0.0142449\tvalid_1's multi_logloss: 0.0763066\tvalid_1's loss is: : 0.140115\n",
      "[157]\ttraining's multi_logloss: 0.00702384\ttraining's loss is: : 0.0140156\tvalid_1's multi_logloss: 0.0764331\tvalid_1's loss is: : 0.140369\n",
      "[158]\ttraining's multi_logloss: 0.00691075\ttraining's loss is: : 0.0137906\tvalid_1's multi_logloss: 0.0765522\tvalid_1's loss is: : 0.140608\n",
      "[159]\ttraining's multi_logloss: 0.00679903\ttraining's loss is: : 0.0135684\tvalid_1's multi_logloss: 0.0766419\tvalid_1's loss is: : 0.14079\n",
      "[160]\ttraining's multi_logloss: 0.00668573\ttraining's loss is: : 0.0133429\tvalid_1's multi_logloss: 0.0767413\tvalid_1's loss is: : 0.140976\n",
      "[161]\ttraining's multi_logloss: 0.00657145\ttraining's loss is: : 0.0131154\tvalid_1's multi_logloss: 0.0768288\tvalid_1's loss is: : 0.141152\n",
      "[162]\ttraining's multi_logloss: 0.00646288\ttraining's loss is: : 0.0128992\tvalid_1's multi_logloss: 0.0769204\tvalid_1's loss is: : 0.141337\n",
      "[163]\ttraining's multi_logloss: 0.00635842\ttraining's loss is: : 0.0126913\tvalid_1's multi_logloss: 0.0770311\tvalid_1's loss is: : 0.14156\n",
      "[164]\ttraining's multi_logloss: 0.00625792\ttraining's loss is: : 0.0124913\tvalid_1's multi_logloss: 0.0771327\tvalid_1's loss is: : 0.141756\n",
      "[165]\ttraining's multi_logloss: 0.00616302\ttraining's loss is: : 0.0123024\tvalid_1's multi_logloss: 0.0772362\tvalid_1's loss is: : 0.141953\n",
      "[166]\ttraining's multi_logloss: 0.00606807\ttraining's loss is: : 0.0121136\tvalid_1's multi_logloss: 0.0773763\tvalid_1's loss is: : 0.14223\n",
      "[167]\ttraining's multi_logloss: 0.00597365\ttraining's loss is: : 0.0119259\tvalid_1's multi_logloss: 0.0775051\tvalid_1's loss is: : 0.142476\n",
      "[168]\ttraining's multi_logloss: 0.00588095\ttraining's loss is: : 0.0117414\tvalid_1's multi_logloss: 0.0776247\tvalid_1's loss is: : 0.142707\n",
      "[169]\ttraining's multi_logloss: 0.00579283\ttraining's loss is: : 0.0115661\tvalid_1's multi_logloss: 0.0777552\tvalid_1's loss is: : 0.142962\n",
      "[170]\ttraining's multi_logloss: 0.00570956\ttraining's loss is: : 0.0114004\tvalid_1's multi_logloss: 0.0778602\tvalid_1's loss is: : 0.143176\n",
      "[171]\ttraining's multi_logloss: 0.00562321\ttraining's loss is: : 0.0112285\tvalid_1's multi_logloss: 0.0779906\tvalid_1's loss is: : 0.143436\n",
      "[172]\ttraining's multi_logloss: 0.00554521\ttraining's loss is: : 0.0110733\tvalid_1's multi_logloss: 0.078105\tvalid_1's loss is: : 0.143664\n",
      "[173]\ttraining's multi_logloss: 0.00546674\ttraining's loss is: : 0.0109171\tvalid_1's multi_logloss: 0.0782515\tvalid_1's loss is: : 0.143952\n",
      "[174]\ttraining's multi_logloss: 0.00539143\ttraining's loss is: : 0.0107671\tvalid_1's multi_logloss: 0.0783685\tvalid_1's loss is: : 0.144176\n",
      "[175]\ttraining's multi_logloss: 0.0053146\ttraining's loss is: : 0.0106141\tvalid_1's multi_logloss: 0.0784848\tvalid_1's loss is: : 0.144399\n",
      "[176]\ttraining's multi_logloss: 0.00523456\ttraining's loss is: : 0.0104547\tvalid_1's multi_logloss: 0.0786408\tvalid_1's loss is: : 0.144698\n",
      "[177]\ttraining's multi_logloss: 0.0051611\ttraining's loss is: : 0.0103083\tvalid_1's multi_logloss: 0.0787814\tvalid_1's loss is: : 0.144962\n",
      "[178]\ttraining's multi_logloss: 0.00509203\ttraining's loss is: : 0.0101708\tvalid_1's multi_logloss: 0.0789002\tvalid_1's loss is: : 0.145192\n",
      "[179]\ttraining's multi_logloss: 0.00501697\ttraining's loss is: : 0.0100212\tvalid_1's multi_logloss: 0.0790283\tvalid_1's loss is: : 0.145445\n",
      "[180]\ttraining's multi_logloss: 0.0049491\ttraining's loss is: : 0.00988595\tvalid_1's multi_logloss: 0.0791533\tvalid_1's loss is: : 0.145694\n",
      "Early stopping, best iteration is:\n",
      "[130]\ttraining's multi_logloss: 0.0115882\ttraining's loss is: : 0.0230763\tvalid_1's multi_logloss: 0.0744822\tvalid_1's loss is: : 0.136215\n"
     ]
    }
   ],
   "source": [
    "dtrain = lgb.Dataset(train_X,train_Y) \n",
    "dval   = lgb.Dataset(test_X,test_Y, reference = dtrain) \n",
    "\n",
    "params = {\n",
    "         'task':'train', \n",
    "         'num_leaves': 255,\n",
    "         'objective': 'multiclass',\n",
    "         'num_class':6,\n",
    "        #'min_data_in_leaf': 40,\n",
    "         'min_data_in_leaf': 1,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.85,\n",
    "        'bagging_fraction': 0.9,\n",
    "         'bagging_freq': 5, \n",
    "         'max_bin':128,\n",
    "        'num_threads': 10,\n",
    "        'random_state':100\n",
    "     }  \n",
    "lgb_model_0_order = lgb.train(params, dtrain, num_boost_round=500,valid_sets=[dtrain,dval], early_stopping_rounds=50, feval=lgb_logloss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runXGB(train_X,train_y,test_X,test_y=None,feature_names=None,seed_val=0,num_rounds=1000):\n",
    "    #参数设定\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'#多分类、输出概率值\n",
    "    param['eta'] = 0.1#学习率\n",
    "    param['max_depth'] = 6#最大深度，越大越容易过拟合\n",
    "    param['silent'] = 1#打印提示信息\n",
    "    param['num_class'] = 6#三个类别\n",
    "    param['eval_metric']= \"mlogloss\"#对数损失\n",
    "    param['min_child_weight']=1#停止条件，这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。\n",
    "    param['subsample'] =0.7#随机采样训练样本\n",
    "    param['colsample_bytree'] = 0.7# 生成树时进行的列采样\n",
    "    param['seed'] = seed_val#随机数种子\n",
    "    num_rounds = num_rounds#迭代次数\n",
    "    \n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X,label=train_y)\n",
    "    \n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X,label=test_y)\n",
    "        watchlist = [(xgtrain,'train'),(xgtest,'test')]\n",
    "        model = xgb.train(plst,xgtrain,num_rounds,watchlist,early_stopping_rounds=20)\n",
    "      #  early_stopping_rounds 当设置的迭代次数较大时，early_stopping_rounds 可在一定的迭代次数内准确率没有提升就停止训练\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst,xgtrain,num_rounds)\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y,model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.52184\ttest-mlogloss:1.52155\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[1]\ttrain-mlogloss:1.32143\ttest-mlogloss:1.32118\n",
      "[2]\ttrain-mlogloss:1.16268\ttest-mlogloss:1.16262\n",
      "[3]\ttrain-mlogloss:1.03308\ttest-mlogloss:1.03296\n",
      "[4]\ttrain-mlogloss:0.924021\ttest-mlogloss:0.924054\n",
      "[5]\ttrain-mlogloss:0.830729\ttest-mlogloss:0.830848\n",
      "[6]\ttrain-mlogloss:0.750349\ttest-mlogloss:0.750585\n",
      "[7]\ttrain-mlogloss:0.680013\ttest-mlogloss:0.680375\n",
      "[8]\ttrain-mlogloss:0.61866\ttest-mlogloss:0.619101\n",
      "[9]\ttrain-mlogloss:0.564536\ttest-mlogloss:0.56511\n",
      "[10]\ttrain-mlogloss:0.516592\ttest-mlogloss:0.517349\n",
      "[11]\ttrain-mlogloss:0.473969\ttest-mlogloss:0.474918\n",
      "[12]\ttrain-mlogloss:0.435977\ttest-mlogloss:0.437048\n",
      "[13]\ttrain-mlogloss:0.401491\ttest-mlogloss:0.402744\n",
      "[14]\ttrain-mlogloss:0.371106\ttest-mlogloss:0.372446\n",
      "[15]\ttrain-mlogloss:0.34342\ttest-mlogloss:0.344913\n",
      "[16]\ttrain-mlogloss:0.318787\ttest-mlogloss:0.320446\n",
      "[17]\ttrain-mlogloss:0.29656\ttest-mlogloss:0.298443\n",
      "[18]\ttrain-mlogloss:0.276643\ttest-mlogloss:0.278738\n",
      "[19]\ttrain-mlogloss:0.258136\ttest-mlogloss:0.260448\n",
      "[20]\ttrain-mlogloss:0.241707\ttest-mlogloss:0.244258\n",
      "[21]\ttrain-mlogloss:0.226899\ttest-mlogloss:0.229641\n",
      "[22]\ttrain-mlogloss:0.213369\ttest-mlogloss:0.216445\n",
      "[23]\ttrain-mlogloss:0.201193\ttest-mlogloss:0.204532\n",
      "[24]\ttrain-mlogloss:0.190208\ttest-mlogloss:0.193873\n",
      "[25]\ttrain-mlogloss:0.180294\ttest-mlogloss:0.18418\n",
      "[26]\ttrain-mlogloss:0.171082\ttest-mlogloss:0.175373\n",
      "[27]\ttrain-mlogloss:0.162569\ttest-mlogloss:0.16721\n",
      "[28]\ttrain-mlogloss:0.155288\ttest-mlogloss:0.160218\n",
      "[29]\ttrain-mlogloss:0.148402\ttest-mlogloss:0.153621\n",
      "[30]\ttrain-mlogloss:0.142206\ttest-mlogloss:0.147814\n",
      "[31]\ttrain-mlogloss:0.136796\ttest-mlogloss:0.142736\n",
      "[32]\ttrain-mlogloss:0.131539\ttest-mlogloss:0.137775\n",
      "[33]\ttrain-mlogloss:0.126632\ttest-mlogloss:0.133159\n",
      "[34]\ttrain-mlogloss:0.121691\ttest-mlogloss:0.128555\n",
      "[35]\ttrain-mlogloss:0.117603\ttest-mlogloss:0.124764\n",
      "[36]\ttrain-mlogloss:0.113971\ttest-mlogloss:0.121366\n",
      "[37]\ttrain-mlogloss:0.110287\ttest-mlogloss:0.117985\n",
      "[38]\ttrain-mlogloss:0.107174\ttest-mlogloss:0.115165\n",
      "[39]\ttrain-mlogloss:0.104336\ttest-mlogloss:0.112654\n",
      "[40]\ttrain-mlogloss:0.10147\ttest-mlogloss:0.110158\n",
      "[41]\ttrain-mlogloss:0.099003\ttest-mlogloss:0.108013\n",
      "[42]\ttrain-mlogloss:0.096652\ttest-mlogloss:0.106006\n",
      "[43]\ttrain-mlogloss:0.094682\ttest-mlogloss:0.104364\n",
      "[44]\ttrain-mlogloss:0.092721\ttest-mlogloss:0.102606\n",
      "[45]\ttrain-mlogloss:0.090677\ttest-mlogloss:0.100825\n",
      "[46]\ttrain-mlogloss:0.088987\ttest-mlogloss:0.099364\n",
      "[47]\ttrain-mlogloss:0.08715\ttest-mlogloss:0.09788\n",
      "[48]\ttrain-mlogloss:0.08583\ttest-mlogloss:0.096874\n",
      "[49]\ttrain-mlogloss:0.084475\ttest-mlogloss:0.095861\n",
      "[50]\ttrain-mlogloss:0.083023\ttest-mlogloss:0.094693\n",
      "[51]\ttrain-mlogloss:0.081706\ttest-mlogloss:0.093693\n",
      "[52]\ttrain-mlogloss:0.080302\ttest-mlogloss:0.092566\n",
      "[53]\ttrain-mlogloss:0.079074\ttest-mlogloss:0.091621\n",
      "[54]\ttrain-mlogloss:0.078016\ttest-mlogloss:0.090916\n",
      "[55]\ttrain-mlogloss:0.07692\ttest-mlogloss:0.090197\n",
      "[56]\ttrain-mlogloss:0.075818\ttest-mlogloss:0.089374\n",
      "[57]\ttrain-mlogloss:0.074828\ttest-mlogloss:0.088695\n",
      "[58]\ttrain-mlogloss:0.073899\ttest-mlogloss:0.088095\n",
      "[59]\ttrain-mlogloss:0.072918\ttest-mlogloss:0.087442\n",
      "[60]\ttrain-mlogloss:0.072229\ttest-mlogloss:0.086968\n",
      "[61]\ttrain-mlogloss:0.071445\ttest-mlogloss:0.086462\n",
      "[62]\ttrain-mlogloss:0.07063\ttest-mlogloss:0.085923\n",
      "[63]\ttrain-mlogloss:0.069948\ttest-mlogloss:0.085565\n",
      "[64]\ttrain-mlogloss:0.06934\ttest-mlogloss:0.085271\n",
      "[65]\ttrain-mlogloss:0.068558\ttest-mlogloss:0.084821\n",
      "[66]\ttrain-mlogloss:0.067907\ttest-mlogloss:0.084527\n",
      "[67]\ttrain-mlogloss:0.067317\ttest-mlogloss:0.084179\n",
      "[68]\ttrain-mlogloss:0.066773\ttest-mlogloss:0.083905\n",
      "[69]\ttrain-mlogloss:0.065975\ttest-mlogloss:0.083454\n",
      "[70]\ttrain-mlogloss:0.065493\ttest-mlogloss:0.083224\n",
      "[71]\ttrain-mlogloss:0.064802\ttest-mlogloss:0.082797\n",
      "[72]\ttrain-mlogloss:0.064144\ttest-mlogloss:0.082448\n",
      "[73]\ttrain-mlogloss:0.063611\ttest-mlogloss:0.082208\n",
      "[74]\ttrain-mlogloss:0.063138\ttest-mlogloss:0.081892\n",
      "[75]\ttrain-mlogloss:0.062659\ttest-mlogloss:0.081586\n",
      "[76]\ttrain-mlogloss:0.062183\ttest-mlogloss:0.081314\n",
      "[77]\ttrain-mlogloss:0.061523\ttest-mlogloss:0.080982\n",
      "[78]\ttrain-mlogloss:0.061042\ttest-mlogloss:0.080733\n",
      "[79]\ttrain-mlogloss:0.060596\ttest-mlogloss:0.080563\n",
      "[80]\ttrain-mlogloss:0.060221\ttest-mlogloss:0.080451\n",
      "[81]\ttrain-mlogloss:0.059849\ttest-mlogloss:0.080294\n",
      "[82]\ttrain-mlogloss:0.059354\ttest-mlogloss:0.080041\n",
      "[83]\ttrain-mlogloss:0.058979\ttest-mlogloss:0.079915\n",
      "[84]\ttrain-mlogloss:0.058562\ttest-mlogloss:0.079739\n",
      "[85]\ttrain-mlogloss:0.058148\ttest-mlogloss:0.079587\n",
      "[86]\ttrain-mlogloss:0.057758\ttest-mlogloss:0.07947\n",
      "[87]\ttrain-mlogloss:0.057388\ttest-mlogloss:0.079337\n",
      "[88]\ttrain-mlogloss:0.056936\ttest-mlogloss:0.079178\n",
      "[89]\ttrain-mlogloss:0.056462\ttest-mlogloss:0.079004\n",
      "[90]\ttrain-mlogloss:0.056031\ttest-mlogloss:0.078849\n",
      "[91]\ttrain-mlogloss:0.055703\ttest-mlogloss:0.078732\n",
      "[92]\ttrain-mlogloss:0.055382\ttest-mlogloss:0.078605\n",
      "[93]\ttrain-mlogloss:0.055077\ttest-mlogloss:0.078484\n",
      "[94]\ttrain-mlogloss:0.054764\ttest-mlogloss:0.078376\n",
      "[95]\ttrain-mlogloss:0.054405\ttest-mlogloss:0.07824\n",
      "[96]\ttrain-mlogloss:0.054163\ttest-mlogloss:0.078114\n",
      "[97]\ttrain-mlogloss:0.053812\ttest-mlogloss:0.07799\n",
      "[98]\ttrain-mlogloss:0.053581\ttest-mlogloss:0.077932\n",
      "[99]\ttrain-mlogloss:0.053299\ttest-mlogloss:0.077827\n",
      "[100]\ttrain-mlogloss:0.052967\ttest-mlogloss:0.077707\n",
      "[101]\ttrain-mlogloss:0.052753\ttest-mlogloss:0.077618\n",
      "[102]\ttrain-mlogloss:0.052516\ttest-mlogloss:0.077557\n",
      "[103]\ttrain-mlogloss:0.052203\ttest-mlogloss:0.077471\n",
      "[104]\ttrain-mlogloss:0.051884\ttest-mlogloss:0.077401\n",
      "[105]\ttrain-mlogloss:0.051584\ttest-mlogloss:0.077283\n",
      "[106]\ttrain-mlogloss:0.05133\ttest-mlogloss:0.077164\n",
      "[107]\ttrain-mlogloss:0.051107\ttest-mlogloss:0.07714\n",
      "[108]\ttrain-mlogloss:0.050805\ttest-mlogloss:0.076955\n",
      "[109]\ttrain-mlogloss:0.050594\ttest-mlogloss:0.076935\n",
      "[110]\ttrain-mlogloss:0.050397\ttest-mlogloss:0.076936\n",
      "[111]\ttrain-mlogloss:0.050166\ttest-mlogloss:0.07687\n",
      "[112]\ttrain-mlogloss:0.049813\ttest-mlogloss:0.076711\n",
      "[113]\ttrain-mlogloss:0.049562\ttest-mlogloss:0.076635\n",
      "[114]\ttrain-mlogloss:0.049326\ttest-mlogloss:0.076637\n",
      "[115]\ttrain-mlogloss:0.04914\ttest-mlogloss:0.076631\n",
      "[116]\ttrain-mlogloss:0.048883\ttest-mlogloss:0.076594\n",
      "[117]\ttrain-mlogloss:0.048542\ttest-mlogloss:0.076469\n",
      "[118]\ttrain-mlogloss:0.048315\ttest-mlogloss:0.076417\n",
      "[119]\ttrain-mlogloss:0.048085\ttest-mlogloss:0.07632\n",
      "[120]\ttrain-mlogloss:0.047775\ttest-mlogloss:0.076228\n",
      "[121]\ttrain-mlogloss:0.04748\ttest-mlogloss:0.076143\n",
      "[122]\ttrain-mlogloss:0.047259\ttest-mlogloss:0.076044\n",
      "[123]\ttrain-mlogloss:0.047019\ttest-mlogloss:0.075956\n",
      "[124]\ttrain-mlogloss:0.046791\ttest-mlogloss:0.075839\n",
      "[125]\ttrain-mlogloss:0.046648\ttest-mlogloss:0.075809\n",
      "[126]\ttrain-mlogloss:0.046488\ttest-mlogloss:0.075802\n",
      "[127]\ttrain-mlogloss:0.046279\ttest-mlogloss:0.075765\n",
      "[128]\ttrain-mlogloss:0.04605\ttest-mlogloss:0.075711\n",
      "[129]\ttrain-mlogloss:0.045785\ttest-mlogloss:0.075602\n",
      "[130]\ttrain-mlogloss:0.045558\ttest-mlogloss:0.075558\n",
      "[131]\ttrain-mlogloss:0.045386\ttest-mlogloss:0.075555\n",
      "[132]\ttrain-mlogloss:0.045228\ttest-mlogloss:0.075539\n",
      "[133]\ttrain-mlogloss:0.045031\ttest-mlogloss:0.075509\n",
      "[134]\ttrain-mlogloss:0.044805\ttest-mlogloss:0.075456\n",
      "[135]\ttrain-mlogloss:0.04459\ttest-mlogloss:0.075439\n",
      "[136]\ttrain-mlogloss:0.044391\ttest-mlogloss:0.075427\n",
      "[137]\ttrain-mlogloss:0.044212\ttest-mlogloss:0.0754\n",
      "[138]\ttrain-mlogloss:0.043938\ttest-mlogloss:0.075323\n",
      "[139]\ttrain-mlogloss:0.043616\ttest-mlogloss:0.075238\n",
      "[140]\ttrain-mlogloss:0.043404\ttest-mlogloss:0.075153\n",
      "[141]\ttrain-mlogloss:0.043189\ttest-mlogloss:0.075092\n",
      "[142]\ttrain-mlogloss:0.042982\ttest-mlogloss:0.07505\n",
      "[143]\ttrain-mlogloss:0.042768\ttest-mlogloss:0.075026\n",
      "[144]\ttrain-mlogloss:0.042605\ttest-mlogloss:0.074975\n",
      "[145]\ttrain-mlogloss:0.042408\ttest-mlogloss:0.074921\n",
      "[146]\ttrain-mlogloss:0.042225\ttest-mlogloss:0.07488\n",
      "[147]\ttrain-mlogloss:0.042046\ttest-mlogloss:0.07485\n",
      "[148]\ttrain-mlogloss:0.041842\ttest-mlogloss:0.074771\n",
      "[149]\ttrain-mlogloss:0.041694\ttest-mlogloss:0.074745\n",
      "[150]\ttrain-mlogloss:0.041523\ttest-mlogloss:0.074713\n",
      "[151]\ttrain-mlogloss:0.041341\ttest-mlogloss:0.074686\n",
      "[152]\ttrain-mlogloss:0.041169\ttest-mlogloss:0.074663\n",
      "[153]\ttrain-mlogloss:0.041004\ttest-mlogloss:0.074662\n",
      "[154]\ttrain-mlogloss:0.0408\ttest-mlogloss:0.074593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[155]\ttrain-mlogloss:0.04065\ttest-mlogloss:0.074577\n",
      "[156]\ttrain-mlogloss:0.040467\ttest-mlogloss:0.074581\n",
      "[157]\ttrain-mlogloss:0.040264\ttest-mlogloss:0.074575\n",
      "[158]\ttrain-mlogloss:0.040033\ttest-mlogloss:0.074495\n",
      "[159]\ttrain-mlogloss:0.039858\ttest-mlogloss:0.074447\n",
      "[160]\ttrain-mlogloss:0.039686\ttest-mlogloss:0.074389\n",
      "[161]\ttrain-mlogloss:0.039512\ttest-mlogloss:0.07439\n",
      "[162]\ttrain-mlogloss:0.039348\ttest-mlogloss:0.074371\n",
      "[163]\ttrain-mlogloss:0.039156\ttest-mlogloss:0.074328\n",
      "[164]\ttrain-mlogloss:0.039004\ttest-mlogloss:0.074308\n",
      "[165]\ttrain-mlogloss:0.038798\ttest-mlogloss:0.074262\n",
      "[166]\ttrain-mlogloss:0.038581\ttest-mlogloss:0.074218\n",
      "[167]\ttrain-mlogloss:0.038408\ttest-mlogloss:0.074178\n",
      "[168]\ttrain-mlogloss:0.038176\ttest-mlogloss:0.074134\n",
      "[169]\ttrain-mlogloss:0.038014\ttest-mlogloss:0.074109\n",
      "[170]\ttrain-mlogloss:0.037909\ttest-mlogloss:0.074093\n",
      "[171]\ttrain-mlogloss:0.037743\ttest-mlogloss:0.074109\n",
      "[172]\ttrain-mlogloss:0.037574\ttest-mlogloss:0.074064\n",
      "[173]\ttrain-mlogloss:0.037392\ttest-mlogloss:0.074043\n",
      "[174]\ttrain-mlogloss:0.037241\ttest-mlogloss:0.074034\n",
      "[175]\ttrain-mlogloss:0.037105\ttest-mlogloss:0.074062\n",
      "[176]\ttrain-mlogloss:0.03691\ttest-mlogloss:0.074005\n",
      "[177]\ttrain-mlogloss:0.036771\ttest-mlogloss:0.074005\n",
      "[178]\ttrain-mlogloss:0.036611\ttest-mlogloss:0.073938\n",
      "[179]\ttrain-mlogloss:0.036458\ttest-mlogloss:0.073901\n",
      "[180]\ttrain-mlogloss:0.036296\ttest-mlogloss:0.073891\n",
      "[181]\ttrain-mlogloss:0.036128\ttest-mlogloss:0.073872\n",
      "[182]\ttrain-mlogloss:0.035925\ttest-mlogloss:0.07383\n",
      "[183]\ttrain-mlogloss:0.03572\ttest-mlogloss:0.073805\n",
      "[184]\ttrain-mlogloss:0.035553\ttest-mlogloss:0.073785\n",
      "[185]\ttrain-mlogloss:0.035384\ttest-mlogloss:0.073821\n",
      "[186]\ttrain-mlogloss:0.035229\ttest-mlogloss:0.073769\n",
      "[187]\ttrain-mlogloss:0.0351\ttest-mlogloss:0.073788\n",
      "[188]\ttrain-mlogloss:0.034932\ttest-mlogloss:0.073755\n",
      "[189]\ttrain-mlogloss:0.0348\ttest-mlogloss:0.073754\n",
      "[190]\ttrain-mlogloss:0.034685\ttest-mlogloss:0.073713\n",
      "[191]\ttrain-mlogloss:0.034575\ttest-mlogloss:0.073717\n",
      "[192]\ttrain-mlogloss:0.034372\ttest-mlogloss:0.073621\n",
      "[193]\ttrain-mlogloss:0.03423\ttest-mlogloss:0.073601\n",
      "[194]\ttrain-mlogloss:0.034109\ttest-mlogloss:0.073595\n",
      "[195]\ttrain-mlogloss:0.033967\ttest-mlogloss:0.073547\n",
      "[196]\ttrain-mlogloss:0.033815\ttest-mlogloss:0.07351\n",
      "[197]\ttrain-mlogloss:0.033689\ttest-mlogloss:0.073503\n",
      "[198]\ttrain-mlogloss:0.033551\ttest-mlogloss:0.073454\n",
      "[199]\ttrain-mlogloss:0.033379\ttest-mlogloss:0.073431\n",
      "[200]\ttrain-mlogloss:0.033218\ttest-mlogloss:0.073392\n",
      "[201]\ttrain-mlogloss:0.033128\ttest-mlogloss:0.073406\n",
      "[202]\ttrain-mlogloss:0.032998\ttest-mlogloss:0.073397\n",
      "[203]\ttrain-mlogloss:0.032782\ttest-mlogloss:0.073358\n",
      "[204]\ttrain-mlogloss:0.032669\ttest-mlogloss:0.073332\n",
      "[205]\ttrain-mlogloss:0.032567\ttest-mlogloss:0.073348\n",
      "[206]\ttrain-mlogloss:0.032471\ttest-mlogloss:0.073339\n",
      "[207]\ttrain-mlogloss:0.032311\ttest-mlogloss:0.073318\n",
      "[208]\ttrain-mlogloss:0.032192\ttest-mlogloss:0.073312\n",
      "[209]\ttrain-mlogloss:0.032104\ttest-mlogloss:0.073327\n",
      "[210]\ttrain-mlogloss:0.032007\ttest-mlogloss:0.073332\n",
      "[211]\ttrain-mlogloss:0.03189\ttest-mlogloss:0.073353\n",
      "[212]\ttrain-mlogloss:0.031815\ttest-mlogloss:0.073353\n",
      "[213]\ttrain-mlogloss:0.031696\ttest-mlogloss:0.073332\n",
      "[214]\ttrain-mlogloss:0.031553\ttest-mlogloss:0.07334\n",
      "[215]\ttrain-mlogloss:0.031422\ttest-mlogloss:0.07333\n",
      "[216]\ttrain-mlogloss:0.031368\ttest-mlogloss:0.07334\n",
      "[217]\ttrain-mlogloss:0.031244\ttest-mlogloss:0.073311\n",
      "[218]\ttrain-mlogloss:0.031127\ttest-mlogloss:0.073288\n",
      "[219]\ttrain-mlogloss:0.031013\ttest-mlogloss:0.073308\n",
      "[220]\ttrain-mlogloss:0.030905\ttest-mlogloss:0.07327\n",
      "[221]\ttrain-mlogloss:0.030792\ttest-mlogloss:0.073279\n",
      "[222]\ttrain-mlogloss:0.030718\ttest-mlogloss:0.073279\n",
      "[223]\ttrain-mlogloss:0.030618\ttest-mlogloss:0.073291\n",
      "[224]\ttrain-mlogloss:0.030473\ttest-mlogloss:0.073237\n",
      "[225]\ttrain-mlogloss:0.030369\ttest-mlogloss:0.073238\n",
      "[226]\ttrain-mlogloss:0.030274\ttest-mlogloss:0.073252\n",
      "[227]\ttrain-mlogloss:0.030162\ttest-mlogloss:0.073248\n",
      "[228]\ttrain-mlogloss:0.030077\ttest-mlogloss:0.073262\n",
      "[229]\ttrain-mlogloss:0.02998\ttest-mlogloss:0.073283\n",
      "[230]\ttrain-mlogloss:0.029888\ttest-mlogloss:0.073302\n",
      "[231]\ttrain-mlogloss:0.029799\ttest-mlogloss:0.073303\n",
      "[232]\ttrain-mlogloss:0.029699\ttest-mlogloss:0.073342\n",
      "[233]\ttrain-mlogloss:0.029599\ttest-mlogloss:0.073299\n",
      "[234]\ttrain-mlogloss:0.029528\ttest-mlogloss:0.073295\n",
      "[235]\ttrain-mlogloss:0.029413\ttest-mlogloss:0.073243\n",
      "[236]\ttrain-mlogloss:0.029299\ttest-mlogloss:0.073241\n",
      "[237]\ttrain-mlogloss:0.029213\ttest-mlogloss:0.073252\n",
      "[238]\ttrain-mlogloss:0.029131\ttest-mlogloss:0.073268\n",
      "[239]\ttrain-mlogloss:0.029011\ttest-mlogloss:0.07329\n",
      "[240]\ttrain-mlogloss:0.02894\ttest-mlogloss:0.073313\n",
      "[241]\ttrain-mlogloss:0.028849\ttest-mlogloss:0.073317\n",
      "[242]\ttrain-mlogloss:0.028738\ttest-mlogloss:0.073347\n",
      "[243]\ttrain-mlogloss:0.028593\ttest-mlogloss:0.073278\n",
      "[244]\ttrain-mlogloss:0.028466\ttest-mlogloss:0.073238\n",
      "Stopping. Best iteration:\n",
      "[224]\ttrain-mlogloss:0.030473\ttest-mlogloss:0.073237\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[9.9572819e-01, 1.6203585e-05, 1.6343502e-03, 8.3550818e-05,\n",
       "         4.8396148e-05, 2.4893144e-03],\n",
       "        [9.9548537e-01, 2.3472287e-06, 4.8043585e-05, 4.9336686e-06,\n",
       "         2.5823115e-06, 4.4566989e-03],\n",
       "        [9.9947113e-01, 1.4132763e-05, 3.6072724e-05, 1.2409997e-05,\n",
       "         7.6228835e-06, 4.5866182e-04],\n",
       "        ...,\n",
       "        [9.9464637e-01, 5.6236811e-05, 6.2921160e-04, 2.3285649e-04,\n",
       "         4.9585480e-05, 4.3857256e-03],\n",
       "        [9.9870121e-01, 3.7009111e-05, 6.2678810e-05, 2.5975469e-05,\n",
       "         2.1061803e-06, 1.1710105e-03],\n",
       "        [9.9572951e-01, 2.2936781e-04, 1.5375386e-03, 3.2207929e-04,\n",
       "         7.7494398e-05, 2.1040195e-03]], dtype=float32),\n",
       " <xgboost.core.Booster at 0x7efc5d4e1b00>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "runXGB(train_X,train_Y,test_X,test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全局特征扩充\n",
    "- File_id + return_value分段：计数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 局部组合特征(展开形式)\n",
    "### File_id + Api  \n",
    "- File_id + Api (tid): count,nunique\n",
    "- File_id + Api (return value): nunique, max, min, median, std\n",
    "- File_id + Api (index):  nunique, max, min, median, std\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File_id + Api (tid): count,nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_pivot_features(data_merge, data_orig , groupby_features,col1 = None, col2 = None, opts = None):\n",
    "    for opt in opts:\n",
    "        print(opt)\n",
    "        train_split = data_orig.groupby(['file_id',col1])[col2].agg({'fileid_' + col1 + '_'+col2+'_'+ str(opt):opt}).reset_index() \n",
    "        \n",
    "        train_split_ =  pd.pivot_table(train_split, values = 'fileid_' + col1 + '_'+col2+'_'+ str(opt), index=['file_id'],columns=[col1])\n",
    "        new_cols = [ 'fileid_' + col1 + '_'+col2+  '_' + opt + '_' + str(col) for col in train_split_.columns]\n",
    "        \n",
    "        groupby_features.append(new_cols)\n",
    "        train_split_.columns = new_cols \n",
    "\n",
    "        train_split_.reset_index(inplace = True)\n",
    "        \n",
    "        data_merge = pd.merge(data_merge,train_split_,how='left', on='file_id') \n",
    "    return data_merge,groupby_features \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunique\n"
     ]
    }
   ],
   "source": [
    "groupby_features = []\n",
    "api_opts = ['count', 'nunique']\n",
    "train_data_,groupby_features = groupby_pivot_features(train_data, train, groupby_features, col1 = 'api', col2 = 'tid', opts = api_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File_id + Api (return value): nunique, max, min, median, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# api_opts = ['nunique','max','min','median','std']\n",
    "# train_data_,groupby_features = groupby_pivot_features(train_data_, train, groupby_features, col1 = 'api', col2 = 'return_value', opts = api_opts) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  File_id + Api(index): nunique, max, min, median, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunique\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max\n",
      "min\n",
      "median\n",
      "std\n"
     ]
    }
   ],
   "source": [
    "api_opts = ['nunique','max','min','median','std']\n",
    "train_data_,groupby_features = groupby_pivot_features(train_data_, train, groupby_features, col1 = 'api', col2 = 'index', opts = api_opts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>label</th>\n",
       "      <th>fileid_api_count</th>\n",
       "      <th>fileid_api_nunique</th>\n",
       "      <th>fileid_tid_count</th>\n",
       "      <th>fileid_tid_nunique</th>\n",
       "      <th>fileid_tid_max</th>\n",
       "      <th>fileid_tid_min</th>\n",
       "      <th>fileid_tid_median</th>\n",
       "      <th>fileid_tid_std</th>\n",
       "      <th>...</th>\n",
       "      <th>fileid_api_index_std_recv</th>\n",
       "      <th>fileid_api_index_std_recvfrom</th>\n",
       "      <th>fileid_api_index_std_select</th>\n",
       "      <th>fileid_api_index_std_send</th>\n",
       "      <th>fileid_api_index_std_sendto</th>\n",
       "      <th>fileid_api_index_std_setsockopt</th>\n",
       "      <th>fileid_api_index_std_shutdown</th>\n",
       "      <th>fileid_api_index_std_socket</th>\n",
       "      <th>fileid_api_index_std_system</th>\n",
       "      <th>fileid_api_index_std_timeGetTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>424</td>\n",
       "      <td>19</td>\n",
       "      <td>424</td>\n",
       "      <td>1</td>\n",
       "      <td>2644</td>\n",
       "      <td>2644</td>\n",
       "      <td>2644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2524</td>\n",
       "      <td>2524</td>\n",
       "      <td>2524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2516</td>\n",
       "      <td>2516</td>\n",
       "      <td>2516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2800</td>\n",
       "      <td>65</td>\n",
       "      <td>2800</td>\n",
       "      <td>5</td>\n",
       "      <td>2884</td>\n",
       "      <td>2508</td>\n",
       "      <td>2884</td>\n",
       "      <td>170.764080</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.193663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6832</td>\n",
       "      <td>78</td>\n",
       "      <td>6832</td>\n",
       "      <td>6</td>\n",
       "      <td>2968</td>\n",
       "      <td>2060</td>\n",
       "      <td>2820</td>\n",
       "      <td>48.861741</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1013.848858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_id  label  fileid_api_count  fileid_api_nunique  fileid_tid_count  \\\n",
       "0        0      0               424                  19               424   \n",
       "1        1      5                 2                   2                 2   \n",
       "2        2      5                34                  15                34   \n",
       "3        3      5              2800                  65              2800   \n",
       "4        4      5              6832                  78              6832   \n",
       "\n",
       "   fileid_tid_nunique  fileid_tid_max  fileid_tid_min  fileid_tid_median  \\\n",
       "0                   1            2644            2644               2644   \n",
       "1                   1            2524            2524               2524   \n",
       "2                   1            2516            2516               2516   \n",
       "3                   5            2884            2508               2884   \n",
       "4                   6            2968            2060               2820   \n",
       "\n",
       "   fileid_tid_std                ...                 \\\n",
       "0        0.000000                ...                  \n",
       "1        0.000000                ...                  \n",
       "2        0.000000                ...                  \n",
       "3      170.764080                ...                  \n",
       "4       48.861741                ...                  \n",
       "\n",
       "   fileid_api_index_std_recv  fileid_api_index_std_recvfrom  \\\n",
       "0                        NaN                            NaN   \n",
       "1                        NaN                            NaN   \n",
       "2                        NaN                            NaN   \n",
       "3                        NaN                            NaN   \n",
       "4                        NaN                            NaN   \n",
       "\n",
       "   fileid_api_index_std_select  fileid_api_index_std_send  \\\n",
       "0                          NaN                        NaN   \n",
       "1                          NaN                        NaN   \n",
       "2                          NaN                        NaN   \n",
       "3                          NaN                        NaN   \n",
       "4                          NaN                        NaN   \n",
       "\n",
       "   fileid_api_index_std_sendto  fileid_api_index_std_setsockopt  \\\n",
       "0                          NaN                              NaN   \n",
       "1                          NaN                              NaN   \n",
       "2                          NaN                              NaN   \n",
       "3                          NaN                              NaN   \n",
       "4                          NaN                              NaN   \n",
       "\n",
       "   fileid_api_index_std_shutdown  fileid_api_index_std_socket  \\\n",
       "0                            NaN                          NaN   \n",
       "1                            NaN                          NaN   \n",
       "2                            NaN                          NaN   \n",
       "3                            NaN                    24.193663   \n",
       "4                            NaN                  1013.848858   \n",
       "\n",
       "   fileid_api_index_std_system  fileid_api_index_std_timeGetTime  \n",
       "0                          NaN                               NaN  \n",
       "1                          NaN                               NaN  \n",
       "2                          NaN                               NaN  \n",
       "3                          NaN                               NaN  \n",
       "4                          NaN                               NaN  \n",
       "\n",
       "[5 rows x 2180 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1阶特征的线下验证(File_id + Api)（<font color=red>0.0347293</font>）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File_id + Index  \n",
    "- File_id + Index (api): count,nunique\n",
    "- File_id + Index (return value): nunique, max, min, median, std(暂时先搁置)\n",
    "- File_id + Index (tid):  nunique, max, min, median, std(暂时先搁置)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File_id +Tid (api): count,nunique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File_id + Index特征过拟合，删除\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# delcol = []\n",
    "# for i in range(2):\n",
    "#     for item in groupby_features2[i]:\n",
    "#         delcol.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_.drop(delcol,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征补充（加入index的差值特征）\n",
    "- File_id + Api (index_diff): 'nunique','max','min','median','std'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_diff = train.groupby(['file_id','tid'])['index'].diff().fillna(-999).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['index_diff'] = train_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_diff = train.loc[train.index_diff!=-999] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunique\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max\n",
      "min\n",
      "median\n",
      "std\n"
     ]
    }
   ],
   "source": [
    "api_opts = ['nunique','max','min','median','std']\n",
    "train_data_,groupby_features = groupby_pivot_features(train_data_, train_diff, groupby_features, col1 = 'api', col2 = 'index_diff', opts = api_opts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116624, 3718)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_logloss(preds,data):\n",
    "    labels_ = data.get_label()\n",
    "    classes_ = np.unique(labels_) \n",
    "    preds_prob = []\n",
    "    for i in range(len(classes_)):\n",
    "        preds_prob.append(preds[i*len(labels_):(i+1) * len(labels_)])\n",
    "    preds_prob_ = np.vstack(preds_prob) \n",
    "    \n",
    "    loss = [] \n",
    "    for i in range(preds_prob_.shape[1]):  # 样本个数\n",
    "        sum_ = 0  \n",
    "        for j in range(preds_prob_.shape[0]): #类别个数\n",
    "            pred = preds_prob_[j,i] # 第i个样本预测为第j类的概率\n",
    "            if  j == labels_[i]:\n",
    "                sum_ += np.log(pred)\n",
    "            else:\n",
    "                sum_ += np.log(1 - pred) \n",
    "             \n",
    "        loss.append(sum_)  \n",
    "         \n",
    "    return 'loss is: ' ,-1 * (np.sum(loss) / preds_prob_.shape[1]),False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线下验证(<font color=red>0.0346954</font>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "train_features = [col for col in train_data_.columns if col!='label' and col!='file_id']\n",
    "train_label = 'label'\n",
    "print(type(train_features))\n",
    "#print(len(train_features))\n",
    "#runXGB(train_data_.loc[train_ind,train_features],train_data_.loc[train_ind,train_label].values,train_data_.loc[test_ind,train_features],train_data_.loc[test_ind,train_label].values)\n",
    "# dtrain = lgb.Dataset(train_data_.loc[train_ind,train_features],train_data_.loc[train_ind,train_label].values) \n",
    "# dval   = lgb.Dataset(train_data_.loc[test_ind,train_features],train_data_.loc[test_ind,train_label].values, reference = dtrain) \n",
    "\n",
    "# params = {\n",
    "#         'task':'train', \n",
    "#         'num_leaves': 255,\n",
    "#         'objective': 'multiclass',\n",
    "#         'num_class':6,\n",
    "#         'min_data_in_leaf': 40,\n",
    "#         'learning_rate': 0.05,\n",
    "#         'feature_fraction': 0.85,\n",
    "#         'bagging_fraction': 0.9,\n",
    "#         'bagging_freq': 5, \n",
    "#         'max_bin':128,\n",
    "#         'num_threads': 64,\n",
    "#         'random_state':100\n",
    "#     }  \n",
    "# lgb_model_3_order = lgb.train(params, dtrain, num_boost_round=500,valid_sets=[dtrain,dval], early_stopping_rounds=50, feval=lgb_logloss)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删除quantile,std统计变量之后的验证(<font color=red>0.0350054</font>)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_features = [col for col in train_data_.columns if col!='label' and col!='file_id' and 'std' not in col and 'quantile' not in col]\n",
    "# train_label = 'label'\n",
    "# print(len(train_features))\n",
    "# dtrain = lgb.Dataset(train_data_.loc[train_ind,train_features],train_data_.loc[train_ind,train_label].values) \n",
    "# dval   = lgb.Dataset(train_data_.loc[test_ind,train_features],train_data_.loc[test_ind,train_label].values, reference = dtrain) \n",
    "\n",
    "# params = {\n",
    "#         'task':'train', \n",
    "#         'num_leaves': 255,\n",
    "#         'objective': 'multiclass',\n",
    "#         'num_class':6,\n",
    "#         'min_data_in_leaf': 40,\n",
    "#         'learning_rate': 0.05,\n",
    "#         'feature_fraction': 0.85,\n",
    "#         'bagging_fraction': 0.9,\n",
    "#         'bagging_freq': 5, \n",
    "#         'max_bin':128,\n",
    "#         'num_threads': 64,\n",
    "#         'random_state':100\n",
    "#     }  \n",
    "# lgb_model_3_order = lgb.train(params, dtrain, num_boost_round=500,valid_sets=[dtrain,dval], early_stopping_rounds=50, feval=lgb_logloss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_.to_csv('/data/Data_JieZhang/TC_SAFE/train_val/train_data.csv',index = None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程& 验证结果 2-Gram\n",
    "## 全局特征\n",
    "### File_id（Api_2）:count,nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['api_shift'] = train['api'].shift(-1)\n",
    "train['api_2'] = train['api'] +'_' + train['api_shift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['api_shift'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "api_count = train['api_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_opt = ['count','nunique'] \n",
    "for opt in api_opt:\n",
    "    print(opt)\n",
    "    tmp = train.groupby(['file_id'])['api_2'].agg({'fileid_api_2_' + opt: opt}).reset_index() \n",
    "    train_data_ = pd.merge(train_data_,tmp,how='left', on='file_id')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 局部特征\n",
    "### File_id + tid (Api_2): count特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "api_value_counts = pd.DataFrame(api_count).reset_index()\n",
    "api_value_counts.columns = ['api_2','api_2_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, api_value_counts, on ='api_2' , how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:4: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "api_opts = ['count']\n",
    "groupby_features =  []\n",
    "train_data_,groupby_features = groupby_pivot_features(train_data_, train.loc[train.api_2_count>=20], groupby_features, col1 = 'api_2', col2 = 'tid', opts = api_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线下验证(<font color=red> 0.0330886</font>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features = [col for col in train_data_.columns if col!='label' and col!='file_id']\n",
    "# train_label = 'label'\n",
    "# print(len(train_features))\n",
    "# dtrain = lgb.Dataset(train_data_.loc[train_ind,train_features],train_data_.loc[train_ind,train_label].values) \n",
    "# dval   = lgb.Dataset(train_data_.loc[test_ind,train_features],train_data_.loc[test_ind,train_label].values, reference = dtrain) \n",
    "\n",
    "# params = {\n",
    "#         'task':'train', \n",
    "#         'num_leaves': 255,\n",
    "#         'objective': 'multiclass',\n",
    "#         'num_class':6,\n",
    "#         'min_data_in_leaf': 40,\n",
    "#         'learning_rate': 0.05,\n",
    "#         'feature_fraction': 0.85,\n",
    "#         'bagging_fraction': 0.9,\n",
    "#         'bagging_freq': 5, \n",
    "#         'max_bin':128,\n",
    "#         'num_threads': 64,\n",
    "#         'random_state':100\n",
    "#     }  \n",
    "# lgb_model_3_order = lgb.train(params, dtrain, num_boost_round=500,valid_sets=[dtrain,dval], early_stopping_rounds=50, feval=lgb_logloss)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File_id + index (Api_2): max,min特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12236\n",
      "[1]\ttraining's multi_logloss: 1.90825\ttraining's loss is: : 2.81617\tvalid_1's multi_logloss: 1.92056\tvalid_1's loss is: : 2.83041\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's multi_logloss: 1.7664\ttraining's loss is: : 2.64826\tvalid_1's multi_logloss: 1.78989\tvalid_1's loss is: : 2.67577\n",
      "[3]\ttraining's multi_logloss: 1.64441\ttraining's loss is: : 2.50066\tvalid_1's multi_logloss: 1.67822\tvalid_1's loss is: : 2.54072\n",
      "[4]\ttraining's multi_logloss: 1.53808\ttraining's loss is: : 2.36933\tvalid_1's multi_logloss: 1.58129\tvalid_1's loss is: : 2.42106\n",
      "[5]\ttraining's multi_logloss: 1.44341\ttraining's loss is: : 2.25009\tvalid_1's multi_logloss: 1.49486\tvalid_1's loss is: : 2.31237\n",
      "[6]\ttraining's multi_logloss: 1.35794\ttraining's loss is: : 2.14047\tvalid_1's multi_logloss: 1.41736\tvalid_1's loss is: : 2.21313\n",
      "[7]\ttraining's multi_logloss: 1.28042\ttraining's loss is: : 2.03927\tvalid_1's multi_logloss: 1.3472\tvalid_1's loss is: : 2.12168\n",
      "[8]\ttraining's multi_logloss: 1.20948\ttraining's loss is: : 1.94505\tvalid_1's multi_logloss: 1.28358\tvalid_1's loss is: : 2.03733\n",
      "[9]\ttraining's multi_logloss: 1.14453\ttraining's loss is: : 1.85734\tvalid_1's multi_logloss: 1.22492\tvalid_1's loss is: : 1.95836\n",
      "[10]\ttraining's multi_logloss: 1.08453\ttraining's loss is: : 1.77504\tvalid_1's multi_logloss: 1.17135\tvalid_1's loss is: : 1.8851\n",
      "[11]\ttraining's multi_logloss: 1.02856\ttraining's loss is: : 1.69716\tvalid_1's multi_logloss: 1.12133\tvalid_1's loss is: : 1.81578\n",
      "[12]\ttraining's multi_logloss: 0.976554\ttraining's loss is: : 1.62376\tvalid_1's multi_logloss: 1.0752\tvalid_1's loss is: : 1.75093\n",
      "[13]\ttraining's multi_logloss: 0.928142\ttraining's loss is: : 1.55447\tvalid_1's multi_logloss: 1.03248\tvalid_1's loss is: : 1.69002\n",
      "[14]\ttraining's multi_logloss: 0.883126\ttraining's loss is: : 1.48916\tvalid_1's multi_logloss: 0.992714\tvalid_1's loss is: : 1.63258\n",
      "[15]\ttraining's multi_logloss: 0.840695\ttraining's loss is: : 1.42686\tvalid_1's multi_logloss: 0.955498\tvalid_1's loss is: : 1.57816\n",
      "[16]\ttraining's multi_logloss: 0.800954\ttraining's loss is: : 1.3678\tvalid_1's multi_logloss: 0.920533\tvalid_1's loss is: : 1.52646\n",
      "[17]\ttraining's multi_logloss: 0.763765\ttraining's loss is: : 1.31188\tvalid_1's multi_logloss: 0.887673\tvalid_1's loss is: : 1.47736\n",
      "[18]\ttraining's multi_logloss: 0.728787\ttraining's loss is: : 1.2587\tvalid_1's multi_logloss: 0.856913\tvalid_1's loss is: : 1.4309\n",
      "[19]\ttraining's multi_logloss: 0.695569\ttraining's loss is: : 1.20769\tvalid_1's multi_logloss: 0.828211\tvalid_1's loss is: : 1.38708\n",
      "[20]\ttraining's multi_logloss: 0.664199\ttraining's loss is: : 1.15899\tvalid_1's multi_logloss: 0.800872\tvalid_1's loss is: : 1.34494\n",
      "[21]\ttraining's multi_logloss: 0.634357\ttraining's loss is: : 1.11231\tvalid_1's multi_logloss: 0.775091\tvalid_1's loss is: : 1.30487\n",
      "[22]\ttraining's multi_logloss: 0.605941\ttraining's loss is: : 1.06746\tvalid_1's multi_logloss: 0.750618\tvalid_1's loss is: : 1.26651\n",
      "[23]\ttraining's multi_logloss: 0.579217\ttraining's loss is: : 1.02488\tvalid_1's multi_logloss: 0.727735\tvalid_1's loss is: : 1.23031\n",
      "[24]\ttraining's multi_logloss: 0.553998\ttraining's loss is: : 0.984349\tvalid_1's multi_logloss: 0.706673\tvalid_1's loss is: : 1.19664\n",
      "[25]\ttraining's multi_logloss: 0.529941\ttraining's loss is: : 0.945384\tvalid_1's multi_logloss: 0.68617\tvalid_1's loss is: : 1.16368\n",
      "[26]\ttraining's multi_logloss: 0.506906\ttraining's loss is: : 0.907815\tvalid_1's multi_logloss: 0.666587\tvalid_1's loss is: : 1.13209\n",
      "[27]\ttraining's multi_logloss: 0.485085\ttraining's loss is: : 0.871957\tvalid_1's multi_logloss: 0.64791\tvalid_1's loss is: : 1.10182\n",
      "[28]\ttraining's multi_logloss: 0.464389\ttraining's loss is: : 0.837699\tvalid_1's multi_logloss: 0.630219\tvalid_1's loss is: : 1.07294\n",
      "[29]\ttraining's multi_logloss: 0.44473\ttraining's loss is: : 0.804927\tvalid_1's multi_logloss: 0.61377\tvalid_1's loss is: : 1.04588\n",
      "[30]\ttraining's multi_logloss: 0.4259\ttraining's loss is: : 0.773345\tvalid_1's multi_logloss: 0.598212\tvalid_1's loss is: : 1.02011\n",
      "[31]\ttraining's multi_logloss: 0.40794\ttraining's loss is: : 0.743069\tvalid_1's multi_logloss: 0.583315\tvalid_1's loss is: : 0.99528\n",
      "[32]\ttraining's multi_logloss: 0.39069\ttraining's loss is: : 0.713822\tvalid_1's multi_logloss: 0.569091\tvalid_1's loss is: : 0.971497\n",
      "[33]\ttraining's multi_logloss: 0.374381\ttraining's loss is: : 0.686018\tvalid_1's multi_logloss: 0.555696\tvalid_1's loss is: : 0.948995\n",
      "[34]\ttraining's multi_logloss: 0.35876\ttraining's loss is: : 0.659245\tvalid_1's multi_logloss: 0.543135\tvalid_1's loss is: : 0.927734\n",
      "[35]\ttraining's multi_logloss: 0.343904\ttraining's loss is: : 0.633634\tvalid_1's multi_logloss: 0.531209\tvalid_1's loss is: : 0.907459\n",
      "[36]\ttraining's multi_logloss: 0.32964\ttraining's loss is: : 0.608957\tvalid_1's multi_logloss: 0.519762\tvalid_1's loss is: : 0.887926\n",
      "[37]\ttraining's multi_logloss: 0.316108\ttraining's loss is: : 0.585414\tvalid_1's multi_logloss: 0.508903\tvalid_1's loss is: : 0.869326\n",
      "[38]\ttraining's multi_logloss: 0.303214\ttraining's loss is: : 0.562877\tvalid_1's multi_logloss: 0.498482\tvalid_1's loss is: : 0.851482\n",
      "[39]\ttraining's multi_logloss: 0.290812\ttraining's loss is: : 0.54111\tvalid_1's multi_logloss: 0.48849\tvalid_1's loss is: : 0.834326\n",
      "[40]\ttraining's multi_logloss: 0.279049\ttraining's loss is: : 0.520365\tvalid_1's multi_logloss: 0.479091\tvalid_1's loss is: : 0.81804\n",
      "[41]\ttraining's multi_logloss: 0.267642\ttraining's loss is: : 0.500194\tvalid_1's multi_logloss: 0.469912\tvalid_1's loss is: : 0.802232\n",
      "[42]\ttraining's multi_logloss: 0.256756\ttraining's loss is: : 0.480875\tvalid_1's multi_logloss: 0.461132\tvalid_1's loss is: : 0.787072\n",
      "[43]\ttraining's multi_logloss: 0.246276\ttraining's loss is: : 0.462203\tvalid_1's multi_logloss: 0.452835\tvalid_1's loss is: : 0.772721\n",
      "[44]\ttraining's multi_logloss: 0.236308\ttraining's loss is: : 0.444381\tvalid_1's multi_logloss: 0.445202\tvalid_1's loss is: : 0.759409\n",
      "[45]\ttraining's multi_logloss: 0.226883\ttraining's loss is: : 0.42744\tvalid_1's multi_logloss: 0.437831\tvalid_1's loss is: : 0.746604\n",
      "[46]\ttraining's multi_logloss: 0.217787\ttraining's loss is: : 0.411061\tvalid_1's multi_logloss: 0.430787\tvalid_1's loss is: : 0.73432\n",
      "[47]\ttraining's multi_logloss: 0.209078\ttraining's loss is: : 0.395321\tvalid_1's multi_logloss: 0.42435\tvalid_1's loss is: : 0.723004\n",
      "[48]\ttraining's multi_logloss: 0.200714\ttraining's loss is: : 0.38016\tvalid_1's multi_logloss: 0.418208\tvalid_1's loss is: : 0.712147\n",
      "[49]\ttraining's multi_logloss: 0.192732\ttraining's loss is: : 0.365651\tvalid_1's multi_logloss: 0.412177\tvalid_1's loss is: : 0.701588\n",
      "[50]\ttraining's multi_logloss: 0.185053\ttraining's loss is: : 0.351648\tvalid_1's multi_logloss: 0.406677\tvalid_1's loss is: : 0.691801\n",
      "[51]\ttraining's multi_logloss: 0.177728\ttraining's loss is: : 0.338248\tvalid_1's multi_logloss: 0.401446\tvalid_1's loss is: : 0.682569\n",
      "[52]\ttraining's multi_logloss: 0.170654\ttraining's loss is: : 0.325288\tvalid_1's multi_logloss: 0.396174\tvalid_1's loss is: : 0.673259\n",
      "[53]\ttraining's multi_logloss: 0.163948\ttraining's loss is: : 0.312951\tvalid_1's multi_logloss: 0.391198\tvalid_1's loss is: : 0.664466\n",
      "[54]\ttraining's multi_logloss: 0.157468\ttraining's loss is: : 0.301008\tvalid_1's multi_logloss: 0.38649\tvalid_1's loss is: : 0.656172\n",
      "[55]\ttraining's multi_logloss: 0.151274\ttraining's loss is: : 0.289559\tvalid_1's multi_logloss: 0.382204\tvalid_1's loss is: : 0.648541\n",
      "[56]\ttraining's multi_logloss: 0.14527\ttraining's loss is: : 0.278452\tvalid_1's multi_logloss: 0.377978\tvalid_1's loss is: : 0.641073\n",
      "[57]\ttraining's multi_logloss: 0.139582\ttraining's loss is: : 0.267897\tvalid_1's multi_logloss: 0.373886\tvalid_1's loss is: : 0.633879\n",
      "[58]\ttraining's multi_logloss: 0.134135\ttraining's loss is: : 0.257766\tvalid_1's multi_logloss: 0.370216\tvalid_1's loss is: : 0.627353\n",
      "[59]\ttraining's multi_logloss: 0.128886\ttraining's loss is: : 0.247989\tvalid_1's multi_logloss: 0.366885\tvalid_1's loss is: : 0.621431\n",
      "[60]\ttraining's multi_logloss: 0.12385\ttraining's loss is: : 0.238582\tvalid_1's multi_logloss: 0.363389\tvalid_1's loss is: : 0.615355\n",
      "[61]\ttraining's multi_logloss: 0.118987\ttraining's loss is: : 0.229488\tvalid_1's multi_logloss: 0.360251\tvalid_1's loss is: : 0.609829\n",
      "[62]\ttraining's multi_logloss: 0.114318\ttraining's loss is: : 0.220738\tvalid_1's multi_logloss: 0.357381\tvalid_1's loss is: : 0.604729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63]\ttraining's multi_logloss: 0.109875\ttraining's loss is: : 0.212393\tvalid_1's multi_logloss: 0.354111\tvalid_1's loss is: : 0.599118\n",
      "[64]\ttraining's multi_logloss: 0.105601\ttraining's loss is: : 0.204351\tvalid_1's multi_logloss: 0.351429\tvalid_1's loss is: : 0.594374\n",
      "[65]\ttraining's multi_logloss: 0.101489\ttraining's loss is: : 0.196593\tvalid_1's multi_logloss: 0.348967\tvalid_1's loss is: : 0.590063\n",
      "[66]\ttraining's multi_logloss: 0.0975043\ttraining's loss is: : 0.189071\tvalid_1's multi_logloss: 0.346486\tvalid_1's loss is: : 0.585778\n",
      "[67]\ttraining's multi_logloss: 0.0936928\ttraining's loss is: : 0.181861\tvalid_1's multi_logloss: 0.344046\tvalid_1's loss is: : 0.581524\n",
      "[68]\ttraining's multi_logloss: 0.0900635\ttraining's loss is: : 0.17498\tvalid_1's multi_logloss: 0.341734\tvalid_1's loss is: : 0.577578\n",
      "[69]\ttraining's multi_logloss: 0.086594\ttraining's loss is: : 0.16839\tvalid_1's multi_logloss: 0.33952\tvalid_1's loss is: : 0.573784\n",
      "[70]\ttraining's multi_logloss: 0.0833025\ttraining's loss is: : 0.162128\tvalid_1's multi_logloss: 0.337602\tvalid_1's loss is: : 0.570458\n",
      "[71]\ttraining's multi_logloss: 0.0800773\ttraining's loss is: : 0.155987\tvalid_1's multi_logloss: 0.335933\tvalid_1's loss is: : 0.567505\n",
      "[72]\ttraining's multi_logloss: 0.076983\ttraining's loss is: : 0.150086\tvalid_1's multi_logloss: 0.334096\tvalid_1's loss is: : 0.564415\n",
      "[73]\ttraining's multi_logloss: 0.0740294\ttraining's loss is: : 0.144443\tvalid_1's multi_logloss: 0.332228\tvalid_1's loss is: : 0.561257\n",
      "[74]\ttraining's multi_logloss: 0.0712099\ttraining's loss is: : 0.139045\tvalid_1's multi_logloss: 0.330842\tvalid_1's loss is: : 0.558803\n",
      "[75]\ttraining's multi_logloss: 0.0684856\ttraining's loss is: : 0.133822\tvalid_1's multi_logloss: 0.329386\tvalid_1's loss is: : 0.556336\n",
      "[76]\ttraining's multi_logloss: 0.0658205\ttraining's loss is: : 0.128712\tvalid_1's multi_logloss: 0.327849\tvalid_1's loss is: : 0.553826\n",
      "[77]\ttraining's multi_logloss: 0.0633134\ttraining's loss is: : 0.123896\tvalid_1's multi_logloss: 0.326368\tvalid_1's loss is: : 0.551398\n",
      "[78]\ttraining's multi_logloss: 0.0609074\ttraining's loss is: : 0.119266\tvalid_1's multi_logloss: 0.325233\tvalid_1's loss is: : 0.549503\n",
      "[79]\ttraining's multi_logloss: 0.0585798\ttraining's loss is: : 0.114782\tvalid_1's multi_logloss: 0.324104\tvalid_1's loss is: : 0.547633\n",
      "[80]\ttraining's multi_logloss: 0.0563709\ttraining's loss is: : 0.110522\tvalid_1's multi_logloss: 0.323144\tvalid_1's loss is: : 0.546122\n",
      "[81]\ttraining's multi_logloss: 0.0542073\ttraining's loss is: : 0.106353\tvalid_1's multi_logloss: 0.322383\tvalid_1's loss is: : 0.544899\n",
      "[82]\ttraining's multi_logloss: 0.0521054\ttraining's loss is: : 0.102297\tvalid_1's multi_logloss: 0.321488\tvalid_1's loss is: : 0.543505\n",
      "[83]\ttraining's multi_logloss: 0.0500874\ttraining's loss is: : 0.0983978\tvalid_1's multi_logloss: 0.320799\tvalid_1's loss is: : 0.542458\n",
      "[84]\ttraining's multi_logloss: 0.0481415\ttraining's loss is: : 0.0946342\tvalid_1's multi_logloss: 0.320204\tvalid_1's loss is: : 0.541552\n",
      "[85]\ttraining's multi_logloss: 0.0462877\ttraining's loss is: : 0.0910436\tvalid_1's multi_logloss: 0.319564\tvalid_1's loss is: : 0.540575\n",
      "[86]\ttraining's multi_logloss: 0.0444902\ttraining's loss is: : 0.0875609\tvalid_1's multi_logloss: 0.318937\tvalid_1's loss is: : 0.539661\n",
      "[87]\ttraining's multi_logloss: 0.0427774\ttraining's loss is: : 0.0842371\tvalid_1's multi_logloss: 0.318292\tvalid_1's loss is: : 0.538696\n",
      "[88]\ttraining's multi_logloss: 0.0411403\ttraining's loss is: : 0.0810573\tvalid_1's multi_logloss: 0.317676\tvalid_1's loss is: : 0.53781\n",
      "[89]\ttraining's multi_logloss: 0.0395835\ttraining's loss is: : 0.0780297\tvalid_1's multi_logloss: 0.317388\tvalid_1's loss is: : 0.537468\n",
      "[90]\ttraining's multi_logloss: 0.0380927\ttraining's loss is: : 0.0751272\tvalid_1's multi_logloss: 0.317162\tvalid_1's loss is: : 0.537266\n",
      "[91]\ttraining's multi_logloss: 0.0366448\ttraining's loss is: : 0.072304\tvalid_1's multi_logloss: 0.316999\tvalid_1's loss is: : 0.53711\n",
      "[92]\ttraining's multi_logloss: 0.0352705\ttraining's loss is: : 0.0696215\tvalid_1's multi_logloss: 0.316857\tvalid_1's loss is: : 0.537084\n",
      "[93]\ttraining's multi_logloss: 0.0339552\ttraining's loss is: : 0.0670518\tvalid_1's multi_logloss: 0.316638\tvalid_1's loss is: : 0.536914\n",
      "[94]\ttraining's multi_logloss: 0.0326861\ttraining's loss is: : 0.0645707\tvalid_1's multi_logloss: 0.316545\tvalid_1's loss is: : 0.536977\n",
      "[95]\ttraining's multi_logloss: 0.0314704\ttraining's loss is: : 0.0621919\tvalid_1's multi_logloss: 0.316538\tvalid_1's loss is: : 0.537064\n",
      "[96]\ttraining's multi_logloss: 0.0302971\ttraining's loss is: : 0.0598966\tvalid_1's multi_logloss: 0.316489\tvalid_1's loss is: : 0.537225\n",
      "[97]\ttraining's multi_logloss: 0.0291617\ttraining's loss is: : 0.0576743\tvalid_1's multi_logloss: 0.316366\tvalid_1's loss is: : 0.53719\n",
      "[98]\ttraining's multi_logloss: 0.028085\ttraining's loss is: : 0.0555642\tvalid_1's multi_logloss: 0.316227\tvalid_1's loss is: : 0.537176\n",
      "[99]\ttraining's multi_logloss: 0.0270546\ttraining's loss is: : 0.0535439\tvalid_1's multi_logloss: 0.316357\tvalid_1's loss is: : 0.53762\n",
      "[100]\ttraining's multi_logloss: 0.0260603\ttraining's loss is: : 0.0515926\tvalid_1's multi_logloss: 0.316364\tvalid_1's loss is: : 0.537916\n",
      "[101]\ttraining's multi_logloss: 0.0250948\ttraining's loss is: : 0.0496975\tvalid_1's multi_logloss: 0.316562\tvalid_1's loss is: : 0.538526\n",
      "[102]\ttraining's multi_logloss: 0.0241782\ttraining's loss is: : 0.0478967\tvalid_1's multi_logloss: 0.316849\tvalid_1's loss is: : 0.539264\n",
      "[103]\ttraining's multi_logloss: 0.0233006\ttraining's loss is: : 0.0461713\tvalid_1's multi_logloss: 0.316902\tvalid_1's loss is: : 0.539698\n",
      "[104]\ttraining's multi_logloss: 0.0224614\ttraining's loss is: : 0.0445202\tvalid_1's multi_logloss: 0.317095\tvalid_1's loss is: : 0.540255\n",
      "[105]\ttraining's multi_logloss: 0.0216475\ttraining's loss is: : 0.0429183\tvalid_1's multi_logloss: 0.317374\tvalid_1's loss is: : 0.541047\n",
      "[106]\ttraining's multi_logloss: 0.0208167\ttraining's loss is: : 0.0412842\tvalid_1's multi_logloss: 0.317574\tvalid_1's loss is: : 0.541732\n",
      "[107]\ttraining's multi_logloss: 0.0200159\ttraining's loss is: : 0.0397085\tvalid_1's multi_logloss: 0.31765\tvalid_1's loss is: : 0.542132\n",
      "[108]\ttraining's multi_logloss: 0.0192522\ttraining's loss is: : 0.0382044\tvalid_1's multi_logloss: 0.317923\tvalid_1's loss is: : 0.542864\n",
      "[109]\ttraining's multi_logloss: 0.0185108\ttraining's loss is: : 0.0367436\tvalid_1's multi_logloss: 0.318155\tvalid_1's loss is: : 0.543552\n",
      "[110]\ttraining's multi_logloss: 0.0178154\ttraining's loss is: : 0.0353723\tvalid_1's multi_logloss: 0.318435\tvalid_1's loss is: : 0.544264\n",
      "[111]\ttraining's multi_logloss: 0.0171383\ttraining's loss is: : 0.0340366\tvalid_1's multi_logloss: 0.318857\tvalid_1's loss is: : 0.545266\n",
      "[112]\ttraining's multi_logloss: 0.0164915\ttraining's loss is: : 0.0327601\tvalid_1's multi_logloss: 0.31927\tvalid_1's loss is: : 0.546311\n",
      "[113]\ttraining's multi_logloss: 0.0158643\ttraining's loss is: : 0.0315216\tvalid_1's multi_logloss: 0.319763\tvalid_1's loss is: : 0.547494\n",
      "[114]\ttraining's multi_logloss: 0.0152653\ttraining's loss is: : 0.0303382\tvalid_1's multi_logloss: 0.320388\tvalid_1's loss is: : 0.548872\n",
      "[115]\ttraining's multi_logloss: 0.0146866\ttraining's loss is: : 0.0291942\tvalid_1's multi_logloss: 0.320772\tvalid_1's loss is: : 0.549795\n",
      "[116]\ttraining's multi_logloss: 0.0141331\ttraining's loss is: : 0.0280997\tvalid_1's multi_logloss: 0.32136\tvalid_1's loss is: : 0.551088\n",
      "[117]\ttraining's multi_logloss: 0.0136076\ttraining's loss is: : 0.02706\tvalid_1's multi_logloss: 0.322171\tvalid_1's loss is: : 0.552673\n",
      "[118]\ttraining's multi_logloss: 0.0131105\ttraining's loss is: : 0.0260758\tvalid_1's multi_logloss: 0.322776\tvalid_1's loss is: : 0.55387\n",
      "[119]\ttraining's multi_logloss: 0.0126347\ttraining's loss is: : 0.0251336\tvalid_1's multi_logloss: 0.323436\tvalid_1's loss is: : 0.555166\n",
      "[120]\ttraining's multi_logloss: 0.0121683\ttraining's loss is: : 0.0242095\tvalid_1's multi_logloss: 0.324263\tvalid_1's loss is: : 0.556835\n",
      "[121]\ttraining's multi_logloss: 0.0117035\ttraining's loss is: : 0.0232891\tvalid_1's multi_logloss: 0.32488\tvalid_1's loss is: : 0.558246\n",
      "[122]\ttraining's multi_logloss: 0.0112584\ttraining's loss is: : 0.0224074\tvalid_1's multi_logloss: 0.325591\tvalid_1's loss is: : 0.55978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123]\ttraining's multi_logloss: 0.0108364\ttraining's loss is: : 0.0215714\tvalid_1's multi_logloss: 0.326212\tvalid_1's loss is: : 0.561192\n",
      "[124]\ttraining's multi_logloss: 0.0104299\ttraining's loss is: : 0.0207655\tvalid_1's multi_logloss: 0.326855\tvalid_1's loss is: : 0.56255\n",
      "[125]\ttraining's multi_logloss: 0.0100383\ttraining's loss is: : 0.0199888\tvalid_1's multi_logloss: 0.327589\tvalid_1's loss is: : 0.564102\n",
      "[126]\ttraining's multi_logloss: 0.00966387\ttraining's loss is: : 0.0192463\tvalid_1's multi_logloss: 0.328251\tvalid_1's loss is: : 0.565496\n",
      "[127]\ttraining's multi_logloss: 0.00930306\ttraining's loss is: : 0.0185304\tvalid_1's multi_logloss: 0.329061\tvalid_1's loss is: : 0.567172\n",
      "[128]\ttraining's multi_logloss: 0.00895435\ttraining's loss is: : 0.0178384\tvalid_1's multi_logloss: 0.329773\tvalid_1's loss is: : 0.568687\n",
      "[129]\ttraining's multi_logloss: 0.00862021\ttraining's loss is: : 0.0171752\tvalid_1's multi_logloss: 0.330612\tvalid_1's loss is: : 0.570442\n",
      "[130]\ttraining's multi_logloss: 0.00830182\ttraining's loss is: : 0.016543\tvalid_1's multi_logloss: 0.331456\tvalid_1's loss is: : 0.572168\n",
      "[131]\ttraining's multi_logloss: 0.00799225\ttraining's loss is: : 0.0159282\tvalid_1's multi_logloss: 0.332171\tvalid_1's loss is: : 0.573713\n",
      "[132]\ttraining's multi_logloss: 0.00769811\ttraining's loss is: : 0.0153438\tvalid_1's multi_logloss: 0.333124\tvalid_1's loss is: : 0.57568\n",
      "[133]\ttraining's multi_logloss: 0.00741437\ttraining's loss is: : 0.0147798\tvalid_1's multi_logloss: 0.333953\tvalid_1's loss is: : 0.577409\n",
      "[134]\ttraining's multi_logloss: 0.00714643\ttraining's loss is: : 0.0142472\tvalid_1's multi_logloss: 0.334653\tvalid_1's loss is: : 0.578877\n",
      "[135]\ttraining's multi_logloss: 0.00688838\ttraining's loss is: : 0.0137341\tvalid_1's multi_logloss: 0.335446\tvalid_1's loss is: : 0.580554\n",
      "[136]\ttraining's multi_logloss: 0.00663641\ttraining's loss is: : 0.0132331\tvalid_1's multi_logloss: 0.336295\tvalid_1's loss is: : 0.58228\n",
      "[137]\ttraining's multi_logloss: 0.00639192\ttraining's loss is: : 0.0127469\tvalid_1's multi_logloss: 0.337232\tvalid_1's loss is: : 0.58419\n",
      "[138]\ttraining's multi_logloss: 0.00615912\ttraining's loss is: : 0.0122837\tvalid_1's multi_logloss: 0.33828\tvalid_1's loss is: : 0.58626\n",
      "[139]\ttraining's multi_logloss: 0.00593774\ttraining's loss is: : 0.0118433\tvalid_1's multi_logloss: 0.339247\tvalid_1's loss is: : 0.588201\n",
      "[140]\ttraining's multi_logloss: 0.00572555\ttraining's loss is: : 0.011421\tvalid_1's multi_logloss: 0.339976\tvalid_1's loss is: : 0.589764\n",
      "[141]\ttraining's multi_logloss: 0.00551842\ttraining's loss is: : 0.0110087\tvalid_1's multi_logloss: 0.340873\tvalid_1's loss is: : 0.591587\n",
      "[142]\ttraining's multi_logloss: 0.00531676\ttraining's loss is: : 0.0106072\tvalid_1's multi_logloss: 0.341771\tvalid_1's loss is: : 0.593489\n",
      "[143]\ttraining's multi_logloss: 0.00512512\ttraining's loss is: : 0.0102256\tvalid_1's multi_logloss: 0.34267\tvalid_1's loss is: : 0.595339\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's multi_logloss: 0.0339552\ttraining's loss is: : 0.0670518\tvalid_1's multi_logloss: 0.316638\tvalid_1's loss is: : 0.536914\n"
     ]
    }
   ],
   "source": [
    "train_features = [col for col in train_data_.columns if col!='label' and col!='file_id']\n",
    "train_label = 'label'\n",
    "print(len(train_features))\n",
    "train_X, test_X, train_Y, test_Y = train_test_split( train_data_[train_features],train_data_[train_label].values, test_size = 0.33) \n",
    "\n",
    "dtrain = lgb.Dataset(train_X,train_Y) \n",
    "dval   = lgb.Dataset(test_X,test_Y, reference = dtrain) \n",
    "\n",
    "params = {\n",
    "        'task':'train', \n",
    "        'num_leaves': 255,\n",
    "        'objective': 'multiclass',\n",
    "        'num_class':8,\n",
    "        #'min_data_in_leaf': 40,\n",
    "        'min_data_in_leaf': 10,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.85,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 5, \n",
    "        'max_bin':128,\n",
    "        'num_threads': 64,\n",
    "        'random_state':100\n",
    "    }  \n",
    "lgb_model_3_order = lgb.train(params, dtrain, num_boost_round=500,valid_sets=[dtrain,dval], early_stopping_rounds=50, feval=lgb_logloss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_imp = pd.DataFrame({'feature':train_features, 'imp':lgb_model_3_order.feature_importance()}).sort_values('imp')\n",
    "important_features = fea_imp.loc[fea_imp.imp >=1, 'feature'].values\n",
    "important_features = list(important_features)\n",
    "\n",
    "important_features.append('file_id')\n",
    "important_features.append('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_[important_features].to_csv('../feature_final/train_data_2gram.csv',index = None)\n",
    "\n",
    "train_ind = train_X.index\n",
    "test_ind = test_X.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:4: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min\n"
     ]
    }
   ],
   "source": [
    "api_opts = ['max','min']\n",
    "train_data_,groupby_features = groupby_pivot_features(train_data_[important_features], train.loc[train.api_2_count>=20], groupby_features, col1 = 'api_2', col2 = 'index', opts = api_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_logloss: 1.90856\ttraining's loss is: : 2.81654\tvalid_1's multi_logloss: 1.92087\tvalid_1's loss is: : 2.83077\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's multi_logloss: 1.76571\ttraining's loss is: : 2.64745\tvalid_1's multi_logloss: 1.78921\tvalid_1's loss is: : 2.67497\n",
      "[3]\ttraining's multi_logloss: 1.64335\ttraining's loss is: : 2.49943\tvalid_1's multi_logloss: 1.67637\tvalid_1's loss is: : 2.53858\n",
      "[4]\ttraining's multi_logloss: 1.53597\ttraining's loss is: : 2.3668\tvalid_1's multi_logloss: 1.5782\tvalid_1's loss is: : 2.41745\n",
      "[5]\ttraining's multi_logloss: 1.44075\ttraining's loss is: : 2.24685\tvalid_1's multi_logloss: 1.49107\tvalid_1's loss is: : 2.30783\n",
      "[6]\ttraining's multi_logloss: 1.3547\ttraining's loss is: : 2.13643\tvalid_1's multi_logloss: 1.41293\tvalid_1's loss is: : 2.20775\n",
      "[7]\ttraining's multi_logloss: 1.27698\ttraining's loss is: : 2.03491\tvalid_1's multi_logloss: 1.34204\tvalid_1's loss is: : 2.11535\n",
      "[8]\ttraining's multi_logloss: 1.20605\ttraining's loss is: : 1.94062\tvalid_1's multi_logloss: 1.27811\tvalid_1's loss is: : 2.03057\n",
      "[9]\ttraining's multi_logloss: 1.14103\ttraining's loss is: : 1.85278\tvalid_1's multi_logloss: 1.2195\tvalid_1's loss is: : 1.95166\n",
      "[10]\ttraining's multi_logloss: 1.0812\ttraining's loss is: : 1.77064\tvalid_1's multi_logloss: 1.16593\tvalid_1's loss is: : 1.87834\n",
      "[11]\ttraining's multi_logloss: 1.02552\ttraining's loss is: : 1.69311\tvalid_1's multi_logloss: 1.11574\tvalid_1's loss is: : 1.80875\n",
      "[12]\ttraining's multi_logloss: 0.973664\ttraining's loss is: : 1.61985\tvalid_1's multi_logloss: 1.06962\tvalid_1's loss is: : 1.74385\n",
      "[13]\ttraining's multi_logloss: 0.925313\ttraining's loss is: : 1.55059\tvalid_1's multi_logloss: 1.02654\tvalid_1's loss is: : 1.68245\n",
      "[14]\ttraining's multi_logloss: 0.880372\ttraining's loss is: : 1.48533\tvalid_1's multi_logloss: 0.986352\tvalid_1's loss is: : 1.62442\n",
      "[15]\ttraining's multi_logloss: 0.838061\ttraining's loss is: : 1.42313\tvalid_1's multi_logloss: 0.948768\tvalid_1's loss is: : 1.56946\n",
      "[16]\ttraining's multi_logloss: 0.798185\ttraining's loss is: : 1.36384\tvalid_1's multi_logloss: 0.913706\tvalid_1's loss is: : 1.5176\n",
      "[17]\ttraining's multi_logloss: 0.760602\ttraining's loss is: : 1.30733\tvalid_1's multi_logloss: 0.88053\tvalid_1's loss is: : 1.46803\n",
      "[18]\ttraining's multi_logloss: 0.725431\ttraining's loss is: : 1.25382\tvalid_1's multi_logloss: 0.84948\tvalid_1's loss is: : 1.4211\n",
      "[19]\ttraining's multi_logloss: 0.692034\ttraining's loss is: : 1.2025\tvalid_1's multi_logloss: 0.820372\tvalid_1's loss is: : 1.37661\n",
      "[20]\ttraining's multi_logloss: 0.66084\ttraining's loss is: : 1.15401\tvalid_1's multi_logloss: 0.793067\tvalid_1's loss is: : 1.33447\n",
      "[21]\ttraining's multi_logloss: 0.631066\ttraining's loss is: : 1.10737\tvalid_1's multi_logloss: 0.767356\tvalid_1's loss is: : 1.29437\n",
      "[22]\ttraining's multi_logloss: 0.602775\ttraining's loss is: : 1.06266\tvalid_1's multi_logloss: 0.742825\tvalid_1's loss is: : 1.25585\n",
      "[23]\ttraining's multi_logloss: 0.57613\ttraining's loss is: : 1.02016\tvalid_1's multi_logloss: 0.719977\tvalid_1's loss is: : 1.21958\n",
      "[24]\ttraining's multi_logloss: 0.550826\ttraining's loss is: : 0.979467\tvalid_1's multi_logloss: 0.698204\tvalid_1's loss is: : 1.18486\n",
      "[25]\ttraining's multi_logloss: 0.526815\ttraining's loss is: : 0.940518\tvalid_1's multi_logloss: 0.677629\tvalid_1's loss is: : 1.15177\n",
      "[26]\ttraining's multi_logloss: 0.504013\ttraining's loss is: : 0.903269\tvalid_1's multi_logloss: 0.658216\tvalid_1's loss is: : 1.12033\n",
      "[27]\ttraining's multi_logloss: 0.482214\ttraining's loss is: : 0.867411\tvalid_1's multi_logloss: 0.639891\tvalid_1's loss is: : 1.09044\n",
      "[28]\ttraining's multi_logloss: 0.461599\ttraining's loss is: : 0.833237\tvalid_1's multi_logloss: 0.6227\tvalid_1's loss is: : 1.06213\n",
      "[29]\ttraining's multi_logloss: 0.442041\ttraining's loss is: : 0.800584\tvalid_1's multi_logloss: 0.606131\tvalid_1's loss is: : 1.03475\n",
      "[30]\ttraining's multi_logloss: 0.423349\ttraining's loss is: : 0.769185\tvalid_1's multi_logloss: 0.590357\tvalid_1's loss is: : 1.00865\n",
      "[31]\ttraining's multi_logloss: 0.405361\ttraining's loss is: : 0.738846\tvalid_1's multi_logloss: 0.575381\tvalid_1's loss is: : 0.98373\n",
      "[32]\ttraining's multi_logloss: 0.38829\ttraining's loss is: : 0.709874\tvalid_1's multi_logloss: 0.561571\tvalid_1's loss is: : 0.960484\n",
      "[33]\ttraining's multi_logloss: 0.372023\ttraining's loss is: : 0.682108\tvalid_1's multi_logloss: 0.548281\tvalid_1's loss is: : 0.938055\n",
      "[34]\ttraining's multi_logloss: 0.356577\ttraining's loss is: : 0.655576\tvalid_1's multi_logloss: 0.535722\tvalid_1's loss is: : 0.91675\n",
      "[35]\ttraining's multi_logloss: 0.341752\ttraining's loss is: : 0.630004\tvalid_1's multi_logloss: 0.523803\tvalid_1's loss is: : 0.896492\n",
      "[36]\ttraining's multi_logloss: 0.327575\ttraining's loss is: : 0.605448\tvalid_1's multi_logloss: 0.512377\tvalid_1's loss is: : 0.877007\n",
      "[37]\ttraining's multi_logloss: 0.314073\ttraining's loss is: : 0.58193\tvalid_1's multi_logloss: 0.501429\tvalid_1's loss is: : 0.858225\n",
      "[38]\ttraining's multi_logloss: 0.301198\ttraining's loss is: : 0.559409\tvalid_1's multi_logloss: 0.491126\tvalid_1's loss is: : 0.840488\n",
      "[39]\ttraining's multi_logloss: 0.288903\ttraining's loss is: : 0.537801\tvalid_1's multi_logloss: 0.481406\tvalid_1's loss is: : 0.823662\n",
      "[40]\ttraining's multi_logloss: 0.277206\ttraining's loss is: : 0.517148\tvalid_1's multi_logloss: 0.472108\tvalid_1's loss is: : 0.807555\n",
      "[41]\ttraining's multi_logloss: 0.265854\ttraining's loss is: : 0.497057\tvalid_1's multi_logloss: 0.463293\tvalid_1's loss is: : 0.792235\n",
      "[42]\ttraining's multi_logloss: 0.255063\ttraining's loss is: : 0.477885\tvalid_1's multi_logloss: 0.45489\tvalid_1's loss is: : 0.777557\n",
      "[43]\ttraining's multi_logloss: 0.244806\ttraining's loss is: : 0.459579\tvalid_1's multi_logloss: 0.447024\tvalid_1's loss is: : 0.763801\n",
      "[44]\ttraining's multi_logloss: 0.234904\ttraining's loss is: : 0.441845\tvalid_1's multi_logloss: 0.439296\tvalid_1's loss is: : 0.750265\n",
      "[45]\ttraining's multi_logloss: 0.225465\ttraining's loss is: : 0.424882\tvalid_1's multi_logloss: 0.431952\tvalid_1's loss is: : 0.737405\n",
      "[46]\ttraining's multi_logloss: 0.216386\ttraining's loss is: : 0.408519\tvalid_1's multi_logloss: 0.425105\tvalid_1's loss is: : 0.725385\n",
      "[47]\ttraining's multi_logloss: 0.207744\ttraining's loss is: : 0.392884\tvalid_1's multi_logloss: 0.418736\tvalid_1's loss is: : 0.714137\n",
      "[48]\ttraining's multi_logloss: 0.199455\ttraining's loss is: : 0.377834\tvalid_1's multi_logloss: 0.412657\tvalid_1's loss is: : 0.703386\n",
      "[49]\ttraining's multi_logloss: 0.191525\ttraining's loss is: : 0.363393\tvalid_1's multi_logloss: 0.406751\tvalid_1's loss is: : 0.69296\n",
      "[50]\ttraining's multi_logloss: 0.183917\ttraining's loss is: : 0.349498\tvalid_1's multi_logloss: 0.401374\tvalid_1's loss is: : 0.683354\n",
      "[51]\ttraining's multi_logloss: 0.17659\ttraining's loss is: : 0.336089\tvalid_1's multi_logloss: 0.396031\tvalid_1's loss is: : 0.673881\n",
      "[52]\ttraining's multi_logloss: 0.16958\ttraining's loss is: : 0.323231\tvalid_1's multi_logloss: 0.390834\tvalid_1's loss is: : 0.664689\n",
      "[53]\ttraining's multi_logloss: 0.162885\ttraining's loss is: : 0.310917\tvalid_1's multi_logloss: 0.385976\tvalid_1's loss is: : 0.656052\n",
      "[54]\ttraining's multi_logloss: 0.156498\ttraining's loss is: : 0.299128\tvalid_1's multi_logloss: 0.381328\tvalid_1's loss is: : 0.647799\n",
      "[55]\ttraining's multi_logloss: 0.150363\ttraining's loss is: : 0.287775\tvalid_1's multi_logloss: 0.37704\tvalid_1's loss is: : 0.640127\n",
      "[56]\ttraining's multi_logloss: 0.144448\ttraining's loss is: : 0.276819\tvalid_1's multi_logloss: 0.372944\tvalid_1's loss is: : 0.63283\n",
      "[57]\ttraining's multi_logloss: 0.138778\ttraining's loss is: : 0.266293\tvalid_1's multi_logloss: 0.368911\tvalid_1's loss is: : 0.625716\n",
      "[58]\ttraining's multi_logloss: 0.133322\ttraining's loss is: : 0.256147\tvalid_1's multi_logloss: 0.365084\tvalid_1's loss is: : 0.618963\n",
      "[59]\ttraining's multi_logloss: 0.128106\ttraining's loss is: : 0.246422\tvalid_1's multi_logloss: 0.361351\tvalid_1's loss is: : 0.612393\n",
      "[60]\ttraining's multi_logloss: 0.123115\ttraining's loss is: : 0.237091\tvalid_1's multi_logloss: 0.35796\tvalid_1's loss is: : 0.606445\n",
      "[61]\ttraining's multi_logloss: 0.118251\ttraining's loss is: : 0.227995\tvalid_1's multi_logloss: 0.354818\tvalid_1's loss is: : 0.600877\n",
      "[62]\ttraining's multi_logloss: 0.113634\ttraining's loss is: : 0.219343\tvalid_1's multi_logloss: 0.351774\tvalid_1's loss is: : 0.595464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63]\ttraining's multi_logloss: 0.109227\ttraining's loss is: : 0.21106\tvalid_1's multi_logloss: 0.348992\tvalid_1's loss is: : 0.590537\n",
      "[64]\ttraining's multi_logloss: 0.104992\ttraining's loss is: : 0.203088\tvalid_1's multi_logloss: 0.346622\tvalid_1's loss is: : 0.586319\n",
      "[65]\ttraining's multi_logloss: 0.100929\ttraining's loss is: : 0.195426\tvalid_1's multi_logloss: 0.344024\tvalid_1's loss is: : 0.581803\n",
      "[66]\ttraining's multi_logloss: 0.0969796\ttraining's loss is: : 0.18797\tvalid_1's multi_logloss: 0.341403\tvalid_1's loss is: : 0.577185\n",
      "[67]\ttraining's multi_logloss: 0.0931925\ttraining's loss is: : 0.180804\tvalid_1's multi_logloss: 0.338987\tvalid_1's loss is: : 0.572995\n",
      "[68]\ttraining's multi_logloss: 0.0896026\ttraining's loss is: : 0.173997\tvalid_1's multi_logloss: 0.336951\tvalid_1's loss is: : 0.569401\n",
      "[69]\ttraining's multi_logloss: 0.0861973\ttraining's loss is: : 0.167526\tvalid_1's multi_logloss: 0.334829\tvalid_1's loss is: : 0.56571\n",
      "[70]\ttraining's multi_logloss: 0.0829002\ttraining's loss is: : 0.161254\tvalid_1's multi_logloss: 0.33283\tvalid_1's loss is: : 0.562302\n",
      "[71]\ttraining's multi_logloss: 0.07969\ttraining's loss is: : 0.155142\tvalid_1's multi_logloss: 0.331024\tvalid_1's loss is: : 0.559239\n",
      "[72]\ttraining's multi_logloss: 0.0766467\ttraining's loss is: : 0.149335\tvalid_1's multi_logloss: 0.329337\tvalid_1's loss is: : 0.55632\n",
      "[73]\ttraining's multi_logloss: 0.0737028\ttraining's loss is: : 0.14371\tvalid_1's multi_logloss: 0.327751\tvalid_1's loss is: : 0.553626\n",
      "[74]\ttraining's multi_logloss: 0.0709025\ttraining's loss is: : 0.138348\tvalid_1's multi_logloss: 0.326291\tvalid_1's loss is: : 0.551145\n",
      "[75]\ttraining's multi_logloss: 0.0682038\ttraining's loss is: : 0.133179\tvalid_1's multi_logloss: 0.324739\tvalid_1's loss is: : 0.548556\n",
      "[76]\ttraining's multi_logloss: 0.0656016\ttraining's loss is: : 0.128188\tvalid_1's multi_logloss: 0.323531\tvalid_1's loss is: : 0.546578\n",
      "[77]\ttraining's multi_logloss: 0.0631202\ttraining's loss is: : 0.123422\tvalid_1's multi_logloss: 0.322209\tvalid_1's loss is: : 0.544378\n",
      "[78]\ttraining's multi_logloss: 0.0607134\ttraining's loss is: : 0.118797\tvalid_1's multi_logloss: 0.320998\tvalid_1's loss is: : 0.542421\n",
      "[79]\ttraining's multi_logloss: 0.058416\ttraining's loss is: : 0.114373\tvalid_1's multi_logloss: 0.319989\tvalid_1's loss is: : 0.540834\n",
      "[80]\ttraining's multi_logloss: 0.0562149\ttraining's loss is: : 0.110128\tvalid_1's multi_logloss: 0.318793\tvalid_1's loss is: : 0.538954\n",
      "[81]\ttraining's multi_logloss: 0.0540264\ttraining's loss is: : 0.105917\tvalid_1's multi_logloss: 0.317965\tvalid_1's loss is: : 0.537623\n",
      "[82]\ttraining's multi_logloss: 0.0519424\ttraining's loss is: : 0.101899\tvalid_1's multi_logloss: 0.317027\tvalid_1's loss is: : 0.536126\n",
      "[83]\ttraining's multi_logloss: 0.0499316\ttraining's loss is: : 0.098018\tvalid_1's multi_logloss: 0.316493\tvalid_1's loss is: : 0.535306\n",
      "[84]\ttraining's multi_logloss: 0.0480161\ttraining's loss is: : 0.0943168\tvalid_1's multi_logloss: 0.315846\tvalid_1's loss is: : 0.534344\n",
      "[85]\ttraining's multi_logloss: 0.0461856\ttraining's loss is: : 0.0907753\tvalid_1's multi_logloss: 0.315413\tvalid_1's loss is: : 0.533704\n",
      "[86]\ttraining's multi_logloss: 0.0444196\ttraining's loss is: : 0.0873581\tvalid_1's multi_logloss: 0.314913\tvalid_1's loss is: : 0.532988\n",
      "[87]\ttraining's multi_logloss: 0.0426963\ttraining's loss is: : 0.0840181\tvalid_1's multi_logloss: 0.314411\tvalid_1's loss is: : 0.532309\n",
      "[88]\ttraining's multi_logloss: 0.041071\ttraining's loss is: : 0.0808642\tvalid_1's multi_logloss: 0.314007\tvalid_1's loss is: : 0.531822\n",
      "[89]\ttraining's multi_logloss: 0.0395194\ttraining's loss is: : 0.077849\tvalid_1's multi_logloss: 0.313766\tvalid_1's loss is: : 0.531584\n",
      "[90]\ttraining's multi_logloss: 0.0380299\ttraining's loss is: : 0.0749524\tvalid_1's multi_logloss: 0.313581\tvalid_1's loss is: : 0.531378\n",
      "[91]\ttraining's multi_logloss: 0.036561\ttraining's loss is: : 0.0720928\tvalid_1's multi_logloss: 0.313303\tvalid_1's loss is: : 0.531137\n",
      "[92]\ttraining's multi_logloss: 0.0351847\ttraining's loss is: : 0.0694093\tvalid_1's multi_logloss: 0.313045\tvalid_1's loss is: : 0.53092\n",
      "[93]\ttraining's multi_logloss: 0.0338654\ttraining's loss is: : 0.0668345\tvalid_1's multi_logloss: 0.313055\tvalid_1's loss is: : 0.531068\n",
      "[94]\ttraining's multi_logloss: 0.0325848\ttraining's loss is: : 0.0643339\tvalid_1's multi_logloss: 0.312958\tvalid_1's loss is: : 0.531118\n",
      "[95]\ttraining's multi_logloss: 0.0313701\ttraining's loss is: : 0.0619593\tvalid_1's multi_logloss: 0.313066\tvalid_1's loss is: : 0.531509\n",
      "[96]\ttraining's multi_logloss: 0.0301774\ttraining's loss is: : 0.0596289\tvalid_1's multi_logloss: 0.313282\tvalid_1's loss is: : 0.532102\n",
      "[97]\ttraining's multi_logloss: 0.0290451\ttraining's loss is: : 0.0574143\tvalid_1's multi_logloss: 0.313334\tvalid_1's loss is: : 0.532427\n",
      "[98]\ttraining's multi_logloss: 0.0279471\ttraining's loss is: : 0.0552652\tvalid_1's multi_logloss: 0.313324\tvalid_1's loss is: : 0.532598\n",
      "[99]\ttraining's multi_logloss: 0.0268992\ttraining's loss is: : 0.0532118\tvalid_1's multi_logloss: 0.313394\tvalid_1's loss is: : 0.533006\n",
      "[100]\ttraining's multi_logloss: 0.0259088\ttraining's loss is: : 0.0512695\tvalid_1's multi_logloss: 0.313319\tvalid_1's loss is: : 0.53317\n",
      "[101]\ttraining's multi_logloss: 0.0249446\ttraining's loss is: : 0.0493781\tvalid_1's multi_logloss: 0.313482\tvalid_1's loss is: : 0.533695\n",
      "[102]\ttraining's multi_logloss: 0.0240324\ttraining's loss is: : 0.0475872\tvalid_1's multi_logloss: 0.313884\tvalid_1's loss is: : 0.53469\n",
      "[103]\ttraining's multi_logloss: 0.0231568\ttraining's loss is: : 0.0458667\tvalid_1's multi_logloss: 0.314036\tvalid_1's loss is: : 0.535219\n",
      "[104]\ttraining's multi_logloss: 0.0223152\ttraining's loss is: : 0.0442121\tvalid_1's multi_logloss: 0.314356\tvalid_1's loss is: : 0.53607\n",
      "[105]\ttraining's multi_logloss: 0.0215157\ttraining's loss is: : 0.0426391\tvalid_1's multi_logloss: 0.314524\tvalid_1's loss is: : 0.536611\n",
      "[106]\ttraining's multi_logloss: 0.0206912\ttraining's loss is: : 0.041019\tvalid_1's multi_logloss: 0.314821\tvalid_1's loss is: : 0.537429\n",
      "[107]\ttraining's multi_logloss: 0.0199123\ttraining's loss is: : 0.039487\tvalid_1's multi_logloss: 0.314992\tvalid_1's loss is: : 0.537994\n",
      "[108]\ttraining's multi_logloss: 0.0191758\ttraining's loss is: : 0.0380373\tvalid_1's multi_logloss: 0.315565\tvalid_1's loss is: : 0.539241\n",
      "[109]\ttraining's multi_logloss: 0.0184519\ttraining's loss is: : 0.0366114\tvalid_1's multi_logloss: 0.315922\tvalid_1's loss is: : 0.540145\n",
      "[110]\ttraining's multi_logloss: 0.0177683\ttraining's loss is: : 0.0352644\tvalid_1's multi_logloss: 0.316363\tvalid_1's loss is: : 0.541237\n",
      "[111]\ttraining's multi_logloss: 0.0170964\ttraining's loss is: : 0.0339402\tvalid_1's multi_logloss: 0.316859\tvalid_1's loss is: : 0.542405\n",
      "[112]\ttraining's multi_logloss: 0.0164412\ttraining's loss is: : 0.032648\tvalid_1's multi_logloss: 0.317175\tvalid_1's loss is: : 0.543214\n",
      "[113]\ttraining's multi_logloss: 0.0158187\ttraining's loss is: : 0.0314193\tvalid_1's multi_logloss: 0.317531\tvalid_1's loss is: : 0.544145\n",
      "[114]\ttraining's multi_logloss: 0.0152268\ttraining's loss is: : 0.0302503\tvalid_1's multi_logloss: 0.317817\tvalid_1's loss is: : 0.544971\n",
      "[115]\ttraining's multi_logloss: 0.0146469\ttraining's loss is: : 0.0291045\tvalid_1's multi_logloss: 0.318315\tvalid_1's loss is: : 0.546196\n",
      "[116]\ttraining's multi_logloss: 0.0141012\ttraining's loss is: : 0.0280261\tvalid_1's multi_logloss: 0.318916\tvalid_1's loss is: : 0.54742\n",
      "[117]\ttraining's multi_logloss: 0.0135816\ttraining's loss is: : 0.026999\tvalid_1's multi_logloss: 0.319392\tvalid_1's loss is: : 0.548526\n",
      "[118]\ttraining's multi_logloss: 0.0130827\ttraining's loss is: : 0.0260119\tvalid_1's multi_logloss: 0.320026\tvalid_1's loss is: : 0.5499\n",
      "[119]\ttraining's multi_logloss: 0.0126057\ttraining's loss is: : 0.025068\tvalid_1's multi_logloss: 0.320553\tvalid_1's loss is: : 0.551048\n",
      "[120]\ttraining's multi_logloss: 0.0121537\ttraining's loss is: : 0.024173\tvalid_1's multi_logloss: 0.321273\tvalid_1's loss is: : 0.55258\n",
      "[121]\ttraining's multi_logloss: 0.0117011\ttraining's loss is: : 0.0232771\tvalid_1's multi_logloss: 0.321973\tvalid_1's loss is: : 0.554042\n",
      "[122]\ttraining's multi_logloss: 0.0112617\ttraining's loss is: : 0.0224074\tvalid_1's multi_logloss: 0.322685\tvalid_1's loss is: : 0.555506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123]\ttraining's multi_logloss: 0.0108377\ttraining's loss is: : 0.0215677\tvalid_1's multi_logloss: 0.323428\tvalid_1's loss is: : 0.55709\n",
      "[124]\ttraining's multi_logloss: 0.0104344\ttraining's loss is: : 0.0207686\tvalid_1's multi_logloss: 0.324015\tvalid_1's loss is: : 0.558444\n",
      "[125]\ttraining's multi_logloss: 0.0100475\ttraining's loss is: : 0.0200016\tvalid_1's multi_logloss: 0.324785\tvalid_1's loss is: : 0.560056\n",
      "[126]\ttraining's multi_logloss: 0.00967195\ttraining's loss is: : 0.019257\tvalid_1's multi_logloss: 0.325642\tvalid_1's loss is: : 0.561782\n",
      "[127]\ttraining's multi_logloss: 0.00930444\ttraining's loss is: : 0.0185283\tvalid_1's multi_logloss: 0.326291\tvalid_1's loss is: : 0.563197\n",
      "[128]\ttraining's multi_logloss: 0.00895312\ttraining's loss is: : 0.0178314\tvalid_1's multi_logloss: 0.326888\tvalid_1's loss is: : 0.564504\n",
      "[129]\ttraining's multi_logloss: 0.0086164\ttraining's loss is: : 0.0171633\tvalid_1's multi_logloss: 0.327696\tvalid_1's loss is: : 0.566191\n",
      "[130]\ttraining's multi_logloss: 0.00829792\ttraining's loss is: : 0.0165312\tvalid_1's multi_logloss: 0.328397\tvalid_1's loss is: : 0.567624\n",
      "[131]\ttraining's multi_logloss: 0.0079909\ttraining's loss is: : 0.0159217\tvalid_1's multi_logloss: 0.329184\tvalid_1's loss is: : 0.569265\n",
      "[132]\ttraining's multi_logloss: 0.00769486\ttraining's loss is: : 0.0153339\tvalid_1's multi_logloss: 0.329996\tvalid_1's loss is: : 0.571017\n",
      "[133]\ttraining's multi_logloss: 0.00741302\ttraining's loss is: : 0.0147739\tvalid_1's multi_logloss: 0.331047\tvalid_1's loss is: : 0.573132\n",
      "[134]\ttraining's multi_logloss: 0.00714447\ttraining's loss is: : 0.0142402\tvalid_1's multi_logloss: 0.332074\tvalid_1's loss is: : 0.57521\n",
      "[135]\ttraining's multi_logloss: 0.006883\ttraining's loss is: : 0.0137205\tvalid_1's multi_logloss: 0.332896\tvalid_1's loss is: : 0.576965\n",
      "[136]\ttraining's multi_logloss: 0.00662988\ttraining's loss is: : 0.0132173\tvalid_1's multi_logloss: 0.333774\tvalid_1's loss is: : 0.578786\n",
      "[137]\ttraining's multi_logloss: 0.00638811\ttraining's loss is: : 0.0127367\tvalid_1's multi_logloss: 0.33461\tvalid_1's loss is: : 0.580465\n",
      "[138]\ttraining's multi_logloss: 0.00615925\ttraining's loss is: : 0.0122815\tvalid_1's multi_logloss: 0.335551\tvalid_1's loss is: : 0.582483\n",
      "[139]\ttraining's multi_logloss: 0.00594238\ttraining's loss is: : 0.01185\tvalid_1's multi_logloss: 0.336584\tvalid_1's loss is: : 0.584654\n",
      "[140]\ttraining's multi_logloss: 0.00573192\ttraining's loss is: : 0.0114312\tvalid_1's multi_logloss: 0.337496\tvalid_1's loss is: : 0.586552\n",
      "[141]\ttraining's multi_logloss: 0.0055185\ttraining's loss is: : 0.0110067\tvalid_1's multi_logloss: 0.338122\tvalid_1's loss is: : 0.587956\n",
      "[142]\ttraining's multi_logloss: 0.00531674\ttraining's loss is: : 0.0106053\tvalid_1's multi_logloss: 0.33908\tvalid_1's loss is: : 0.589865\n",
      "Early stopping, best iteration is:\n",
      "[92]\ttraining's multi_logloss: 0.0351847\ttraining's loss is: : 0.0694093\tvalid_1's multi_logloss: 0.313045\tvalid_1's loss is: : 0.53092\n"
     ]
    }
   ],
   "source": [
    "train_features = [col for col in train_data_.columns if col!='label' and col!='file_id' and 'std' not in col and 'quantile' not in col]\n",
    "train_label = 'label'\n",
    "\n",
    "train_ind = train_X.index\n",
    "test_ind = test_X.index\n",
    "\n",
    "dtrain = lgb.Dataset(train_data_.loc[train_ind,train_features],train_data_.loc[train_ind,train_label].values) \n",
    "dval   = lgb.Dataset(train_data_.loc[test_ind,train_features],train_data_.loc[test_ind,train_label].values, reference = dtrain) \n",
    "\n",
    "params = {\n",
    "        'task':'train', \n",
    "        'num_leaves': 255,\n",
    "        'objective': 'multiclass',\n",
    "        'num_class':8,\n",
    "        'min_data_in_leaf': 10,\n",
    "        #'min_data_in_leaf': 1,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.85,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 5, \n",
    "        'max_bin':128,\n",
    "        'num_threads': 64,\n",
    "        'random_state':100\n",
    "    }  \n",
    "lgb_model_3_order = lgb.train(params, dtrain, num_boost_round=500,valid_sets=[dtrain,dval], early_stopping_rounds=50, feval=lgb_logloss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_imp = pd.DataFrame({'feature':train_features, 'imp':lgb_model_3_order.feature_importance()}).sort_values('imp')\n",
    "important_features = fea_imp.loc[fea_imp.imp >=1, 'feature'].values\n",
    "important_features = list(important_features)\n",
    "\n",
    "important_features.append('file_id')\n",
    "important_features.append('label')\n",
    "\n",
    "train_data_[important_features].to_csv('./train_data_2gram.csv',index = None)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 附录\n",
    "tf-idf的1Gram特征可以替换api的次数特征等，加入tf-idf有提升，提升较小"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
