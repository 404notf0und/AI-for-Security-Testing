library(lightgbm)
library(data.table)

set.seed(0)

#---------------------------
cat("Preparing train data...\n")

tr <- fread("../input/train.csv", drop = "MachineIdentifier")

y <- tr$HasDetections
tr$HasDetections <- NULL

fea <- names(tr)
cats <- c()
for (f in fea) if (is.character(tr[[f]])) cats <- c(cats, f)

#---------------------------
cat("Converting character columns to numeric...\n")

levels <- new.env(hash = TRUE, parent = emptyenv())
for (f in fea) 
  if (!is.numeric(tr[[f]])) {
    levels[[f]] <- sort(unique(tr[[f]]))
    tr[, (f) := as.integer(factor(.SD[[f]], levels = levels[[f]]))]
    invisible(gc()) 
  }

#---------------------------
cat("Preparing data for boosting...\n")

tri <- sample(tr[, .N], 0.85 * tr[, .N])
tr <- data.matrix(tr)
xtrain <- lgb.Dataset(data = tr[tri, ], label = y[tri], categorical_feature = cats)
xval <- lgb.Dataset(data = tr[-tri, ], label = y[-tri], categorical_feature = cats)
rm(tr, y, tri); invisible(gc())

#---------------------------
cat("Training model...\n")

p <- list(boosting_type = "gbdt",
          objective = "binary",
          metric ="auc",
          nthread = 4,
          learning_rate = 0.05,
          max_depth = -1, 
          sub_feature = 0.7,
          sub_row = 0.7,
          bagging_freq = 1,
          lambda_l1 = 0.1,
          lambda_l2 = 0.1)

m_gbm <- lgb.train(p, xtrain, 10500, list(val = xval), eval_freq = 100, early_stopping_rounds = 25, verbose = 1)

imp <- lgb.importance(model = m_gbm)

rm(xtrain, xval, imp)
gc()

#---------------------------
cat("Preparing test data...\n")

te <- fread("../input/test.csv", drop = "MachineIdentifier")

for (f in names(te)) 
  if (!is.numeric(te[[f]])) {
    te[, (f) := as.integer(factor(.SD[[f]], levels = levels[[f]]))]
    invisible(gc())  
  }

te <- data.matrix(te)

#---------------------------
cat("Making predictions...\n")

subm <- fread("../input/sample_submission.csv")
subm[, HasDetections := round(predict(m_gbm, te), 5)]
fwrite(subm, paste0("submission", round(m_gbm$best_score, 5), ".csv"))